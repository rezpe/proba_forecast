{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Medida del CRPS\n",
    "def heavyside(prediction,actual):\n",
    "    return prediction >= actual\n",
    "\n",
    "def cdf_dif(prediction,actual):\n",
    "    quantiles = np.arange(1,100)/100.0\n",
    "    t=pd.Series(prediction)\n",
    "    dif=t-t.shift(1)\n",
    "    dif=dif.dropna()\n",
    "    fs = sum(dif*((quantiles-heavyside(prediction,actual))[1:]**2))\n",
    "    # If the actual is outside the range of the prediction, \n",
    "    # we need to account for that areas outside the range \n",
    "    if actual > prediction[-1]:\n",
    "        fs += (actual-prediction[-1]) * 1\n",
    "    if actual < prediction[0]:\n",
    "        fs += (prediction[0]-actual) * 1\n",
    "    return fs\n",
    "\n",
    "def CRPS(predictions, actuals):\n",
    "    difs_mean = [cdf_dif(predictions[i],actuals[i]) for i in range(len(actuals))]\n",
    "    return np.mean(difs_mean)\n",
    "\n",
    "def evaluate(predictions,target):\n",
    "\n",
    "    res={}\n",
    "    \n",
    "    # Calculate the CRPS\n",
    "    res[\"crps\"]=CRPS(predictions,target)\n",
    "    \n",
    "    # Bonus useful Feature\n",
    "    count = 0\n",
    "    for i in range(len(target)):\n",
    "        if (target[i]>predictions[i][0]) and (target[i]<predictions[i][-1]):\n",
    "            count+=1\n",
    "    res[\"count\"]=count\n",
    "    \n",
    "    ## Calculate as well measures for the quantile 50\n",
    "    total_df = pd.DataFrame(predictions)\n",
    "    quantiles = np.arange(1,100)/100.0 \n",
    "    total_df.columns=np.array(quantiles).astype(str)\n",
    "    #RMSE       \n",
    "    res[\"rmse\"]=np.sqrt(np.mean((target-total_df[\"0.5\"])**2))\n",
    "    #MAE    \n",
    "    res[\"mae\"]=np.mean(np.abs(target-total_df[\"0.5\"] ) )\n",
    "    #Bias \n",
    "    res[\"bias\"]=np.mean(target-total_df[\"0.5\"])\n",
    "    #Corr\n",
    "    res[\"corr\"]=np.corrcoef(target,total_df[\"0.5\"])[0][1]\n",
    "\n",
    "    res[\"all\"]=predictions\n",
    "    res[\"target\"]=target\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import  tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.fft import fft\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def prepare_data_from_horizon(df, horizon=12):\n",
    "    \n",
    "    data=df.copy()\n",
    "\n",
    "    sel = np.concatenate([[1,2,3,4],\n",
    "                         [12],\n",
    "                         24*np.arange(1,9),\n",
    "                         12+24*np.arange(1,9)])  \n",
    "    sel=np.concatenate([sel,sel-1,sel+1])  \n",
    "    \n",
    "    ## lagged NO2 values\n",
    "    for i in sel:\n",
    "        if (i>=horizon):\n",
    "            data[\"NO2 - \"+str(i)] = data[\"NO2\"].shift(i)\n",
    "\n",
    "    ## lagged O3 values\n",
    "    for i in 24*np.arange(1,4):\n",
    "        if (i>=horizon):\n",
    "            data[\"O3 - \"+str(i)] = data[\"O3\"].shift(i)\n",
    "\n",
    "    ## Remove empty values\n",
    "    data=data.dropna()\n",
    "\n",
    "    X=data[list(set(data.columns)-set(['DATE',\"NO2\",\"O3\"]))]\n",
    "    y=data[\"NO2\"]\n",
    "  \n",
    "    return X, y\n",
    "\n",
    "#\"data/dataEscAgui.csv\"\n",
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path,sep=\";\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = df[[\"DATE\",\"SPA.NO2\",\"SPA.O3\",\"MACC.NO2\"]].copy()\n",
    "    data[\"DATE\"]=pd.to_datetime(data[\"DATE\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    data = data.sort_values(\"DATE\")\n",
    "    data.columns = [\"DATE\",\"NO2\",\"O3\",\"CAMS\"]\n",
    "\n",
    "    ## Remove everything from 2020\n",
    "    data=data[data[\"DATE\"].astype(str)<\"2020\"]\n",
    "\n",
    "    ## Fourier Columns\n",
    "    freqs = [2922,1461,209,1465,4]\n",
    "    l = 35064\n",
    "    n = np.arange(len(data))\n",
    "    fcols = []\n",
    "    for f in freqs:\n",
    "        data[\"c\"+str(f)]=np.cos(n*2*np.pi*f/l)\n",
    "        fcols.append(\"c\"+str(f))\n",
    "        data[\"s\"+str(f)]=np.cos(n*2*np.pi*f/l)\n",
    "        fcols.append(\"s\"+str(f))\n",
    "\n",
    "    data[\"NO2\"]=np.log1p(data[\"NO2\"])\n",
    "    data[\"O3\"]=np.log1p(data[\"O3\"])\n",
    "    data[\"CAMS\"]=np.log1p(data[\"CAMS\"])\n",
    "\n",
    "    ## Calendar Variables \n",
    "    ## Calendar Variables do not bring better results and therefore\n",
    "    ## removed\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tilted_loss(q,y,f):\n",
    "    e = (y-f)\n",
    "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)\n",
    "\n",
    "class MLPQuantile():\n",
    "    \n",
    "    def __init__(self,batch_size,epochs,lr):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr=lr\n",
    "        self.estimators = []\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        def MLPmodel():\n",
    "            model = Sequential()\n",
    "            model.add(Dense(len(X_train[0]), input_dim=len(X_train[0]), activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(int(len(X_train[0])/2), activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "            return model\n",
    "        \n",
    "        print(\"training !\")\n",
    "\n",
    "        X_ttrain, X_val, y_ttrain, y_val = train_test_split(X_train,y_train,test_size=.05,random_state=2020)\n",
    "\n",
    "        for q in [0.022750131948179195,0.15865525393145707,0.5,0.8413447460685429,0.9772498680518208]:\n",
    "            print(f\"Quantile: {q}\")\n",
    "            model = MLPmodel()\n",
    "            optim=Adam(learning_rate=self.lr)\n",
    "            model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=optim)\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=10)\n",
    "            history = model.fit(X_ttrain, y_ttrain, \n",
    "                                epochs=self.epochs, batch_size=self.batch_size,  \n",
    "                                verbose=1,callbacks=[es],\n",
    "                                validation_data=(X_val,y_val))\n",
    "            self.estimators.append(model)\n",
    "        print(\"Done\")\n",
    "        \n",
    "    def predict(self,X):\n",
    "        predictions_gbr = []\n",
    "        print(\"predicting\")\n",
    "        for reg in tqdm(self.estimators):\n",
    "            predictions_gbr.append(reg.predict(X))\n",
    "         \n",
    "        total_pred={}\n",
    "        for i in range(len(predictions_gbr)):\n",
    "            total_pred[i]=predictions_gbr[i][:,0]\n",
    "            \n",
    "        total_df=pd.DataFrame(total_pred)\n",
    "\n",
    "        def process_row(row):\n",
    "            v = row.values\n",
    "            dif_mean = np.abs(v-v[2])\n",
    "            mu = v[2]\n",
    "            s = np.mean([dif_mean[0]/2,dif_mean[1],dif_mean[3],dif_mean[4]/2])\n",
    "            mi_norm = stats.norm(mu,s)\n",
    "            quant=[]\n",
    "            for quantile in np.arange(1,100)/100.0 :\n",
    "                quant.append(mi_norm.ppf(quantile))\n",
    "            return pd.Series(quant)\n",
    " \n",
    "        total_df = total_df.apply(process_row,axis=1)\n",
    "        \n",
    "        return total_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 13\n",
    "\n",
    "df = get_data(\"../2018_2019_data/28079008.csv\")\n",
    "X, y = prepare_data_from_horizon(df,horizon)\n",
    "\n",
    "kf = KFold(5,shuffle=True)\n",
    "train_index, test_index = list(kf.split(X))[1]\n",
    "\n",
    "train_index = X.index.values[train_index]\n",
    "test_index = X.index.values[test_index] \n",
    "        \n",
    "# Filter the test index when prediction time is 10:00\n",
    "ten_index = df[(df[\"DATE\"]-timedelta(hours=horizon)).dt.hour==10].index\n",
    "test_index_10 = test_index[pd.Series(test_index).isin(ten_index)]\n",
    "        \n",
    "# We retrieve the indexes that are related to the test indexes according to our AR model\n",
    "sel = np.concatenate([[1,2,3,4],\n",
    "                            [12],\n",
    "                            24*np.arange(1,9),\n",
    "                            12+24*np.arange(1,9)])  \n",
    "sel=np.concatenate([sel,sel-1,sel+1]) \n",
    "        \n",
    "all_index_related_test = set([])\n",
    "for i in sel:\n",
    "    all_index_related_test |= set(test_index_10+i)\n",
    "        \n",
    "train_index_CV = train_index[pd.Series(train_index).isin(list(all_index_related_test))]\n",
    "        \n",
    "X_train = X.loc[train_index_CV]\n",
    "y_train = y.loc[train_index_CV]\n",
    "        \n",
    "X_test = X.loc[test_index_10]\n",
    "y_test = y.loc[test_index_10]\n",
    "        \n",
    "scaler = RobustScaler()\n",
    "# Fit the scaler on the training features and transform these in one go\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "# Scale the test set\n",
    "X_test_std = scaler.transform(X_test)\n",
    "        \n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train_std,y_train)\n",
    "\n",
    "dif_train = y_train-lin.predict(X_train_std)\n",
    "dif_test = y_test-lin.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a04dda9e5472d9bad21408a878a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a2f1fdfc964000910986057e409a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acef541f53c434b8265c8222caa1f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.0754 - val_loss: 0.0528\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 864us/step - loss: 0.0524 - val_loss: 0.0412\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 923us/step - loss: 0.0413 - val_loss: 0.0351\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 954us/step - loss: 0.0371 - val_loss: 0.0315\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 919us/step - loss: 0.0336 - val_loss: 0.0304\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 974us/step - loss: 0.0325 - val_loss: 0.0294\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 943us/step - loss: 0.0308 - val_loss: 0.0285\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 870us/step - loss: 0.0294 - val_loss: 0.0280\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 919us/step - loss: 0.0282 - val_loss: 0.0272\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0269 - val_loss: 0.0259\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 885us/step - loss: 0.0263 - val_loss: 0.0262\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 881us/step - loss: 0.0262 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 914us/step - loss: 0.0253 - val_loss: 0.0246\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 975us/step - loss: 0.0248 - val_loss: 0.0238\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 898us/step - loss: 0.0242 - val_loss: 0.0232\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0233\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 963us/step - loss: 0.0233 - val_loss: 0.0227\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 961us/step - loss: 0.0236 - val_loss: 0.0229\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 855us/step - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 871us/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 862us/step - loss: 0.0224 - val_loss: 0.0221\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 868us/step - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0205 - val_loss: 0.0217\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0196 - val_loss: 0.0200\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 870us/step - loss: 0.0191 - val_loss: 0.0203\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 885us/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 872us/step - loss: 0.0187 - val_loss: 0.0195\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0188 - val_loss: 0.0196\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 994us/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 920us/step - loss: 0.0189 - val_loss: 0.0195\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 933us/step - loss: 0.0185 - val_loss: 0.0194\n",
      "Epoch 44/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0182 - val_loss: 0.0191\n",
      "Epoch 45/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0186 - val_loss: 0.0198\n",
      "Epoch 46/200\n",
      "327/327 [==============================] - 0s 973us/step - loss: 0.0184 - val_loss: 0.0190\n",
      "Epoch 47/200\n",
      "327/327 [==============================] - 0s 866us/step - loss: 0.0179 - val_loss: 0.0190\n",
      "Epoch 48/200\n",
      "327/327 [==============================] - 0s 868us/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 49/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.0179 - val_loss: 0.0192\n",
      "Epoch 50/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0180 - val_loss: 0.0188\n",
      "Epoch 51/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.0179 - val_loss: 0.0190\n",
      "Epoch 52/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0176 - val_loss: 0.0196\n",
      "Epoch 53/200\n",
      "327/327 [==============================] - 0s 935us/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 54/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0198\n",
      "Epoch 55/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0193\n",
      "Epoch 56/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0203\n",
      "Epoch 57/200\n",
      "327/327 [==============================] - 0s 999us/step - loss: 0.0173 - val_loss: 0.0194\n",
      "Epoch 58/200\n",
      "327/327 [==============================] - 0s 936us/step - loss: 0.0174 - val_loss: 0.0192\n",
      "Epoch 59/200\n",
      "327/327 [==============================] - 0s 879us/step - loss: 0.0176 - val_loss: 0.0195\n",
      "Epoch 60/200\n",
      "327/327 [==============================] - 0s 879us/step - loss: 0.0168 - val_loss: 0.0193\n",
      "Epoch 00060: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.4780 - val_loss: 0.2688\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.2560 - val_loss: 0.1894\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.1900 - val_loss: 0.1619\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 919us/step - loss: 0.1652 - val_loss: 0.1475\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.1513 - val_loss: 0.1378\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 954us/step - loss: 0.1434 - val_loss: 0.1335\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.1328 - val_loss: 0.1255\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 858us/step - loss: 0.1291 - val_loss: 0.1199\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 862us/step - loss: 0.1207 - val_loss: 0.1151\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 884us/step - loss: 0.1154 - val_loss: 0.1123\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 872us/step - loss: 0.1122 - val_loss: 0.1098\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 874us/step - loss: 0.1089 - val_loss: 0.1072\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.1071 - val_loss: 0.1058\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.1019 - val_loss: 0.1028\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 855us/step - loss: 0.1013 - val_loss: 0.1020\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0994 - val_loss: 0.0997\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0990\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0930 - val_loss: 0.0984\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.0938 - val_loss: 0.0971\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0932 - val_loss: 0.0969\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0905 - val_loss: 0.0956\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.0902 - val_loss: 0.0956\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0884 - val_loss: 0.0942\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0868 - val_loss: 0.0945\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.0870 - val_loss: 0.0933\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0858 - val_loss: 0.0937\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0841 - val_loss: 0.0932\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 921us/step - loss: 0.0849 - val_loss: 0.0923\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0826 - val_loss: 0.0927\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0832 - val_loss: 0.0915\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0833 - val_loss: 0.0915\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0822 - val_loss: 0.0909\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0809 - val_loss: 0.0912\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0831 - val_loss: 0.0915\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0801 - val_loss: 0.0910\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0798 - val_loss: 0.0900\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0792 - val_loss: 0.0892\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0797 - val_loss: 0.0899\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0787 - val_loss: 0.0897\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0784 - val_loss: 0.0889\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0785 - val_loss: 0.0907\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0796 - val_loss: 0.0900\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0779 - val_loss: 0.0894\n",
      "Epoch 44/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0780 - val_loss: 0.0891\n",
      "Epoch 45/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0772 - val_loss: 0.0890\n",
      "Epoch 46/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0765 - val_loss: 0.0890\n",
      "Epoch 47/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0772 - val_loss: 0.0888\n",
      "Epoch 48/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0761 - val_loss: 0.0882\n",
      "Epoch 49/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0767 - val_loss: 0.0887\n",
      "Epoch 50/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0757 - val_loss: 0.0895\n",
      "Epoch 51/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0755 - val_loss: 0.0889\n",
      "Epoch 52/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0758 - val_loss: 0.0904\n",
      "Epoch 53/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0757 - val_loss: 0.0899\n",
      "Epoch 54/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0760 - val_loss: 0.0880\n",
      "Epoch 55/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0759 - val_loss: 0.0870\n",
      "Epoch 56/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0752 - val_loss: 0.0883\n",
      "Epoch 57/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0742 - val_loss: 0.0891\n",
      "Epoch 58/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0755 - val_loss: 0.0884\n",
      "Epoch 59/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0735 - val_loss: 0.0872\n",
      "Epoch 60/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0735 - val_loss: 0.0879\n",
      "Epoch 61/200\n",
      "327/327 [==============================] - 0s 864us/step - loss: 0.0720 - val_loss: 0.0884\n",
      "Epoch 62/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.0737 - val_loss: 0.0870\n",
      "Epoch 63/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0736 - val_loss: 0.0879\n",
      "Epoch 64/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0733 - val_loss: 0.0872\n",
      "Epoch 65/200\n",
      "327/327 [==============================] - 0s 869us/step - loss: 0.0719 - val_loss: 0.0869\n",
      "Epoch 66/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0725 - val_loss: 0.0877\n",
      "Epoch 67/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0726 - val_loss: 0.0880\n",
      "Epoch 68/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0733 - val_loss: 0.0878\n",
      "Epoch 69/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0722 - val_loss: 0.0864\n",
      "Epoch 70/200\n",
      "327/327 [==============================] - 0s 870us/step - loss: 0.0720 - val_loss: 0.0869\n",
      "Epoch 71/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0730 - val_loss: 0.0876\n",
      "Epoch 72/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0707 - val_loss: 0.0878\n",
      "Epoch 73/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.0720 - val_loss: 0.0866\n",
      "Epoch 74/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0727 - val_loss: 0.0867\n",
      "Epoch 75/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0734 - val_loss: 0.0863\n",
      "Epoch 76/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0719 - val_loss: 0.0866\n",
      "Epoch 77/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0711 - val_loss: 0.0865\n",
      "Epoch 78/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0704 - val_loss: 0.0875\n",
      "Epoch 79/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0706 - val_loss: 0.0874\n",
      "Epoch 80/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0716 - val_loss: 0.0864\n",
      "Epoch 81/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0697 - val_loss: 0.0861\n",
      "Epoch 82/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0707 - val_loss: 0.0862\n",
      "Epoch 83/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0700 - val_loss: 0.0862\n",
      "Epoch 84/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0705 - val_loss: 0.0859\n",
      "Epoch 85/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0703 - val_loss: 0.0855\n",
      "Epoch 86/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0699 - val_loss: 0.0863\n",
      "Epoch 87/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0696 - val_loss: 0.0863\n",
      "Epoch 88/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0700 - val_loss: 0.0877\n",
      "Epoch 89/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0692 - val_loss: 0.0868\n",
      "Epoch 90/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0699 - val_loss: 0.0866\n",
      "Epoch 91/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0687 - val_loss: 0.0874\n",
      "Epoch 92/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0690 - val_loss: 0.0855\n",
      "Epoch 93/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0682 - val_loss: 0.0859\n",
      "Epoch 94/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.0684 - val_loss: 0.0868\n",
      "Epoch 95/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0688 - val_loss: 0.0858\n",
      "Epoch 00095: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 1.7566 - val_loss: 0.7285\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 841us/step - loss: 0.6620 - val_loss: 0.3936\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 816us/step - loss: 0.3772 - val_loss: 0.3072\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.3021 - val_loss: 0.2730\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.2678 - val_loss: 0.2532\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.2440 - val_loss: 0.2394\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.2251 - val_loss: 0.2257\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.2132 - val_loss: 0.2163\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.2038 - val_loss: 0.2069\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1964 - val_loss: 0.1948\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 877us/step - loss: 0.1875 - val_loss: 0.1870\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.1781 - val_loss: 0.1807\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1782 - val_loss: 0.1752\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 875us/step - loss: 0.1707 - val_loss: 0.1712\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1674 - val_loss: 0.1673\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 870us/step - loss: 0.1626 - val_loss: 0.1652\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.1570 - val_loss: 0.1608\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.1537 - val_loss: 0.1600\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1514 - val_loss: 0.1569\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1493 - val_loss: 0.1559\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1503 - val_loss: 0.1525\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1475 - val_loss: 0.1531\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1457 - val_loss: 0.1517\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1459 - val_loss: 0.1491\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1437 - val_loss: 0.1473\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1423 - val_loss: 0.1489\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1420 - val_loss: 0.1475\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1406 - val_loss: 0.1457\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.1361 - val_loss: 0.1483\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1386 - val_loss: 0.1457\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.1355 - val_loss: 0.1453\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1367 - val_loss: 0.1442\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1352 - val_loss: 0.1461\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 868us/step - loss: 0.1348 - val_loss: 0.1434\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.1327 - val_loss: 0.1430\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 874us/step - loss: 0.1335 - val_loss: 0.1426\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1338 - val_loss: 0.1422\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1321 - val_loss: 0.1425\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1312 - val_loss: 0.1426\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1323 - val_loss: 0.1419\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1315 - val_loss: 0.1416\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.1311 - val_loss: 0.1401\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1303 - val_loss: 0.1416\n",
      "Epoch 44/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.1310 - val_loss: 0.1397\n",
      "Epoch 45/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.1296 - val_loss: 0.1406\n",
      "Epoch 46/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1268 - val_loss: 0.1405\n",
      "Epoch 47/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1275 - val_loss: 0.1392\n",
      "Epoch 48/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.1274 - val_loss: 0.1389\n",
      "Epoch 49/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1256 - val_loss: 0.1397\n",
      "Epoch 50/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.1266 - val_loss: 0.1407\n",
      "Epoch 51/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1240 - val_loss: 0.1387\n",
      "Epoch 52/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.1230 - val_loss: 0.1383\n",
      "Epoch 53/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1225 - val_loss: 0.1377\n",
      "Epoch 54/200\n",
      "327/327 [==============================] - 0s 865us/step - loss: 0.1281 - val_loss: 0.1387\n",
      "Epoch 55/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1240 - val_loss: 0.1380\n",
      "Epoch 56/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1234 - val_loss: 0.1380\n",
      "Epoch 57/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1219 - val_loss: 0.1380\n",
      "Epoch 58/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.1237 - val_loss: 0.1379\n",
      "Epoch 59/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.1218 - val_loss: 0.1375\n",
      "Epoch 60/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.1227 - val_loss: 0.1379\n",
      "Epoch 61/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1219 - val_loss: 0.1368\n",
      "Epoch 62/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1205 - val_loss: 0.1380\n",
      "Epoch 63/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1234 - val_loss: 0.1373\n",
      "Epoch 64/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.1229 - val_loss: 0.1368\n",
      "Epoch 65/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.1227 - val_loss: 0.1368\n",
      "Epoch 66/200\n",
      "327/327 [==============================] - 0s 877us/step - loss: 0.1216 - val_loss: 0.1366\n",
      "Epoch 67/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.1203 - val_loss: 0.1377\n",
      "Epoch 68/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1219 - val_loss: 0.1373\n",
      "Epoch 69/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.1207 - val_loss: 0.1385\n",
      "Epoch 70/200\n",
      "327/327 [==============================] - 0s 892us/step - loss: 0.1187 - val_loss: 0.1369\n",
      "Epoch 71/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.1219 - val_loss: 0.1386\n",
      "Epoch 72/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.1199 - val_loss: 0.1377\n",
      "Epoch 73/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.1208 - val_loss: 0.1373\n",
      "Epoch 74/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.1189 - val_loss: 0.1375\n",
      "Epoch 75/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.1203 - val_loss: 0.1371\n",
      "Epoch 76/200\n",
      "327/327 [==============================] - 0s 872us/step - loss: 0.1204 - val_loss: 0.1361\n",
      "Epoch 77/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1188 - val_loss: 0.1373\n",
      "Epoch 78/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.1184 - val_loss: 0.1372\n",
      "Epoch 79/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1178 - val_loss: 0.1363\n",
      "Epoch 80/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.1184 - val_loss: 0.1370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1193 - val_loss: 0.1367\n",
      "Epoch 82/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.1170 - val_loss: 0.1362\n",
      "Epoch 83/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1174 - val_loss: 0.1357\n",
      "Epoch 84/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1183 - val_loss: 0.1375\n",
      "Epoch 85/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.1173 - val_loss: 0.1371\n",
      "Epoch 86/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1180 - val_loss: 0.1377\n",
      "Epoch 87/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1162 - val_loss: 0.1379\n",
      "Epoch 88/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.1167 - val_loss: 0.1366\n",
      "Epoch 89/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1173 - val_loss: 0.1363\n",
      "Epoch 90/200\n",
      "327/327 [==============================] - 0s 976us/step - loss: 0.1167 - val_loss: 0.1368\n",
      "Epoch 91/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1179 - val_loss: 0.1373\n",
      "Epoch 92/200\n",
      "327/327 [==============================] - 0s 882us/step - loss: 0.1166 - val_loss: 0.1375\n",
      "Epoch 93/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.1177 - val_loss: 0.1373\n",
      "Epoch 00093: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 2.7841 - val_loss: 0.9844\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 869us/step - loss: 0.7686 - val_loss: 0.4029\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.3649 - val_loss: 0.3060\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.2814 - val_loss: 0.2519\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.2301 - val_loss: 0.2167\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.1992 - val_loss: 0.1899\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.1785 - val_loss: 0.1713\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 811us/step - loss: 0.1615 - val_loss: 0.1600\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.1490 - val_loss: 0.1507\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.1398 - val_loss: 0.1415\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1358 - val_loss: 0.1361\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1301 - val_loss: 0.1295\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.1235 - val_loss: 0.1240\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 876us/step - loss: 0.1194 - val_loss: 0.1209\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.1171 - val_loss: 0.1175\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.1101 - val_loss: 0.1149\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.1079 - val_loss: 0.1105\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1052 - val_loss: 0.1094\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1031 - val_loss: 0.1068\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.1013 - val_loss: 0.1056\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0981 - val_loss: 0.1040\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.0979 - val_loss: 0.1019\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0965 - val_loss: 0.0998\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0949 - val_loss: 0.0992\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0936 - val_loss: 0.0978\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0901 - val_loss: 0.0971\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0915 - val_loss: 0.0954\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0901 - val_loss: 0.0950\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0902 - val_loss: 0.0948\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 874us/step - loss: 0.0888 - val_loss: 0.0936\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0884 - val_loss: 0.0921\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 872us/step - loss: 0.0842 - val_loss: 0.0918\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0865 - val_loss: 0.0913\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0853 - val_loss: 0.0899\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0850 - val_loss: 0.0897\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0900\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0894\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0851 - val_loss: 0.0883\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0841 - val_loss: 0.0883\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0826 - val_loss: 0.0878\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0809 - val_loss: 0.0873\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0808 - val_loss: 0.0878\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0814 - val_loss: 0.0862\n",
      "Epoch 44/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0824 - val_loss: 0.0866\n",
      "Epoch 45/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0807 - val_loss: 0.0854\n",
      "Epoch 46/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0799 - val_loss: 0.0862\n",
      "Epoch 47/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0798 - val_loss: 0.0853\n",
      "Epoch 48/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0798 - val_loss: 0.0858\n",
      "Epoch 49/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0798 - val_loss: 0.0852\n",
      "Epoch 50/200\n",
      "327/327 [==============================] - 0s 898us/step - loss: 0.0792 - val_loss: 0.0845\n",
      "Epoch 51/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0788 - val_loss: 0.0852\n",
      "Epoch 52/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0790 - val_loss: 0.0848\n",
      "Epoch 53/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0789 - val_loss: 0.0838\n",
      "Epoch 54/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0778 - val_loss: 0.0840\n",
      "Epoch 55/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0775 - val_loss: 0.0833\n",
      "Epoch 56/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0785 - val_loss: 0.0834\n",
      "Epoch 57/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0774 - val_loss: 0.0828\n",
      "Epoch 58/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0766 - val_loss: 0.0830\n",
      "Epoch 59/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0772 - val_loss: 0.0837\n",
      "Epoch 60/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0766 - val_loss: 0.0842\n",
      "Epoch 61/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.0760 - val_loss: 0.0831\n",
      "Epoch 62/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0753 - val_loss: 0.0836\n",
      "Epoch 63/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0757 - val_loss: 0.0827\n",
      "Epoch 64/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0764 - val_loss: 0.0821\n",
      "Epoch 65/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0775 - val_loss: 0.0827\n",
      "Epoch 66/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0749 - val_loss: 0.0811\n",
      "Epoch 67/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.0757 - val_loss: 0.0824\n",
      "Epoch 68/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0740 - val_loss: 0.0813\n",
      "Epoch 69/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0746 - val_loss: 0.0818\n",
      "Epoch 70/200\n",
      "327/327 [==============================] - 0s 818us/step - loss: 0.0746 - val_loss: 0.0821\n",
      "Epoch 71/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0754 - val_loss: 0.0826\n",
      "Epoch 72/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0736 - val_loss: 0.0810\n",
      "Epoch 73/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0733 - val_loss: 0.0821\n",
      "Epoch 74/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0733 - val_loss: 0.0811\n",
      "Epoch 75/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0743 - val_loss: 0.0818\n",
      "Epoch 76/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0732 - val_loss: 0.0817\n",
      "Epoch 77/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0736 - val_loss: 0.0815\n",
      "Epoch 78/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0733 - val_loss: 0.0807\n",
      "Epoch 79/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0741 - val_loss: 0.0810\n",
      "Epoch 80/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0728 - val_loss: 0.0811\n",
      "Epoch 81/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0715 - val_loss: 0.0821\n",
      "Epoch 82/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0719 - val_loss: 0.0808\n",
      "Epoch 83/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0726 - val_loss: 0.0811\n",
      "Epoch 84/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0719 - val_loss: 0.0818\n",
      "Epoch 85/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.0726 - val_loss: 0.0801\n",
      "Epoch 86/200\n",
      "327/327 [==============================] - 0s 866us/step - loss: 0.0720 - val_loss: 0.0800\n",
      "Epoch 87/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0718 - val_loss: 0.0800\n",
      "Epoch 88/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0710 - val_loss: 0.0802\n",
      "Epoch 89/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0714 - val_loss: 0.0798\n",
      "Epoch 90/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0723 - val_loss: 0.0795\n",
      "Epoch 91/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0717 - val_loss: 0.0796\n",
      "Epoch 92/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0719 - val_loss: 0.0809\n",
      "Epoch 93/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0722 - val_loss: 0.0800\n",
      "Epoch 94/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0705 - val_loss: 0.0803\n",
      "Epoch 95/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0702 - val_loss: 0.0809\n",
      "Epoch 96/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0707 - val_loss: 0.0809\n",
      "Epoch 97/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0716 - val_loss: 0.0808\n",
      "Epoch 98/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0709 - val_loss: 0.0799\n",
      "Epoch 99/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0702 - val_loss: 0.0797\n",
      "Epoch 100/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0704 - val_loss: 0.0810\n",
      "Epoch 00100: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 3.2928 - val_loss: 1.3198\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.8733 - val_loss: 0.1852\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 818us/step - loss: 0.1600 - val_loss: 0.0978\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0888 - val_loss: 0.0813\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 811us/step - loss: 0.0769 - val_loss: 0.0733\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0686 - val_loss: 0.0670\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0631 - val_loss: 0.0623\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0571 - val_loss: 0.0576\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0520 - val_loss: 0.0538\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0491 - val_loss: 0.0505\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0462 - val_loss: 0.0474\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0442 - val_loss: 0.0444\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0406 - val_loss: 0.0421\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0390 - val_loss: 0.0396\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0363 - val_loss: 0.0378\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0346 - val_loss: 0.0359\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0335 - val_loss: 0.0349\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0320 - val_loss: 0.0349\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0305 - val_loss: 0.0330\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0290 - val_loss: 0.0337\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 858us/step - loss: 0.0286 - val_loss: 0.0307\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0276 - val_loss: 0.0309\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0266 - val_loss: 0.0304\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0262 - val_loss: 0.0295\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0256 - val_loss: 0.0299\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.0253 - val_loss: 0.0296\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0251 - val_loss: 0.0284\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0246 - val_loss: 0.0289\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0240 - val_loss: 0.0285\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0235 - val_loss: 0.0282\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0273\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 869us/step - loss: 0.0226 - val_loss: 0.0279\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0222 - val_loss: 0.0271\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0217 - val_loss: 0.0264\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0219 - val_loss: 0.0261\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 885us/step - loss: 0.0215 - val_loss: 0.0261\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0254\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0211 - val_loss: 0.0261\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0207 - val_loss: 0.0255\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 915us/step - loss: 0.0210 - val_loss: 0.0252\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0204 - val_loss: 0.0251\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0198 - val_loss: 0.0248\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.0203 - val_loss: 0.0247\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 847us/step - loss: 0.0199 - val_loss: 0.0244\n",
      "Epoch 45/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 46/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0196 - val_loss: 0.0248\n",
      "Epoch 47/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0191 - val_loss: 0.0238\n",
      "Epoch 48/200\n",
      "327/327 [==============================] - 0s 814us/step - loss: 0.0193 - val_loss: 0.0242\n",
      "Epoch 49/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0190 - val_loss: 0.0247\n",
      "Epoch 50/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0191 - val_loss: 0.0238\n",
      "Epoch 51/200\n",
      "327/327 [==============================] - 0s 816us/step - loss: 0.0188 - val_loss: 0.0238\n",
      "Epoch 52/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0184 - val_loss: 0.0239\n",
      "Epoch 53/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0184 - val_loss: 0.0237\n",
      "Epoch 54/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0182 - val_loss: 0.0243\n",
      "Epoch 55/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 56/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0185 - val_loss: 0.0242\n",
      "Epoch 57/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 58/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0229\n",
      "Epoch 59/200\n",
      "327/327 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0232\n",
      "Epoch 60/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0180 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0181 - val_loss: 0.0234\n",
      "Epoch 62/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0177 - val_loss: 0.0228\n",
      "Epoch 63/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0176 - val_loss: 0.0231\n",
      "Epoch 64/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0174 - val_loss: 0.0228\n",
      "Epoch 65/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0171 - val_loss: 0.0230\n",
      "Epoch 66/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0171 - val_loss: 0.0227\n",
      "Epoch 67/200\n",
      "327/327 [==============================] - 0s 819us/step - loss: 0.0173 - val_loss: 0.0227\n",
      "Epoch 68/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0170 - val_loss: 0.0220\n",
      "Epoch 69/200\n",
      "327/327 [==============================] - 0s 865us/step - loss: 0.0170 - val_loss: 0.0231\n",
      "Epoch 70/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0166 - val_loss: 0.0225\n",
      "Epoch 71/200\n",
      "327/327 [==============================] - 0s 937us/step - loss: 0.0167 - val_loss: 0.0222\n",
      "Epoch 72/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0169 - val_loss: 0.0226\n",
      "Epoch 73/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0169 - val_loss: 0.0223\n",
      "Epoch 74/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0168 - val_loss: 0.0221\n",
      "Epoch 75/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0163 - val_loss: 0.0218\n",
      "Epoch 76/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0166 - val_loss: 0.0225\n",
      "Epoch 77/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0166 - val_loss: 0.0228\n",
      "Epoch 78/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.0165 - val_loss: 0.0228\n",
      "Epoch 79/200\n",
      "327/327 [==============================] - 0s 929us/step - loss: 0.0164 - val_loss: 0.0228\n",
      "Epoch 80/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0163 - val_loss: 0.0221\n",
      "Epoch 81/200\n",
      "327/327 [==============================] - 0s 868us/step - loss: 0.0163 - val_loss: 0.0220\n",
      "Epoch 82/200\n",
      "327/327 [==============================] - 0s 880us/step - loss: 0.0163 - val_loss: 0.0230\n",
      "Epoch 83/200\n",
      "327/327 [==============================] - 0s 872us/step - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 84/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0223\n",
      "Epoch 85/200\n",
      "327/327 [==============================] - 0s 942us/step - loss: 0.0163 - val_loss: 0.0223\n",
      "Epoch 00085: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e995e8d6254da995356bf2845dcff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.0544 - val_loss: 0.0290\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0296 - val_loss: 0.0274\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0269 - val_loss: 0.0231\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0236 - val_loss: 0.0244\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0232 - val_loss: 0.0227\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0216 - val_loss: 0.0232\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0211 - val_loss: 0.0226\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 817us/step - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 818us/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0204 - val_loss: 0.0227\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0197 - val_loss: 0.0221\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0193 - val_loss: 0.0199\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0191 - val_loss: 0.0219\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.0185 - val_loss: 0.0210\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.0182 - val_loss: 0.0211\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 861us/step - loss: 0.0180 - val_loss: 0.0231\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0183 - val_loss: 0.0192\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0174 - val_loss: 0.0213\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0175 - val_loss: 0.0253\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0175 - val_loss: 0.0227\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0176 - val_loss: 0.0219\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0170 - val_loss: 0.0207\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0167 - val_loss: 0.0215\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0165 - val_loss: 0.0227\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 873us/step - loss: 0.0167 - val_loss: 0.0208\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 00032: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.3066 - val_loss: 0.1229\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 862us/step - loss: 0.1180 - val_loss: 0.1077\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 866us/step - loss: 0.1012 - val_loss: 0.1021\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 903us/step - loss: 0.0938 - val_loss: 0.0970\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 819us/step - loss: 0.0895 - val_loss: 0.0939\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0840 - val_loss: 0.0988\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0844 - val_loss: 0.0946\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0802 - val_loss: 0.0880\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.0823 - val_loss: 0.0879\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0810 - val_loss: 0.0884\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0798 - val_loss: 0.0876\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0797 - val_loss: 0.0885\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0780 - val_loss: 0.0848\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0780 - val_loss: 0.0852\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0763 - val_loss: 0.0864\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.0774 - val_loss: 0.0976\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0750 - val_loss: 0.0897\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 866us/step - loss: 0.0763 - val_loss: 0.0868\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 880us/step - loss: 0.0746 - val_loss: 0.0880\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 947us/step - loss: 0.0724 - val_loss: 0.0871\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0724 - val_loss: 0.0868\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0719 - val_loss: 0.0871\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0736 - val_loss: 0.0826\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0736 - val_loss: 0.0853\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0720 - val_loss: 0.0853\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0721 - val_loss: 0.0849\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 873us/step - loss: 0.0708 - val_loss: 0.0835\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0712 - val_loss: 0.0860\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0706 - val_loss: 0.0844\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 856us/step - loss: 0.0703 - val_loss: 0.0862\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0688 - val_loss: 0.0836\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0691 - val_loss: 0.0902\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0691 - val_loss: 0.0815\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0681 - val_loss: 0.0842\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 855us/step - loss: 0.0677 - val_loss: 0.0827\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0681 - val_loss: 0.0891\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0677 - val_loss: 0.0827\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0671 - val_loss: 0.0851\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0670 - val_loss: 0.0836\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0673 - val_loss: 0.0928\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0681 - val_loss: 0.0839\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0656 - val_loss: 0.0835\n",
      "Epoch 43/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0656 - val_loss: 0.0865\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.8384 - val_loss: 0.2303\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 864us/step - loss: 0.2100 - val_loss: 0.1822\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1673 - val_loss: 0.1661\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1535 - val_loss: 0.1468\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.1464 - val_loss: 0.1496\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.1396 - val_loss: 0.1480\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1352 - val_loss: 0.1402\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.1338 - val_loss: 0.1429\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1342 - val_loss: 0.1407\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1298 - val_loss: 0.1399\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.1298 - val_loss: 0.1395\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 943us/step - loss: 0.1288 - val_loss: 0.1347\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1286 - val_loss: 0.1408\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1272 - val_loss: 0.1378\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.1247 - val_loss: 0.1380\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.1241 - val_loss: 0.1355\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1248 - val_loss: 0.1359\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1251 - val_loss: 0.1343\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1197 - val_loss: 0.1325\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.1216 - val_loss: 0.1323\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1195 - val_loss: 0.1370\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.1197 - val_loss: 0.1342\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.1359\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1179 - val_loss: 0.1307\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1202 - val_loss: 0.1382\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.1162 - val_loss: 0.1344\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 864us/step - loss: 0.1188 - val_loss: 0.1363\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1187 - val_loss: 0.1368\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.1169 - val_loss: 0.1341\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1178 - val_loss: 0.1341\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1172 - val_loss: 0.1381\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1168 - val_loss: 0.1365\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1139 - val_loss: 0.1359\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.1143 - val_loss: 0.1314\n",
      "Epoch 00034: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 1.0786 - val_loss: 0.1615\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.1458 - val_loss: 0.1280\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1163 - val_loss: 0.1040\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.1042 - val_loss: 0.0998\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0966 - val_loss: 0.0931\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.0908 - val_loss: 0.0903\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0881 - val_loss: 0.0937\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0867 - val_loss: 0.0864\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0827 - val_loss: 0.0893\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0829 - val_loss: 0.0839\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 874us/step - loss: 0.0818 - val_loss: 0.0828\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0809 - val_loss: 0.0853\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0816 - val_loss: 0.0863\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 855us/step - loss: 0.0802 - val_loss: 0.0855\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 867us/step - loss: 0.0779 - val_loss: 0.0821\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0774 - val_loss: 0.0817\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 858us/step - loss: 0.0760 - val_loss: 0.0795\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0774 - val_loss: 0.0792\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0762 - val_loss: 0.0838\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0824\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0758 - val_loss: 0.0864\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0805\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0813\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0824\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0737 - val_loss: 0.0789\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 866us/step - loss: 0.0728 - val_loss: 0.0811\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0739 - val_loss: 0.0836\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0744 - val_loss: 0.0848\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 899us/step - loss: 0.0714 - val_loss: 0.0824\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 874us/step - loss: 0.0721 - val_loss: 0.0803\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0697 - val_loss: 0.0821\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0709 - val_loss: 0.0804\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 865us/step - loss: 0.0703 - val_loss: 0.0867\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0712 - val_loss: 0.0793\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.0687 - val_loss: 0.0851\n",
      "Epoch 00035: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 1.1343 - val_loss: 0.0622\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 886us/step - loss: 0.0519 - val_loss: 0.0381\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0352 - val_loss: 0.0298\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.0302 - val_loss: 0.0282\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0254 - val_loss: 0.0250\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0243 - val_loss: 0.0267\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0238 - val_loss: 0.0219\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 871us/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0224 - val_loss: 0.0228\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0209 - val_loss: 0.0225\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 0s 851us/step - loss: 0.0209 - val_loss: 0.0224\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0204 - val_loss: 0.0247\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0200 - val_loss: 0.0257\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0204 - val_loss: 0.0230\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0188 - val_loss: 0.0197\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.0193 - val_loss: 0.0203\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 816us/step - loss: 0.0188 - val_loss: 0.0216\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.0189 - val_loss: 0.0207\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0185 - val_loss: 0.0208\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0186 - val_loss: 0.0198\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 873us/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 00026: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556009f5be2847dd83c12d21e2f610b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 2ms/step - loss: 0.0655 - val_loss: 0.0350\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 873us/step - loss: 0.0308 - val_loss: 0.0257\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0253 - val_loss: 0.0239\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0238 - val_loss: 0.0252\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 809us/step - loss: 0.0239 - val_loss: 0.0199\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0227 - val_loss: 0.0312\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0231 - val_loss: 0.0213\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 819us/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 811us/step - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0222 - val_loss: 0.0205\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 817us/step - loss: 0.0225 - val_loss: 0.0209\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 817us/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 822us/step - loss: 0.0228 - val_loss: 0.0224\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0217 - val_loss: 0.0200\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 818us/step - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 00015: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.2095 - val_loss: 0.1029\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 871us/step - loss: 0.1023 - val_loss: 0.0985\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0967 - val_loss: 0.1031\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0964 - val_loss: 0.0872\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0929 - val_loss: 0.0886\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0916 - val_loss: 0.0999\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 815us/step - loss: 0.0898 - val_loss: 0.0881\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0899 - val_loss: 0.0933\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0896 - val_loss: 0.0897\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0919 - val_loss: 0.0923\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0876 - val_loss: 0.0965\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 817us/step - loss: 0.0873 - val_loss: 0.0932\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 812us/step - loss: 0.0843 - val_loss: 0.0943\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0882 - val_loss: 0.0894\n",
      "Epoch 00014: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.3955 - val_loss: 0.1574\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 871us/step - loss: 0.1606 - val_loss: 0.1662\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.1569 - val_loss: 0.1428\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.1462 - val_loss: 0.1487\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1466 - val_loss: 0.1521\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1493 - val_loss: 0.1433\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.1452 - val_loss: 0.1520\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.1473 - val_loss: 0.1387\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.1415 - val_loss: 0.1489\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 932us/step - loss: 0.1454 - val_loss: 0.1417\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 869us/step - loss: 0.1396 - val_loss: 0.1366\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 884us/step - loss: 0.1386 - val_loss: 0.1487\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.1387 - val_loss: 0.1374\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.1362 - val_loss: 0.1375\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1391 - val_loss: 0.1380\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1406 - val_loss: 0.1383\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 926us/step - loss: 0.1359 - val_loss: 0.1390\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 913us/step - loss: 0.1367 - val_loss: 0.1515\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.1364 - val_loss: 0.1323\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1349 - val_loss: 0.1363\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 862us/step - loss: 0.1323 - val_loss: 0.1379\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1355 - val_loss: 0.1325\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 855us/step - loss: 0.1352 - val_loss: 0.1433\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1336 - val_loss: 0.1343\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1339 - val_loss: 0.1344\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1353 - val_loss: 0.1306\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.1325 - val_loss: 0.1352\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.1346 - val_loss: 0.1404\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1339 - val_loss: 0.1328\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.1311 - val_loss: 0.1339\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1322 - val_loss: 0.1341\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.1334 - val_loss: 0.1378\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1340 - val_loss: 0.1329\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.1316 - val_loss: 0.1337\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 875us/step - loss: 0.1309 - val_loss: 0.1332\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.1337 - val_loss: 0.1373\n",
      "Epoch 00036: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.4374 - val_loss: 0.1232\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 876us/step - loss: 0.1160 - val_loss: 0.1147\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.1039 - val_loss: 0.1025\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0978 - val_loss: 0.0891\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0947 - val_loss: 0.1055\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0912 - val_loss: 0.0964\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0937 - val_loss: 0.0889\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0882 - val_loss: 0.0951\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0892 - val_loss: 0.0896\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0886 - val_loss: 0.0888\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0913 - val_loss: 0.0963\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0868 - val_loss: 0.0961\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0879 - val_loss: 0.0846\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0883 - val_loss: 0.0951\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 812us/step - loss: 0.0873 - val_loss: 0.0838\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0855 - val_loss: 0.0846\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.0857 - val_loss: 0.0843\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0873 - val_loss: 0.0843\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0862 - val_loss: 0.0831\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0842 - val_loss: 0.0841\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.0850 - val_loss: 0.0869\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0850 - val_loss: 0.0807\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 824us/step - loss: 0.0853 - val_loss: 0.0873\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0823 - val_loss: 0.0851\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0816 - val_loss: 0.0832\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0841 - val_loss: 0.0871\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0830 - val_loss: 0.0874\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.0820 - val_loss: 0.0855\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0837 - val_loss: 0.0855\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0816 - val_loss: 0.0931\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0815 - val_loss: 0.0802\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 955us/step - loss: 0.0812 - val_loss: 0.0797\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0825 - val_loss: 0.0804\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 860us/step - loss: 0.0809 - val_loss: 0.0855\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.0808 - val_loss: 0.0823\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 841us/step - loss: 0.0805 - val_loss: 0.0880\n",
      "Epoch 37/200\n",
      "327/327 [==============================] - 0s 821us/step - loss: 0.0831 - val_loss: 0.0820\n",
      "Epoch 38/200\n",
      "327/327 [==============================] - 0s 857us/step - loss: 0.0829 - val_loss: 0.0897\n",
      "Epoch 39/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0813 - val_loss: 0.0886\n",
      "Epoch 40/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0822 - val_loss: 0.0813\n",
      "Epoch 41/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.0816 - val_loss: 0.0903\n",
      "Epoch 42/200\n",
      "327/327 [==============================] - 0s 853us/step - loss: 0.0821 - val_loss: 0.0836\n",
      "Epoch 00042: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.2986 - val_loss: 0.0684\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 884us/step - loss: 0.0432 - val_loss: 0.0413\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.0361 - val_loss: 0.0379\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0316 - val_loss: 0.0211\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.0267 - val_loss: 0.0285\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0251 - val_loss: 0.0208\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.0251 - val_loss: 0.0226\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.0230 - val_loss: 0.0217\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0250 - val_loss: 0.0215\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0237 - val_loss: 0.0206\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.0224 - val_loss: 0.0196\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.0227 - val_loss: 0.0206\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 0.0217 - val_loss: 0.0200\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.0220 - val_loss: 0.0231\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.0217 - val_loss: 0.0190\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.0207 - val_loss: 0.0243\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0203 - val_loss: 0.0210\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0209\n",
      "Epoch 25/200\n",
      "327/327 [==============================] - 1s 2ms/step - loss: 0.0206 - val_loss: 0.0196\n",
      "Epoch 26/200\n",
      "327/327 [==============================] - 0s 981us/step - loss: 0.0189 - val_loss: 0.0182\n",
      "Epoch 27/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.0200 - val_loss: 0.0188\n",
      "Epoch 28/200\n",
      "327/327 [==============================] - 0s 865us/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 29/200\n",
      "327/327 [==============================] - 0s 864us/step - loss: 0.0198 - val_loss: 0.0255\n",
      "Epoch 30/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 31/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.0190 - val_loss: 0.0206\n",
      "Epoch 32/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 33/200\n",
      "327/327 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0251\n",
      "Epoch 34/200\n",
      "327/327 [==============================] - 0s 886us/step - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 35/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 36/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.0202 - val_loss: 0.0187\n",
      "Epoch 00036: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2782c20a18946828d2481f3ea66edfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.6602 - val_loss: 0.1834\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.1238 - val_loss: 0.0734\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0536 - val_loss: 0.0535\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.0325 - val_loss: 0.0273\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0335 - val_loss: 1.1145\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 858us/step - loss: 34.7204 - val_loss: 1.7442\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 1.4363 - val_loss: 0.2884\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 862us/step - loss: 0.4644 - val_loss: 0.4127\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.3239 - val_loss: 0.2254\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.2250 - val_loss: 0.3154\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.7044 - val_loss: 7.2789\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 1.6257 - val_loss: 0.3561\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 942us/step - loss: 0.2951 - val_loss: 0.2623\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.1782 - val_loss: 0.1147\n",
      "Epoch 00014: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.5431 - val_loss: 0.1104\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 873us/step - loss: 0.1276 - val_loss: 0.2729\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 5.1854 - val_loss: 0.2934\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 818us/step - loss: 0.1946 - val_loss: 0.1106\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1394 - val_loss: 0.1118\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 815us/step - loss: 0.1270 - val_loss: 0.1142\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 844us/step - loss: 0.1472 - val_loss: 0.1268\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 829us/step - loss: 0.1589 - val_loss: 0.1341\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 0.1416 - val_loss: 0.1429\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1364 - val_loss: 0.1072\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 0.1375 - val_loss: 0.1248\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.1581 - val_loss: 0.1436\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.1309 - val_loss: 0.1293\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1205 - val_loss: 0.1045\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 1.0416 - val_loss: 6.9961\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 6.7863 - val_loss: 0.3817\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.2410 - val_loss: 0.1844\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 851us/step - loss: 0.1644 - val_loss: 0.1884\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 849us/step - loss: 0.2272 - val_loss: 0.1328\n",
      "Epoch 20/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.1368 - val_loss: 0.1078\n",
      "Epoch 21/200\n",
      "327/327 [==============================] - 0s 859us/step - loss: 1.4317 - val_loss: 0.1756\n",
      "Epoch 22/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.1373 - val_loss: 0.1253\n",
      "Epoch 23/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.1210 - val_loss: 0.1362\n",
      "Epoch 24/200\n",
      "327/327 [==============================] - 0s 847us/step - loss: 0.1287 - val_loss: 0.3054\n",
      "Epoch 00024: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.6653 - val_loss: 0.1726\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1993 - val_loss: 0.4956\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.6188 - val_loss: 0.2004\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 850us/step - loss: 0.2020 - val_loss: 0.1784\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1917 - val_loss: 0.2181\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 837us/step - loss: 0.2501 - val_loss: 0.3216\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 0.3613 - val_loss: 0.2328\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 843us/step - loss: 0.3601 - val_loss: 0.3157\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.3126 - val_loss: 0.4083\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 823us/step - loss: 0.3032 - val_loss: 0.2799\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 931us/step - loss: 0.2270 - val_loss: 0.2994\n",
      "Epoch 00011: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.6475 - val_loss: 0.1087\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 868us/step - loss: 0.1259 - val_loss: 0.2233\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 3.6714 - val_loss: 0.5882\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 848us/step - loss: 0.2800 - val_loss: 0.1424\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1558 - val_loss: 0.0961\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1215 - val_loss: 0.1075\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 852us/step - loss: 0.1105 - val_loss: 0.1137\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.1274 - val_loss: 0.1140\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.1357 - val_loss: 0.0895\n",
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.1126 - val_loss: 0.2779\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 838us/step - loss: 0.2423 - val_loss: 0.1063\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 832us/step - loss: 0.1119 - val_loss: 0.1055\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 820us/step - loss: 0.1061 - val_loss: 0.1009\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 836us/step - loss: 0.1229 - val_loss: 0.1247\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 846us/step - loss: 0.4905 - val_loss: 18.0281\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 8.2019 - val_loss: 0.2784\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.2397 - val_loss: 0.1166\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 833us/step - loss: 0.1506 - val_loss: 0.1023\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 845us/step - loss: 0.1159 - val_loss: 0.1390\n",
      "Epoch 00019: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "327/327 [==============================] - 1s 1ms/step - loss: 0.6522 - val_loss: 0.0604\n",
      "Epoch 2/200\n",
      "327/327 [==============================] - 0s 912us/step - loss: 1.9513 - val_loss: 2.8849\n",
      "Epoch 3/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 1.6719 - val_loss: 0.3874\n",
      "Epoch 4/200\n",
      "327/327 [==============================] - 0s 839us/step - loss: 0.2224 - val_loss: 0.0941\n",
      "Epoch 5/200\n",
      "327/327 [==============================] - 0s 842us/step - loss: 0.5530 - val_loss: 1.0989\n",
      "Epoch 6/200\n",
      "327/327 [==============================] - 0s 858us/step - loss: 0.6146 - val_loss: 0.1002\n",
      "Epoch 7/200\n",
      "327/327 [==============================] - 0s 840us/step - loss: 0.0921 - val_loss: 0.0744\n",
      "Epoch 8/200\n",
      "327/327 [==============================] - 0s 835us/step - loss: 0.0814 - val_loss: 0.0427\n",
      "Epoch 9/200\n",
      "327/327 [==============================] - 0s 834us/step - loss: 0.0735 - val_loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "327/327 [==============================] - 0s 817us/step - loss: 0.0402 - val_loss: 0.0280\n",
      "Epoch 11/200\n",
      "327/327 [==============================] - 0s 863us/step - loss: 0.0596 - val_loss: 0.0414\n",
      "Epoch 12/200\n",
      "327/327 [==============================] - 0s 827us/step - loss: 4.2828 - val_loss: 17.4703\n",
      "Epoch 13/200\n",
      "327/327 [==============================] - 0s 830us/step - loss: 6.0651 - val_loss: 1.0887\n",
      "Epoch 14/200\n",
      "327/327 [==============================] - 0s 825us/step - loss: 0.9469 - val_loss: 0.3176\n",
      "Epoch 15/200\n",
      "327/327 [==============================] - 0s 826us/step - loss: 0.3519 - val_loss: 0.1621\n",
      "Epoch 16/200\n",
      "327/327 [==============================] - 0s 828us/step - loss: 0.2440 - val_loss: 0.6343\n",
      "Epoch 17/200\n",
      "327/327 [==============================] - 0s 831us/step - loss: 2.5895 - val_loss: 1.1716\n",
      "Epoch 18/200\n",
      "327/327 [==============================] - 0s 854us/step - loss: 0.3707 - val_loss: 0.1109\n",
      "Epoch 19/200\n",
      "327/327 [==============================] - 0s 819us/step - loss: 1.9893 - val_loss: 14.7786\n",
      "Epoch 00019: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e6555ed1e54e72a8ebda4cc2ab5f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6636df86349347a39975fcd7e98c3f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868918ef2bb94f81a620e31805ef138b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.0711 - val_loss: 0.0575\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1000us/step - loss: 0.0577 - val_loss: 0.0494\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 952us/step - loss: 0.0490 - val_loss: 0.0437\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.0433 - val_loss: 0.0414\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 947us/step - loss: 0.0389 - val_loss: 0.0385\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.0358 - val_loss: 0.0369\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 942us/step - loss: 0.0333 - val_loss: 0.0351\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 946us/step - loss: 0.0321 - val_loss: 0.0339\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.0305 - val_loss: 0.0326\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.0304 - val_loss: 0.0335\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 963us/step - loss: 0.0292 - val_loss: 0.0316\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 932us/step - loss: 0.0284 - val_loss: 0.0309\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 977us/step - loss: 0.0278 - val_loss: 0.0304\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 965us/step - loss: 0.0271 - val_loss: 0.0303\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.0269 - val_loss: 0.0300\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.0260 - val_loss: 0.0294\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 984us/step - loss: 0.0255 - val_loss: 0.0284\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 966us/step - loss: 0.0247 - val_loss: 0.0276\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.0247 - val_loss: 0.0275\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.0240 - val_loss: 0.0273\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 948us/step - loss: 0.0240 - val_loss: 0.0279\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 981us/step - loss: 0.0237 - val_loss: 0.0279\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.0235 - val_loss: 0.0269\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 974us/step - loss: 0.0229 - val_loss: 0.0264\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 970us/step - loss: 0.0224 - val_loss: 0.0263\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 956us/step - loss: 0.0222 - val_loss: 0.0273\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 986us/step - loss: 0.0220 - val_loss: 0.0259\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 973us/step - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 965us/step - loss: 0.0213 - val_loss: 0.0257\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.0212 - val_loss: 0.0252\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.0213 - val_loss: 0.0253\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 953us/step - loss: 0.0209 - val_loss: 0.0251\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 970us/step - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0245\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0253\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0248\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 990us/step - loss: 0.0199 - val_loss: 0.0252\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.0199 - val_loss: 0.0253\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0198 - val_loss: 0.0243\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 957us/step - loss: 0.0196 - val_loss: 0.0238\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 959us/step - loss: 0.0197 - val_loss: 0.0249\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0243\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0244\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.0192 - val_loss: 0.0241\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0245\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 975us/step - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.0182 - val_loss: 0.0239\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 993us/step - loss: 0.0191 - val_loss: 0.0237\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 974us/step - loss: 0.0184 - val_loss: 0.0231\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 974us/step - loss: 0.0187 - val_loss: 0.0234\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 966us/step - loss: 0.0184 - val_loss: 0.0245\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0237\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 980us/step - loss: 0.0183 - val_loss: 0.0246\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 981us/step - loss: 0.0182 - val_loss: 0.0234\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.0179 - val_loss: 0.0242\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 987us/step - loss: 0.0177 - val_loss: 0.0236\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.0179 - val_loss: 0.0248\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.0178 - val_loss: 0.0242\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0237\n",
      "Epoch 00063: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.5680 - val_loss: 0.4096\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3610 - val_loss: 0.2514\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2480 - val_loss: 0.1966\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 995us/step - loss: 0.1990 - val_loss: 0.1737\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 998us/step - loss: 0.1800 - val_loss: 0.1635\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 998us/step - loss: 0.1679 - val_loss: 0.1573\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1590 - val_loss: 0.1548\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 994us/step - loss: 0.1510 - val_loss: 0.1480\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 997us/step - loss: 0.1452 - val_loss: 0.1445\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1414 - val_loss: 0.1393\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 992us/step - loss: 0.1360 - val_loss: 0.1373\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1282 - val_loss: 0.1331\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1270 - val_loss: 0.1312\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 984us/step - loss: 0.1223 - val_loss: 0.1280\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 996us/step - loss: 0.1180 - val_loss: 0.1256\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.1155 - val_loss: 0.1225\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 979us/step - loss: 0.1135 - val_loss: 0.1236\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.1106 - val_loss: 0.1175\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 979us/step - loss: 0.1070 - val_loss: 0.1181\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 952us/step - loss: 0.1067 - val_loss: 0.1159\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 966us/step - loss: 0.1046 - val_loss: 0.1138\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 986us/step - loss: 0.1030 - val_loss: 0.1125\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 950us/step - loss: 0.1017 - val_loss: 0.1133\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 961us/step - loss: 0.1005 - val_loss: 0.1108\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 975us/step - loss: 0.0982 - val_loss: 0.1100\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 973us/step - loss: 0.0992 - val_loss: 0.1084\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.0986 - val_loss: 0.1076\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 992us/step - loss: 0.0963 - val_loss: 0.1082\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.0948 - val_loss: 0.1049\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.0941 - val_loss: 0.1047\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 956us/step - loss: 0.0929 - val_loss: 0.1035\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 0.0924 - val_loss: 0.1041\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 959us/step - loss: 0.0912 - val_loss: 0.1026\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 956us/step - loss: 0.0908 - val_loss: 0.1022\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 937us/step - loss: 0.0910 - val_loss: 0.1012\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.0884 - val_loss: 0.1004\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 953us/step - loss: 0.0902 - val_loss: 0.1009\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.0886 - val_loss: 0.1006\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.0880 - val_loss: 0.1002\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 976us/step - loss: 0.0891 - val_loss: 0.0993\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0866 - val_loss: 0.0985\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0988\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.0870 - val_loss: 0.0995\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 994us/step - loss: 0.0849 - val_loss: 0.0974\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 999us/step - loss: 0.0841 - val_loss: 0.0981\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 980us/step - loss: 0.0842 - val_loss: 0.0972\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 949us/step - loss: 0.0846 - val_loss: 0.0975\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 938us/step - loss: 0.0844 - val_loss: 0.0966\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.0838 - val_loss: 0.0959\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.0822 - val_loss: 0.0962\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.0830 - val_loss: 0.0969\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 975us/step - loss: 0.0818 - val_loss: 0.0970\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0961\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0963\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 992us/step - loss: 0.0817 - val_loss: 0.0949\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0961\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0947\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0943\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 997us/step - loss: 0.0821 - val_loss: 0.0945\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 996us/step - loss: 0.0802 - val_loss: 0.0947\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0942\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 998us/step - loss: 0.0811 - val_loss: 0.0939\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 952us/step - loss: 0.0805 - val_loss: 0.0934\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 0s 993us/step - loss: 0.0789 - val_loss: 0.0930\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0947\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0926\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0938\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.0797 - val_loss: 0.0940\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 0s 944us/step - loss: 0.0786 - val_loss: 0.0939\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 0s 980us/step - loss: 0.0797 - val_loss: 0.0921\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0927\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 0s 997us/step - loss: 0.0787 - val_loss: 0.0932\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 0s 993us/step - loss: 0.0790 - val_loss: 0.0939\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 0s 999us/step - loss: 0.0769 - val_loss: 0.0929\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 0s 990us/step - loss: 0.0788 - val_loss: 0.0925\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0778 - val_loss: 0.0922\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 0s 992us/step - loss: 0.0785 - val_loss: 0.0927\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.0784 - val_loss: 0.0924\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 0s 990us/step - loss: 0.0784 - val_loss: 0.0934\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 0s 948us/step - loss: 0.0781 - val_loss: 0.0929\n",
      "Epoch 00080: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 1.7727 - val_loss: 1.0074\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.8821 - val_loss: 0.5310\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 995us/step - loss: 0.5303 - val_loss: 0.4145\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 968us/step - loss: 0.4075 - val_loss: 0.3562\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 968us/step - loss: 0.3512 - val_loss: 0.3221\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 986us/step - loss: 0.3212 - val_loss: 0.2972\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.2909 - val_loss: 0.2818\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.2771 - val_loss: 0.2661\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2605 - val_loss: 0.2546\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 976us/step - loss: 0.2468 - val_loss: 0.2400\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 991us/step - loss: 0.2355 - val_loss: 0.2318\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 990us/step - loss: 0.2267 - val_loss: 0.2223\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 982us/step - loss: 0.2189 - val_loss: 0.2147\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 980us/step - loss: 0.2106 - val_loss: 0.2076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 970us/step - loss: 0.2002 - val_loss: 0.2020\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 968us/step - loss: 0.1945 - val_loss: 0.1951\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 972us/step - loss: 0.1908 - val_loss: 0.1897\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 984us/step - loss: 0.1850 - val_loss: 0.1850\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1818 - val_loss: 0.1786\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 992us/step - loss: 0.1769 - val_loss: 0.1759\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 951us/step - loss: 0.1692 - val_loss: 0.1726\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 980us/step - loss: 0.1679 - val_loss: 0.1688\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 968us/step - loss: 0.1678 - val_loss: 0.1674\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 962us/step - loss: 0.1615 - val_loss: 0.1644\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.1610 - val_loss: 0.1625\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.1594 - val_loss: 0.1608\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.1550 - val_loss: 0.1578\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 975us/step - loss: 0.1566 - val_loss: 0.1570\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 966us/step - loss: 0.1520 - val_loss: 0.1551\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.1488 - val_loss: 0.1549\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1486 - val_loss: 0.1531\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.1491 - val_loss: 0.1514\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 961us/step - loss: 0.1436 - val_loss: 0.1508\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.1441 - val_loss: 0.1495\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 981us/step - loss: 0.1450 - val_loss: 0.1488\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 995us/step - loss: 0.1448 - val_loss: 0.1470\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 982us/step - loss: 0.1413 - val_loss: 0.1465\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 971us/step - loss: 0.1435 - val_loss: 0.1454\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 944us/step - loss: 0.1401 - val_loss: 0.1453\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1384 - val_loss: 0.1461\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1402 - val_loss: 0.1444\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 0.1398 - val_loss: 0.1438\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.1349 - val_loss: 0.1441\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 957us/step - loss: 0.1382 - val_loss: 0.1441\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 950us/step - loss: 0.1347 - val_loss: 0.1425\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 961us/step - loss: 0.1375 - val_loss: 0.1425\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.1367 - val_loss: 0.1411\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1363 - val_loss: 0.1411\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.1333 - val_loss: 0.1413\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 942us/step - loss: 0.1337 - val_loss: 0.1414\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.1363 - val_loss: 0.1418\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.1337 - val_loss: 0.1409\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 957us/step - loss: 0.1331 - val_loss: 0.1400\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 970us/step - loss: 0.1329 - val_loss: 0.1394\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.1326 - val_loss: 0.1402\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 989us/step - loss: 0.1342 - val_loss: 0.1405\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 971us/step - loss: 0.1360 - val_loss: 0.1403\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.1309 - val_loss: 0.1402\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1305 - val_loss: 0.1397\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 970us/step - loss: 0.1305 - val_loss: 0.1384\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.1298 - val_loss: 0.1393\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 994us/step - loss: 0.1301 - val_loss: 0.1392\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 977us/step - loss: 0.1269 - val_loss: 0.1388\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.1291 - val_loss: 0.1401\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 0s 972us/step - loss: 0.1304 - val_loss: 0.1380\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.1303 - val_loss: 0.1390\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.1283 - val_loss: 0.1390\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 0s 993us/step - loss: 0.1279 - val_loss: 0.1381\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 0s 971us/step - loss: 0.1284 - val_loss: 0.1386\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 0s 977us/step - loss: 0.1289 - val_loss: 0.1386\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 0s 974us/step - loss: 0.1284 - val_loss: 0.1387\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1267 - val_loss: 0.1371\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1361\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1264 - val_loss: 0.1375\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1273 - val_loss: 0.1368\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1271 - val_loss: 0.1374\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 0s 973us/step - loss: 0.1275 - val_loss: 0.1374\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.1258 - val_loss: 0.1371\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.1275 - val_loss: 0.1372\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.1265 - val_loss: 0.1373\n",
      "Epoch 81/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.1238 - val_loss: 0.1379\n",
      "Epoch 82/200\n",
      "164/164 [==============================] - 0s 983us/step - loss: 0.1240 - val_loss: 0.1361\n",
      "Epoch 83/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.1239 - val_loss: 0.1359\n",
      "Epoch 84/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 0.1250 - val_loss: 0.1369\n",
      "Epoch 85/200\n",
      "164/164 [==============================] - 0s 880us/step - loss: 0.1229 - val_loss: 0.1368\n",
      "Epoch 86/200\n",
      "164/164 [==============================] - 0s 896us/step - loss: 0.1249 - val_loss: 0.1355\n",
      "Epoch 87/200\n",
      "164/164 [==============================] - 0s 920us/step - loss: 0.1245 - val_loss: 0.1367\n",
      "Epoch 88/200\n",
      "164/164 [==============================] - 0s 904us/step - loss: 0.1264 - val_loss: 0.1357\n",
      "Epoch 89/200\n",
      "164/164 [==============================] - 0s 883us/step - loss: 0.1253 - val_loss: 0.1360\n",
      "Epoch 90/200\n",
      "164/164 [==============================] - 0s 887us/step - loss: 0.1246 - val_loss: 0.1374\n",
      "Epoch 91/200\n",
      "164/164 [==============================] - 0s 893us/step - loss: 0.1230 - val_loss: 0.1360\n",
      "Epoch 92/200\n",
      "164/164 [==============================] - 0s 882us/step - loss: 0.1242 - val_loss: 0.1363\n",
      "Epoch 93/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.1215 - val_loss: 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "164/164 [==============================] - 0s 952us/step - loss: 0.1232 - val_loss: 0.1353\n",
      "Epoch 95/200\n",
      "164/164 [==============================] - 0s 909us/step - loss: 0.1234 - val_loss: 0.1344\n",
      "Epoch 96/200\n",
      "164/164 [==============================] - 0s 900us/step - loss: 0.1237 - val_loss: 0.1350\n",
      "Epoch 97/200\n",
      "164/164 [==============================] - 0s 898us/step - loss: 0.1217 - val_loss: 0.1375\n",
      "Epoch 98/200\n",
      "164/164 [==============================] - 0s 906us/step - loss: 0.1210 - val_loss: 0.1359\n",
      "Epoch 99/200\n",
      "164/164 [==============================] - 0s 878us/step - loss: 0.1214 - val_loss: 0.1351\n",
      "Epoch 100/200\n",
      "164/164 [==============================] - 0s 876us/step - loss: 0.1219 - val_loss: 0.1360\n",
      "Epoch 101/200\n",
      "164/164 [==============================] - 0s 898us/step - loss: 0.1213 - val_loss: 0.1364\n",
      "Epoch 102/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.1194 - val_loss: 0.1362\n",
      "Epoch 103/200\n",
      "164/164 [==============================] - 0s 900us/step - loss: 0.1232 - val_loss: 0.1356\n",
      "Epoch 104/200\n",
      "164/164 [==============================] - 0s 920us/step - loss: 0.1194 - val_loss: 0.1350\n",
      "Epoch 105/200\n",
      "164/164 [==============================] - 0s 919us/step - loss: 0.1200 - val_loss: 0.1360\n",
      "Epoch 00105: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2.9772 - val_loss: 2.0586\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 1.7059 - val_loss: 0.8859\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 928us/step - loss: 0.7556 - val_loss: 0.4429\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 953us/step - loss: 0.4387 - val_loss: 0.3482\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 935us/step - loss: 0.3477 - val_loss: 0.3051\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 945us/step - loss: 0.2982 - val_loss: 0.2711\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 931us/step - loss: 0.2698 - val_loss: 0.2454\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 929us/step - loss: 0.2368 - val_loss: 0.2246\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 957us/step - loss: 0.2215 - val_loss: 0.2073\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 948us/step - loss: 0.2010 - val_loss: 0.1919\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 934us/step - loss: 0.1913 - val_loss: 0.1817\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 923us/step - loss: 0.1776 - val_loss: 0.1727\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 948us/step - loss: 0.1720 - val_loss: 0.1661\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.1662 - val_loss: 0.1606\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 939us/step - loss: 0.1573 - val_loss: 0.1544\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 935us/step - loss: 0.1532 - val_loss: 0.1493\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 951us/step - loss: 0.1496 - val_loss: 0.1466\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 929us/step - loss: 0.1415 - val_loss: 0.1412\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 928us/step - loss: 0.1418 - val_loss: 0.1371\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 953us/step - loss: 0.1330 - val_loss: 0.1346\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 937us/step - loss: 0.1297 - val_loss: 0.1311\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 944us/step - loss: 0.1263 - val_loss: 0.1270\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 951us/step - loss: 0.1237 - val_loss: 0.1237\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 934us/step - loss: 0.1211 - val_loss: 0.1214\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 942us/step - loss: 0.1197 - val_loss: 0.1200\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 946us/step - loss: 0.1158 - val_loss: 0.1168\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 929us/step - loss: 0.1130 - val_loss: 0.1144\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1120 - val_loss: 0.1123\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 960us/step - loss: 0.1095 - val_loss: 0.1095\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 973us/step - loss: 0.1075 - val_loss: 0.1075\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.1068 - val_loss: 0.1067\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1039 - val_loss: 0.1043\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1045 - val_loss: 0.1029\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1024 - val_loss: 0.1022\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0999 - val_loss: 0.1007\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0986 - val_loss: 0.0986\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0982 - val_loss: 0.0990\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0955 - val_loss: 0.0977\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.0958 - val_loss: 0.0971\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 944us/step - loss: 0.0942 - val_loss: 0.0956\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 946us/step - loss: 0.0922 - val_loss: 0.0955\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 965us/step - loss: 0.0939 - val_loss: 0.0948\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.0929 - val_loss: 0.0937\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 955us/step - loss: 0.0912 - val_loss: 0.0937\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.0898 - val_loss: 0.0935\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 950us/step - loss: 0.0895 - val_loss: 0.0926\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 977us/step - loss: 0.0895 - val_loss: 0.0922\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 957us/step - loss: 0.0890 - val_loss: 0.0924\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 949us/step - loss: 0.0899 - val_loss: 0.0914\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 951us/step - loss: 0.0873 - val_loss: 0.0919\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.0861 - val_loss: 0.0913\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 959us/step - loss: 0.0863 - val_loss: 0.0909\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 981us/step - loss: 0.0859 - val_loss: 0.0899\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 948us/step - loss: 0.0844 - val_loss: 0.0903\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 965us/step - loss: 0.0842 - val_loss: 0.0900\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 965us/step - loss: 0.0853 - val_loss: 0.0900\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 931us/step - loss: 0.0846 - val_loss: 0.0894\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 939us/step - loss: 0.0827 - val_loss: 0.0887\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 945us/step - loss: 0.0835 - val_loss: 0.0889\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 984us/step - loss: 0.0837 - val_loss: 0.0894\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 902us/step - loss: 0.0820 - val_loss: 0.0886\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 909us/step - loss: 0.0827 - val_loss: 0.0889\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 907us/step - loss: 0.0826 - val_loss: 0.0878\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 0s 905us/step - loss: 0.0827 - val_loss: 0.0878\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 0s 897us/step - loss: 0.0814 - val_loss: 0.0881\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 0s 907us/step - loss: 0.0807 - val_loss: 0.0877\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 0s 924us/step - loss: 0.0804 - val_loss: 0.0870\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 0s 907us/step - loss: 0.0803 - val_loss: 0.0870\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.0802 - val_loss: 0.0878\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 0s 911us/step - loss: 0.0806 - val_loss: 0.0864\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 0s 899us/step - loss: 0.0809 - val_loss: 0.0868\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 0s 880us/step - loss: 0.0803 - val_loss: 0.0868\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 0s 903us/step - loss: 0.0804 - val_loss: 0.0860\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 0s 935us/step - loss: 0.0802 - val_loss: 0.0860\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 0s 894us/step - loss: 0.0801 - val_loss: 0.0864\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 0s 891us/step - loss: 0.0795 - val_loss: 0.0858\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 0s 891us/step - loss: 0.0786 - val_loss: 0.0862\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 0s 907us/step - loss: 0.0778 - val_loss: 0.0859\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 0s 888us/step - loss: 0.0787 - val_loss: 0.0855\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 0s 883us/step - loss: 0.0773 - val_loss: 0.0864\n",
      "Epoch 81/200\n",
      "164/164 [==============================] - 0s 895us/step - loss: 0.0774 - val_loss: 0.0855\n",
      "Epoch 82/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.0778 - val_loss: 0.0858\n",
      "Epoch 83/200\n",
      "164/164 [==============================] - 0s 886us/step - loss: 0.0776 - val_loss: 0.0853\n",
      "Epoch 84/200\n",
      "164/164 [==============================] - 0s 899us/step - loss: 0.0765 - val_loss: 0.0849\n",
      "Epoch 85/200\n",
      "164/164 [==============================] - 0s 909us/step - loss: 0.0771 - val_loss: 0.0851\n",
      "Epoch 86/200\n",
      "164/164 [==============================] - 0s 926us/step - loss: 0.0777 - val_loss: 0.0841\n",
      "Epoch 87/200\n",
      "164/164 [==============================] - 0s 883us/step - loss: 0.0785 - val_loss: 0.0845\n",
      "Epoch 88/200\n",
      "164/164 [==============================] - 0s 899us/step - loss: 0.0780 - val_loss: 0.0844\n",
      "Epoch 89/200\n",
      "164/164 [==============================] - 0s 895us/step - loss: 0.0778 - val_loss: 0.0847\n",
      "Epoch 90/200\n",
      "164/164 [==============================] - 0s 908us/step - loss: 0.0765 - val_loss: 0.0844\n",
      "Epoch 91/200\n",
      "164/164 [==============================] - 0s 922us/step - loss: 0.0769 - val_loss: 0.0851\n",
      "Epoch 92/200\n",
      "164/164 [==============================] - 0s 928us/step - loss: 0.0764 - val_loss: 0.0843\n",
      "Epoch 93/200\n",
      "164/164 [==============================] - 0s 894us/step - loss: 0.0769 - val_loss: 0.0843\n",
      "Epoch 94/200\n",
      "164/164 [==============================] - 0s 887us/step - loss: 0.0752 - val_loss: 0.0848\n",
      "Epoch 95/200\n",
      "164/164 [==============================] - 0s 927us/step - loss: 0.0755 - val_loss: 0.0836\n",
      "Epoch 96/200\n",
      "164/164 [==============================] - 0s 899us/step - loss: 0.0748 - val_loss: 0.0841\n",
      "Epoch 97/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0839\n",
      "Epoch 98/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0841\n",
      "Epoch 99/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0835\n",
      "Epoch 100/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0841\n",
      "Epoch 101/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0839\n",
      "Epoch 102/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0834\n",
      "Epoch 103/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0826\n",
      "Epoch 104/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0835\n",
      "Epoch 105/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0834\n",
      "Epoch 106/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0829\n",
      "Epoch 107/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0829\n",
      "Epoch 108/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0831\n",
      "Epoch 109/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0829\n",
      "Epoch 110/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0747 - val_loss: 0.0832\n",
      "Epoch 111/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0827\n",
      "Epoch 112/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0740 - val_loss: 0.0827\n",
      "Epoch 113/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0821\n",
      "Epoch 114/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0824\n",
      "Epoch 115/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0831\n",
      "Epoch 116/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0818\n",
      "Epoch 117/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0829\n",
      "Epoch 118/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0820\n",
      "Epoch 119/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0741 - val_loss: 0.0829\n",
      "Epoch 120/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0831\n",
      "Epoch 121/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0820\n",
      "Epoch 122/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0820\n",
      "Epoch 123/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0823\n",
      "Epoch 124/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0730 - val_loss: 0.0827\n",
      "Epoch 125/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0815\n",
      "Epoch 126/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0822\n",
      "Epoch 127/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0828\n",
      "Epoch 128/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0825\n",
      "Epoch 129/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0823\n",
      "Epoch 130/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0827\n",
      "Epoch 131/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0818\n",
      "Epoch 132/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0822\n",
      "Epoch 133/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0815\n",
      "Epoch 134/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0823\n",
      "Epoch 135/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0819\n",
      "Epoch 00135: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 3.3403 - val_loss: 2.1194\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1.6692 - val_loss: 0.5719\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.1823\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1553 - val_loss: 0.1093\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0968 - val_loss: 0.0893\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0803\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0744 - val_loss: 0.0750\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0709\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0674\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0645\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0623\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0603\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0577\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0545 - val_loss: 0.0559\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0523 - val_loss: 0.0535\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0514\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0493\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0469\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0454\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0447\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0435\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0421\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0405\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0395\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0382 - val_loss: 0.0386\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0369 - val_loss: 0.0377\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0350 - val_loss: 0.0371\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0352 - val_loss: 0.0359\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0339 - val_loss: 0.0356\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0328 - val_loss: 0.0352\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0339\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0344\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0302 - val_loss: 0.0332\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0293 - val_loss: 0.0332\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0291 - val_loss: 0.0337\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0288 - val_loss: 0.0318\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0325\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0276 - val_loss: 0.0315\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0274 - val_loss: 0.0306\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0270 - val_loss: 0.0312\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.0306\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0255 - val_loss: 0.0302\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0300\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0300\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0253 - val_loss: 0.0295\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0290\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0287\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0236 - val_loss: 0.0285\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0237 - val_loss: 0.0283\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0279\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0274\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0277\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0269\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0272\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0263\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0266\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0258\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0250\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0248\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0257\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0250\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0251\n",
      "Epoch 64/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0238\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0242\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0236\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0238\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0235\n",
      "Epoch 69/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0241\n",
      "Epoch 70/200\n",
      "164/164 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0238\n",
      "Epoch 71/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 72/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0236\n",
      "Epoch 73/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0235\n",
      "Epoch 74/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0227\n",
      "Epoch 75/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0224\n",
      "Epoch 76/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0236\n",
      "Epoch 77/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0221\n",
      "Epoch 78/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0233\n",
      "Epoch 79/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 80/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0224\n",
      "Epoch 81/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0226\n",
      "Epoch 82/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0224\n",
      "Epoch 83/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0222\n",
      "Epoch 84/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0218\n",
      "Epoch 85/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0220\n",
      "Epoch 86/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 87/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0223\n",
      "Epoch 88/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 89/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0226\n",
      "Epoch 90/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0216\n",
      "Epoch 91/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0205\n",
      "Epoch 92/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0212\n",
      "Epoch 93/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0213\n",
      "Epoch 94/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0212\n",
      "Epoch 95/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0208\n",
      "Epoch 96/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0217\n",
      "Epoch 97/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0220\n",
      "Epoch 98/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0213\n",
      "Epoch 99/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 100/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0218\n",
      "Epoch 101/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 102/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0212\n",
      "Epoch 103/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0218\n",
      "Epoch 104/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0210\n",
      "Epoch 105/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0212\n",
      "Epoch 106/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0211\n",
      "Epoch 107/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0208\n",
      "Epoch 108/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0215\n",
      "Epoch 109/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 00109: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f615cb95a74b0eb0ed23057c93c371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.0586 - val_loss: 0.0341\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0318 - val_loss: 0.0271\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0257\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0232\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0219\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0216\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0223\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0201\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0218\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0215\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0219\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0210\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0219\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0232\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 00022: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.3607 - val_loss: 0.1480\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1338 - val_loss: 0.1133\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1100 - val_loss: 0.1025\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1004 - val_loss: 0.1015\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0983\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0908 - val_loss: 0.0958\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0923\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0875\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0883\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0814 - val_loss: 0.0910\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0870\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0906\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0793 - val_loss: 0.0909\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0852\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0872\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0866\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0883\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0855\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0836\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0867\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0854\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0846\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0883\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0860\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0862\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0879\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0847\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0874\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0878\n",
      "Epoch 00029: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.9613 - val_loss: 0.2572\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2375 - val_loss: 0.2048\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1753\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1632\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 974us/step - loss: 0.1531 - val_loss: 0.1565\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 959us/step - loss: 0.1498 - val_loss: 0.1512\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 941us/step - loss: 0.1437 - val_loss: 0.1472\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 921us/step - loss: 0.1385 - val_loss: 0.1512\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 946us/step - loss: 0.1350 - val_loss: 0.1430\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.1350 - val_loss: 0.1416\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 869us/step - loss: 0.1312 - val_loss: 0.1391\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 919us/step - loss: 0.1307 - val_loss: 0.1390\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 929us/step - loss: 0.1265 - val_loss: 0.1412\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 884us/step - loss: 0.1301 - val_loss: 0.1370\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 875us/step - loss: 0.1267 - val_loss: 0.1378\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 871us/step - loss: 0.1295 - val_loss: 0.1379\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 916us/step - loss: 0.1255 - val_loss: 0.1358\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 899us/step - loss: 0.1269 - val_loss: 0.1360\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 885us/step - loss: 0.1232 - val_loss: 0.1333\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 903us/step - loss: 0.1244 - val_loss: 0.1349\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 905us/step - loss: 0.1232 - val_loss: 0.1326\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 911us/step - loss: 0.1210 - val_loss: 0.1321\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 898us/step - loss: 0.1190 - val_loss: 0.1362\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 880us/step - loss: 0.1220 - val_loss: 0.1334\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 882us/step - loss: 0.1202 - val_loss: 0.1308\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 868us/step - loss: 0.1206 - val_loss: 0.1351\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 990us/step - loss: 0.1208 - val_loss: 0.1331\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 909us/step - loss: 0.1191 - val_loss: 0.1339\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 966us/step - loss: 0.1171 - val_loss: 0.1333\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 890us/step - loss: 0.1177 - val_loss: 0.1379\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 978us/step - loss: 0.1169 - val_loss: 0.1340\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.1199 - val_loss: 0.1326\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 876us/step - loss: 0.1197 - val_loss: 0.1308\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 997us/step - loss: 0.1140 - val_loss: 0.1349\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 869us/step - loss: 0.1172 - val_loss: 0.1357\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 874us/step - loss: 0.1147 - val_loss: 0.1310\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 881us/step - loss: 0.1147 - val_loss: 0.1313\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 918us/step - loss: 0.1135 - val_loss: 0.1383\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 909us/step - loss: 0.1153 - val_loss: 0.1317\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 877us/step - loss: 0.1150 - val_loss: 0.1326\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 874us/step - loss: 0.1160 - val_loss: 0.1310\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 873us/step - loss: 0.1121 - val_loss: 0.1376\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 874us/step - loss: 0.1151 - val_loss: 0.1313\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1.2740 - val_loss: 0.1917\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 937us/step - loss: 0.1756 - val_loss: 0.1501\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 0.1397 - val_loss: 0.1266\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 969us/step - loss: 0.1197 - val_loss: 0.1129\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1064 - val_loss: 0.1084\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 964us/step - loss: 0.1009 - val_loss: 0.1022\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 938us/step - loss: 0.0946 - val_loss: 0.0957\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 931us/step - loss: 0.0910 - val_loss: 0.0950\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 936us/step - loss: 0.0878 - val_loss: 0.0889\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 931us/step - loss: 0.0868 - val_loss: 0.0882\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 932us/step - loss: 0.0856 - val_loss: 0.0881\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 924us/step - loss: 0.0827 - val_loss: 0.0864\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 967us/step - loss: 0.0832 - val_loss: 0.0884\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 958us/step - loss: 0.0799 - val_loss: 0.0912\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.0802 - val_loss: 0.0888\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 946us/step - loss: 0.0777 - val_loss: 0.0844\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 938us/step - loss: 0.0796 - val_loss: 0.0871\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 954us/step - loss: 0.0768 - val_loss: 0.0829\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 943us/step - loss: 0.0759 - val_loss: 0.0860\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 935us/step - loss: 0.0779 - val_loss: 0.0866\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 940us/step - loss: 0.0757 - val_loss: 0.0852\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 933us/step - loss: 0.0755 - val_loss: 0.0856\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 928us/step - loss: 0.0737 - val_loss: 0.0829\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0831\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0726 - val_loss: 0.0812\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0826\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0854\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0813\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0813\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0841\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0802\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0823\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0823\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0804\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0842\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0825\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0811\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0689 - val_loss: 0.0798\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0693 - val_loss: 0.0831\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0809\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0694 - val_loss: 0.0845\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0848\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0676 - val_loss: 0.0830\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0833\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0680 - val_loss: 0.0828\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0787\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0811\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0687 - val_loss: 0.0833\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0815\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0656 - val_loss: 0.0830\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0840\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0786\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0800\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0660 - val_loss: 0.0807\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0654 - val_loss: 0.0819\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0838\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0662 - val_loss: 0.0821\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0785\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0631 - val_loss: 0.0834\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0861\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0649 - val_loss: 0.0809\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0645 - val_loss: 0.0805\n",
      "Epoch 63/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0641 - val_loss: 0.0817\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0642 - val_loss: 0.0839\n",
      "Epoch 65/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0635 - val_loss: 0.0807\n",
      "Epoch 66/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0653 - val_loss: 0.0803\n",
      "Epoch 67/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0629 - val_loss: 0.0807\n",
      "Epoch 68/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0626 - val_loss: 0.0839\n",
      "Epoch 00068: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 1.8003 - val_loss: 0.0841\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0572\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0519 - val_loss: 0.0442\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0389\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0358 - val_loss: 0.0329\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0317 - val_loss: 0.0313\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0340\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0269 - val_loss: 0.0283\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0280 - val_loss: 0.0275\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0280\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0245 - val_loss: 0.0303\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0249\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0227\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0233\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0226\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0228\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0211\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0230\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0224\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0208\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0211\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0210\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0214\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0190\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0198\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0193\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0205\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0215\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0190\n",
      "Epoch 42/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 43/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 44/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0209\n",
      "Epoch 45/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0174\n",
      "Epoch 46/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0231\n",
      "Epoch 47/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0198\n",
      "Epoch 48/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0185\n",
      "Epoch 49/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 50/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0187\n",
      "Epoch 51/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0221\n",
      "Epoch 52/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0174\n",
      "Epoch 53/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0196\n",
      "Epoch 54/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0211\n",
      "Epoch 55/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0180\n",
      "Epoch 56/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0185\n",
      "Epoch 57/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0209\n",
      "Epoch 58/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0178\n",
      "Epoch 59/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0193\n",
      "Epoch 60/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0216\n",
      "Epoch 61/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 62/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0196\n",
      "Epoch 00062: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9977ee115cd4f7f9b1e25b9ac6d3752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - ETA: 0s - loss: 0.081 - 1s 2ms/step - loss: 0.0731 - val_loss: 0.0307\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0241\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0224\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0211\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0226 - val_loss: 0.0208\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0230 - val_loss: 0.0235\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0213\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0209\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0207\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0208\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0204\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0262\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0205\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0228\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0191\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0247\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0199\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0200\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0217\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0199\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0188\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0213\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0195\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0204\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0206\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0192\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0222\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0208\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0201\n",
      "Epoch 00040: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.2303 - val_loss: 0.1205\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1064 - val_loss: 0.1051\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1002 - val_loss: 0.0945\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0968\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0925 - val_loss: 0.0958\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0916 - val_loss: 0.0909\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0878 - val_loss: 0.0908\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0895 - val_loss: 0.0928\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.1049\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0877 - val_loss: 0.0926\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0945\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0868\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0888\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0884\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0840 - val_loss: 0.0878\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0998\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0836 - val_loss: 0.0882\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0885\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0845 - val_loss: 0.0898\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0887\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0908\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0869\n",
      "Epoch 00022: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 0.1872\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1601\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1554 - val_loss: 0.1404\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1540 - val_loss: 0.1382\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1433 - val_loss: 0.1410\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1409 - val_loss: 0.1499\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1450 - val_loss: 0.1407\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1442 - val_loss: 0.1447\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1406 - val_loss: 0.1451\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1433 - val_loss: 0.1717\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1435 - val_loss: 0.1381\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1347 - val_loss: 0.1387\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1402 - val_loss: 0.1373\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1386 - val_loss: 0.1478\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1367 - val_loss: 0.1427\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1361 - val_loss: 0.1381\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1344 - val_loss: 0.1474\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1358 - val_loss: 0.1441\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1346\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1324 - val_loss: 0.1354\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1355 - val_loss: 0.1378\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1335 - val_loss: 0.1358\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1319\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1317 - val_loss: 0.1381\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1377 - val_loss: 0.1369\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1322 - val_loss: 0.1329\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1318 - val_loss: 0.1342\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1298 - val_loss: 0.1364\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1324 - val_loss: 0.1343\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1279 - val_loss: 0.1406\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1319 - val_loss: 0.1325\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1296 - val_loss: 0.1347\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1295 - val_loss: 0.1356\n",
      "Epoch 00034: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.1143\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.0936\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.1192\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0973 - val_loss: 0.1078\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0944 - val_loss: 0.0988\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0974\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.0927\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.1039\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0951\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0910\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0874 - val_loss: 0.0899\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0931\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0860 - val_loss: 0.0850\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0905\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0866\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0890\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0851 - val_loss: 0.0922\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0873\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0854\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0822 - val_loss: 0.0880\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0883\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0916\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0842\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0809 - val_loss: 0.0822\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0847\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0865\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0862\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0890\n",
      "Epoch 29/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0798\n",
      "Epoch 30/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0904\n",
      "Epoch 31/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0770\n",
      "Epoch 32/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0788\n",
      "Epoch 33/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0893\n",
      "Epoch 34/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0837 - val_loss: 0.0844\n",
      "Epoch 35/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0779 - val_loss: 0.0809\n",
      "Epoch 36/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0816\n",
      "Epoch 37/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0847\n",
      "Epoch 38/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0832\n",
      "Epoch 39/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0902\n",
      "Epoch 40/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0824\n",
      "Epoch 41/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0802 - val_loss: 0.0820\n",
      "Epoch 00041: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.0416\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0419\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.0284\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0346\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0295 - val_loss: 0.0361\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0267\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0302\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0277 - val_loss: 0.0210\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0232 - val_loss: 0.0263\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0246 - val_loss: 0.0224\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0231 - val_loss: 0.0252\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0238\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0209\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0195\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0196\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0221\n",
      "Epoch 21/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0202\n",
      "Epoch 22/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0237\n",
      "Epoch 23/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 24/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 25/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 26/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 27/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0228\n",
      "Epoch 28/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0212\n",
      "Epoch 00028: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca88d5672d74dfd910c52d58f92e9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.7963 - val_loss: 0.0847\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0245\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0323 - val_loss: 0.0286\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0297 - val_loss: 0.0275\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 11.1437 - val_loss: 4.6538\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 4.0424 - val_loss: 0.8574\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 1.0864\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.5331 - val_loss: 0.2900\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2258 - val_loss: 0.6499\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3873 - val_loss: 0.1283\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2036 - val_loss: 0.1058\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1383 - val_loss: 0.0998\n",
      "Epoch 00012: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 1.4265 - val_loss: 0.1007\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1125 - val_loss: 0.1011\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0962 - val_loss: 0.0974\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0992 - val_loss: 0.0953\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.1058\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1022 - val_loss: 0.0892\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0989 - val_loss: 0.0941\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0997 - val_loss: 0.1083\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1.5073 - val_loss: 2.3461\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1.4452 - val_loss: 0.1784\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1437\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1273 - val_loss: 0.0997\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1163 - val_loss: 0.0970\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1069 - val_loss: 0.1322\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1127 - val_loss: 0.0955\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.1007\n",
      "Epoch 00016: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.8273 - val_loss: 0.1499\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1582 - val_loss: 0.1721\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1970\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1642 - val_loss: 0.2197\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1960\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 2.2432\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.7065 - val_loss: 0.1553\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1491\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1564 - val_loss: 0.1739\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1635 - val_loss: 0.1625\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1620 - val_loss: 0.1669\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1627 - val_loss: 0.1753\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1631 - val_loss: 0.1860\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1546\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1619\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.1700 - val_loss: 0.1584\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1615\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1753\n",
      "Epoch 00018: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.6877 - val_loss: 0.1018\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1018 - val_loss: 0.1271\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1017 - val_loss: 0.1056\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1048 - val_loss: 0.1209\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 13.6235\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2.1586 - val_loss: 0.1665\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1263 - val_loss: 0.0978\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1057 - val_loss: 0.0899\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0991 - val_loss: 0.0926\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0960 - val_loss: 0.0850\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 0.0962 - val_loss: 0.0947\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0984 - val_loss: 0.0987\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0992 - val_loss: 0.0941\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1049 - val_loss: 0.2452\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1459 - val_loss: 0.1211\n",
      "Epoch 16/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1016 - val_loss: 0.1098\n",
      "Epoch 17/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0945 - val_loss: 0.0852\n",
      "Epoch 18/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1139 - val_loss: 0.1847\n",
      "Epoch 19/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1427 - val_loss: 0.0909\n",
      "Epoch 20/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0987 - val_loss: 0.1451\n",
      "Epoch 00020: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "164/164 [==============================] - 1s 2ms/step - loss: 0.6926 - val_loss: 0.0974\n",
      "Epoch 2/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0375\n",
      "Epoch 3/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0354 - val_loss: 0.0313\n",
      "Epoch 4/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.0273\n",
      "Epoch 5/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0270\n",
      "Epoch 6/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0365\n",
      "Epoch 7/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.5356 - val_loss: 23.6889\n",
      "Epoch 8/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.1930 - val_loss: 11.4323\n",
      "Epoch 9/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 6.6043 - val_loss: 2.3912\n",
      "Epoch 10/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1.2559 - val_loss: 0.8220\n",
      "Epoch 11/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.5368\n",
      "Epoch 12/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.1430\n",
      "Epoch 13/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1476 - val_loss: 0.1691\n",
      "Epoch 14/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1560 - val_loss: 0.0788\n",
      "Epoch 15/200\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.1177 - val_loss: 0.2938\n",
      "Epoch 00015: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a990b8b8f74dc19044ceeb521dfd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fb847588a24f0293842d3c6dc5a2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9055102d7d0d451e8367a0cd6ae65a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0745\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0661\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0658 - val_loss: 0.0596\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0556\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0518\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0487\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0456\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0428\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0409\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0388\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0376\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0364\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0352\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0342\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0344 - val_loss: 0.0332\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0332 - val_loss: 0.0327\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0333 - val_loss: 0.0319\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0316\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0311\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0313 - val_loss: 0.0306\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0309 - val_loss: 0.0301\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0296\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0293\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0289\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0296 - val_loss: 0.0285\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0267\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0264\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0262\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0261\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0259\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0253\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0249\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0249\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0246\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0243\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0243\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0240\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0240\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0236\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0236\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0235\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0236\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0231\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0231\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0224\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0225\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0221\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0220\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0218\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0218\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0214\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0214\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0211\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0209\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0211\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0207\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0210\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0210\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0203\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0203\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0205\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0203\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0204\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0202\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0201\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0200\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0198\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.019 - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0196\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0197\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0199\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0194\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0196\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0195\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0196\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0198\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0195\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0198\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0195\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0198\n",
      "Epoch 00119: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 5ms/step - loss: 0.5905 - val_loss: 0.5225\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5065 - val_loss: 0.4455\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4374 - val_loss: 0.3687\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.3011\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3087 - val_loss: 0.2649\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2770 - val_loss: 0.2374\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2491 - val_loss: 0.2194\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2280 - val_loss: 0.2040\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2128 - val_loss: 0.1927\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.1833\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1865 - val_loss: 0.1761\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.1684\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1755 - val_loss: 0.1630\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1595\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1655 - val_loss: 0.1556\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1588 - val_loss: 0.1524\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1561 - val_loss: 0.1486\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1515 - val_loss: 0.1467\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1483 - val_loss: 0.1433\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1470 - val_loss: 0.1404\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1436 - val_loss: 0.1390\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1367\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1385 - val_loss: 0.1335\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.1319\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1302\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1308 - val_loss: 0.1277\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1265\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1257\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1272 - val_loss: 0.1243\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.1228\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1224\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1209\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1190\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1194 - val_loss: 0.1186\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1165\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1180\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.1158\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.1146\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1111 - val_loss: 0.1136\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1117\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.1122\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1100 - val_loss: 0.1111\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1069 - val_loss: 0.1102\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1065 - val_loss: 0.1086\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.1078\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1050 - val_loss: 0.1072\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.1066\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1041 - val_loss: 0.1065\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1025 - val_loss: 0.1062\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.1053\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0988 - val_loss: 0.1055\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1039\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1032\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0985 - val_loss: 0.1037\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1025\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1018\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0974 - val_loss: 0.1005\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0968 - val_loss: 0.1007\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.1011\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0994\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 0.1001\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0989\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0984\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.0984\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0986\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0909 - val_loss: 0.0985\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0969\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0968\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0973\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0955\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0964\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0956\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0952\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0893 - val_loss: 0.0952\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0951\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0943\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0955\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0851 - val_loss: 0.0937\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.0936\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0933\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0928\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0930\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0928\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0927\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0848 - val_loss: 0.0927\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0924\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0917\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0913\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0909\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0910\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0911\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0907\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0907\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0909\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0909\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0906\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0898\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0896\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0897\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0903\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0898\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0891\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0818 - val_loss: 0.0893\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0901\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0891\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0889\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0889\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0892\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0886\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0889\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0885\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0888\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0886\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0886\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0878\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0889\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0883\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0876\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0888\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0883\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0879\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0876\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0876\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0874\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0874\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0880\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0874\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0873\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0869\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0876\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0885\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0872\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0873\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0871\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0872\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0870\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0876\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0869\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0871\n",
      "Epoch 00141: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.1028 - val_loss: 1.8625\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.7731 - val_loss: 1.5336\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.4574 - val_loss: 1.1931\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.1453 - val_loss: 0.8918\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8772 - val_loss: 0.6847\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.7001 - val_loss: 0.5589\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5873 - val_loss: 0.4893\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.4448\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.4136\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.3884\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4021 - val_loss: 0.3666\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.3488\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3519 - val_loss: 0.3330\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3204\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.3100\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3022\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.2944\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2966 - val_loss: 0.2862\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2857 - val_loss: 0.2807\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2828 - val_loss: 0.2747\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2727 - val_loss: 0.2680\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2621 - val_loss: 0.2628\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2596 - val_loss: 0.2586\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2517 - val_loss: 0.2546\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2447 - val_loss: 0.2496\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2446 - val_loss: 0.2459\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2370 - val_loss: 0.2417\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2349 - val_loss: 0.2373\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2293 - val_loss: 0.2328\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2230 - val_loss: 0.2302\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2230 - val_loss: 0.2272\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2200 - val_loss: 0.2238\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2130 - val_loss: 0.2220\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2122 - val_loss: 0.2174\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2120 - val_loss: 0.2158\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2079 - val_loss: 0.2132\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2038 - val_loss: 0.2106\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.2097\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.2007 - val_loss: 0.2063\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.2047\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1938 - val_loss: 0.2031\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 0.2012\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1997\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1876 - val_loss: 0.1970\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1851 - val_loss: 0.1963\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1825 - val_loss: 0.1942\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1924\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1790 - val_loss: 0.1906\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1785 - val_loss: 0.1895\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1758 - val_loss: 0.1871\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1743 - val_loss: 0.1861\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1743 - val_loss: 0.1845\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.1832\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1688 - val_loss: 0.1825\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.1804\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1796\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1653 - val_loss: 0.1777\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1770\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1646 - val_loss: 0.1756\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.1757\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1600 - val_loss: 0.1741\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1727\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1717\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1583 - val_loss: 0.1713\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1699\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1570 - val_loss: 0.1693\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.1683\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1684\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1669\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1662\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1522 - val_loss: 0.1652\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1643\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1503 - val_loss: 0.1638\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1633\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1629\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1624\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1604\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1478 - val_loss: 0.1611\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.1598\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1454 - val_loss: 0.1594\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1443 - val_loss: 0.1591\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1454 - val_loss: 0.1588\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1582\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1444 - val_loss: 0.1579\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1586\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1432 - val_loss: 0.1564\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.1561\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1419 - val_loss: 0.1569\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1403 - val_loss: 0.1560\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1411 - val_loss: 0.1551\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1394 - val_loss: 0.1570\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1396 - val_loss: 0.1549\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1374 - val_loss: 0.1547\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1384 - val_loss: 0.1545\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1534\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1394 - val_loss: 0.1532\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1538\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1386 - val_loss: 0.1535\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1521\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1522\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1362 - val_loss: 0.1529\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1354 - val_loss: 0.1518\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1360 - val_loss: 0.1523\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1353 - val_loss: 0.1518\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1356 - val_loss: 0.1506\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1308 - val_loss: 0.1524\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1345 - val_loss: 0.1508\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1322 - val_loss: 0.1508\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1342 - val_loss: 0.1503\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1311 - val_loss: 0.1503\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.1500\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.1499\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1332 - val_loss: 0.1504\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1310 - val_loss: 0.1499\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1315 - val_loss: 0.1494\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1330 - val_loss: 0.1496\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1327 - val_loss: 0.1489\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.1489\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1488\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1304 - val_loss: 0.1488\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1285 - val_loss: 0.1479\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1301 - val_loss: 0.1484\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.1481\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1307 - val_loss: 0.1476\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.1481\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1472\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1471\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.1463\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1466\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1300 - val_loss: 0.1457\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1303 - val_loss: 0.1468\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.1470\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1279 - val_loss: 0.1459\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1458\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1463\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1467\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1264 - val_loss: 0.1457\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1275 - val_loss: 0.1456\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1456\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.1451\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1444\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1273 - val_loss: 0.1452\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1260 - val_loss: 0.1447\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1263 - val_loss: 0.1449\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1259 - val_loss: 0.1442\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1263 - val_loss: 0.1443\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1447\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1249 - val_loss: 0.1447\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1449\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.1442\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1262 - val_loss: 0.1445\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1440\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1442\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1437\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1445\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1436\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1446\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1439\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1430\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.1434\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1434\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1256 - val_loss: 0.1430\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1429\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1433\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1427\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1430\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1244 - val_loss: 0.1428\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.1428\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1219 - val_loss: 0.1426\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1421\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1227 - val_loss: 0.1427\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1218 - val_loss: 0.1422\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.1425\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1422\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1224 - val_loss: 0.1424\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1423\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1421\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1205 - val_loss: 0.1409\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.1222 - val_loss: 0.1420\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.1416\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1215 - val_loss: 0.1419\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1410\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1215 - val_loss: 0.1417\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1406\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1207 - val_loss: 0.1403\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.1408\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.1209 - val_loss: 0.1410\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.1410\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.1407\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1416\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.1409\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1183 - val_loss: 0.1407\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1410\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1408\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1415\n",
      "Epoch 00195: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.3440 - val_loss: 3.0351\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.9383 - val_loss: 2.6106\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.4947 - val_loss: 2.1428\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 2.0449 - val_loss: 1.6582\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.5777 - val_loss: 1.2001\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.1530 - val_loss: 0.8716\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8598 - val_loss: 0.6663\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.6643 - val_loss: 0.5389\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5386 - val_loss: 0.4586\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4650 - val_loss: 0.4079\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.3774\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3831 - val_loss: 0.3530\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3564 - val_loss: 0.3342\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3364 - val_loss: 0.3173\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3018\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.2871\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2803 - val_loss: 0.2732\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2660 - val_loss: 0.2605\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2533 - val_loss: 0.2495\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2416 - val_loss: 0.2389\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2300 - val_loss: 0.2302\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2240 - val_loss: 0.2223\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 0.2149\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2077 - val_loss: 0.2082\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.2031\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.1973\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1912 - val_loss: 0.1927\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1860 - val_loss: 0.1890\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.1850\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1781 - val_loss: 0.1812\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1781\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1724 - val_loss: 0.1751\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1675 - val_loss: 0.1727\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1666 - val_loss: 0.1700\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1628 - val_loss: 0.1672\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1570 - val_loss: 0.1653\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1630\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1607\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1586\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 0.1567\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1552\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.1526\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1443 - val_loss: 0.1511\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1450 - val_loss: 0.1494\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1416 - val_loss: 0.1474\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1410 - val_loss: 0.1458\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1382 - val_loss: 0.1443\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1377 - val_loss: 0.1432\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1413\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1402\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1394\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1376\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1317 - val_loss: 0.1364\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1294 - val_loss: 0.1352\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1344\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1329\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1277 - val_loss: 0.1319\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1306\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1295\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1290\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 0.1276\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1266\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1258\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1245\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1191 - val_loss: 0.1241\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1225\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1184 - val_loss: 0.1217\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1210\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1139 - val_loss: 0.1201\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1198\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1129 - val_loss: 0.1188\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.1173\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.1167\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1097 - val_loss: 0.1161\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1149\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1145\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1139\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1131\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1122\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1055 - val_loss: 0.1122\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1112\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1028 - val_loss: 0.1097\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1094\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.1091\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1083\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1006 - val_loss: 0.1076\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1071\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1070\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.1059\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0985 - val_loss: 0.1051\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0987 - val_loss: 0.1050\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1046\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.1040\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1048\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.1035\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0958 - val_loss: 0.1023\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.1030\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.1018\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.1015\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.1017\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1009\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0997\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.1006\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0993\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0916 - val_loss: 0.0987\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0991\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0976\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0902 - val_loss: 0.0973\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0894 - val_loss: 0.0973\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0965\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0965\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0968\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0976\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0881 - val_loss: 0.0957\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0950\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0948\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0939\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0939\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0938\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.0932\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0931\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0931\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0929\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0926\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0922\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0915\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0925\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0855 - val_loss: 0.0917\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0917\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0910\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0908\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0841 - val_loss: 0.0915\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0824 - val_loss: 0.0905\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0830 - val_loss: 0.0899\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0905\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0910\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0900\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0816 - val_loss: 0.0903\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0892\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0889\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0898\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0888\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0895\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0892\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0884\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0892\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0891\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0884\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0885\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0886\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0879\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0875\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0886\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0796 - val_loss: 0.0886\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0877\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0871\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0885\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0878\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0875\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0873\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0875\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0872\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0789 - val_loss: 0.0868\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0782 - val_loss: 0.0869\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0873\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0874\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0866\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0870\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0861\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0863\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0861\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0867\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0772 - val_loss: 0.0865\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0861\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0862\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0862\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0860\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0865\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0859\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0854\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0863\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0858\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0858\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0854\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0859\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0860\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0854\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0759 - val_loss: 0.0858\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0857\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0854\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0856\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0853\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0851\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0848\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0854\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0847\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0852\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0849\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0849\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 3.4982 - val_loss: 3.0674\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.8390 - val_loss: 2.4324\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.2533 - val_loss: 1.7815\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.6391 - val_loss: 1.1626\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.0875 - val_loss: 0.7288\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.6911 - val_loss: 0.4667\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.3132\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.2303\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2055 - val_loss: 0.1813\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1519\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1380 - val_loss: 0.1331\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1185 - val_loss: 0.1207\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1078 - val_loss: 0.1124\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.1076\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.1035\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0882 - val_loss: 0.1003\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0975\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0955\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0937\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0920\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0904\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0889\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0738 - val_loss: 0.0873\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0860\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0846\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0833\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0682 - val_loss: 0.0820\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0806\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0793\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0780\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0767\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0632 - val_loss: 0.0755\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0609 - val_loss: 0.0743\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0598 - val_loss: 0.0730\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0718\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0706\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0694\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0556 - val_loss: 0.0682\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.0670\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0541 - val_loss: 0.0658\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0537 - val_loss: 0.0645\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0540 - val_loss: 0.0633\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0530 - val_loss: 0.0624\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0516 - val_loss: 0.0614\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0505 - val_loss: 0.0603\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0500 - val_loss: 0.0594\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0489 - val_loss: 0.0584\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0575\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0483 - val_loss: 0.0566\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0558\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0548\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0542\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0534\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0528\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0523\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0517\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0509\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0506\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0498\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0492\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0488\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0483\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0478\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0473\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0470\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0463\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0459\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0456\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0452\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0443\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0440\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0434\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0434\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0427\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0422\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0421\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0342 - val_loss: 0.0415\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0410\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0337 - val_loss: 0.0406\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0403\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0397\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0331 - val_loss: 0.0396\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.0394\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0390\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0321 - val_loss: 0.0384\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0323 - val_loss: 0.0383\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0314 - val_loss: 0.0376\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0312 - val_loss: 0.0377\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0372\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0371\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0369\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0302 - val_loss: 0.0364\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0364\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0360\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0297 - val_loss: 0.0359\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0353\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0349\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0289 - val_loss: 0.0345\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0285 - val_loss: 0.0344\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0340\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0278 - val_loss: 0.0337\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0273 - val_loss: 0.0332\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0334\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0330\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0328\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0326\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0324\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0274 - val_loss: 0.0325\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0320\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0319\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0316\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0314\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0313\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0309\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0310\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0309\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0308\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0304\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0302\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0303\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0299\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0247 - val_loss: 0.0302\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0297\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0294\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0291\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0291\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0291\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0287\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0286\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0288\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0282\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0281\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0283\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0282\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0276\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0277\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0275\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0271\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0272\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0273\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0272\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0267\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0269\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0271\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0265\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0262\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0262\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0262\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0259\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0260\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0263\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0261\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0260\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0259\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0254\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0258\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0257\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0255\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0250\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0251\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0250\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0250\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0250\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0253\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0250\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0246\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0243\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0245\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0243\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0245\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0243\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0240\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0240\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0236\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0239\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0238\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0241\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0238\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0242\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0235\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0234\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0240\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0238\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0235\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0236\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0233\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0232\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0237\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0235\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0232\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0238\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0231\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0228\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5112da9cfffc436a85ef9a50359007c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0405\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0346\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0325 - val_loss: 0.0307\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0290 - val_loss: 0.0267\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0264 - val_loss: 0.0245\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0225\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0225\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0218\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0229\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0221\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0215\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0220\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0213\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0219\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0232\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0215\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0239\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0210\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0223\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0234\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0222\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0225\n",
      "Epoch 00026: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4833 - val_loss: 0.2135\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1933 - val_loss: 0.1496\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1484 - val_loss: 0.1283\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1263\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1114\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1094 - val_loss: 0.1047\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1041 - val_loss: 0.1075\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.1012\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0955 - val_loss: 0.1000\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0981\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0971\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0953\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0935\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0926\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0901\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0838 - val_loss: 0.0893\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0822 - val_loss: 0.0898\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0913\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0897\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0911\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0879\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0887\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0885\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0862\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0875\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0747 - val_loss: 0.0866\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0867\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0879\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0894\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0873\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0731 - val_loss: 0.0888\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0870\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0860\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0884\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0899\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0887\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0883\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0883\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0880\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0726 - val_loss: 0.0889\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0887\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 0.0728 - val_loss: 0.0862\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0874\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.5328 - val_loss: 0.5144\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.2909\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2820 - val_loss: 0.2491\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2364 - val_loss: 0.2226\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2093 - val_loss: 0.1998\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1948 - val_loss: 0.1846\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1747\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1703 - val_loss: 0.1660\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1584\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1530\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1487\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1516\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1453\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.1427\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1389 - val_loss: 0.1396\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1358 - val_loss: 0.1386\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.1361\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1315 - val_loss: 0.1349\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1321 - val_loss: 0.1365\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.1333\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1278 - val_loss: 0.1348\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.1336\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1371\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.1340\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1345\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1327\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1245 - val_loss: 0.1341\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1331\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1356\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1326\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.1331\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1326\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1311\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1366\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1227 - val_loss: 0.1320\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.1311\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.1336\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1344\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1366\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1327\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1339\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1196 - val_loss: 0.1337\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1199 - val_loss: 0.1357\n",
      "Epoch 00044: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.1696 - val_loss: 0.4189\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.3677 - val_loss: 0.2606\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.2392 - val_loss: 0.1977\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1868 - val_loss: 0.1744\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1562\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1514\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1375 - val_loss: 0.1379\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1266 - val_loss: 0.1321\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1228\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.1161\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1133\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1059 - val_loss: 0.1109\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.1042\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1025\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.0995\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0926 - val_loss: 0.0963\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0905 - val_loss: 0.0943\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0970\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0896 - val_loss: 0.0936\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0856 - val_loss: 0.0900\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0901\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0874\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0828 - val_loss: 0.0877\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0847 - val_loss: 0.0872\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0797 - val_loss: 0.0870\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0861\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0859\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0870\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0842\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0828\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0859\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0865\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0867\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0776 - val_loss: 0.0843\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0764 - val_loss: 0.0826\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0835\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0833\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0825\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0838\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0813\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0862\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0826\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0821\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0834\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0724 - val_loss: 0.0833\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0800\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0807\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0827\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0824\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0810\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0828\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0802\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0708 - val_loss: 0.0793\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0806\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0819\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0806\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0788\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0780\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0791\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0817\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0785\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0805\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0798\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0801\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0786\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0818\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0798\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0659 - val_loss: 0.0808\n",
      "Epoch 00068: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 2.6867 - val_loss: 0.2137\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.0926\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0776\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0665\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0622 - val_loss: 0.0586\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0534\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0506 - val_loss: 0.0491\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0457\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0434\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0433\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0397\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0363\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0367\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0320 - val_loss: 0.0340\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0336\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0310\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0309\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0282 - val_loss: 0.0293\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0300\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0285\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0280\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0271\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0303\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0263\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0253\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0249\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0251\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0244\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0250\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0239\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0248\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0246\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0240\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0227\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0218\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0230\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0210\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0215\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0206\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0211\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0213\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0213\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0217\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0223\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0175 - val_loss: 0.0226\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0205\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0214\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0193\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0227\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0195\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0216\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0216\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0206\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0209\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0202\n",
      "Epoch 00067: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339a89548cb44529b0a05d242ea0ab0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0305\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0253\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0202\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0233\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0208\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0215\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0226\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0217\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0217\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0212\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0187\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0199\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0236\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0186\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0218\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0230\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0200\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0208\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0229\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0229\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0220\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.2962 - val_loss: 0.1228\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1049\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.0951\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0971\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.0979\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0915 - val_loss: 0.1038\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0878\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0872\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0846 - val_loss: 0.0959\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0904\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0903\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0870\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0881\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0855\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0860\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0869\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0933\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0864\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0902\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0789 - val_loss: 0.0903\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0815 - val_loss: 0.0927\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0847\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0891\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0917\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.1004\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0872\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0912\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0761 - val_loss: 0.0856\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0863\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0879\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0922\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0780 - val_loss: 0.0891\n",
      "Epoch 00033: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.6153 - val_loss: 0.2178\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1892 - val_loss: 0.1633\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1606 - val_loss: 0.1532\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1577\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1442 - val_loss: 0.1420\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1448 - val_loss: 0.1488\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1417 - val_loss: 0.1475\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1375 - val_loss: 0.1356\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1505\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1310 - val_loss: 0.1417\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1318 - val_loss: 0.1420\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1309 - val_loss: 0.1378\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1340 - val_loss: 0.1389\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1306 - val_loss: 0.1418\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1295 - val_loss: 0.1316\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1372\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1290 - val_loss: 0.1319\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1412\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1275 - val_loss: 0.1407\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1378\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1328 - val_loss: 0.1332\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1264 - val_loss: 0.1368\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1231 - val_loss: 0.1280\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.1418\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1257 - val_loss: 0.1300\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1332\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1249 - val_loss: 0.1338\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1352\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1256 - val_loss: 0.1332\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1186 - val_loss: 0.1366\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1208 - val_loss: 0.1389\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1247 - val_loss: 0.1355\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1382\n",
      "Epoch 00034: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.9936 - val_loss: 0.1675\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1172\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1109 - val_loss: 0.1007\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.1073\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0964 - val_loss: 0.0979\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0979 - val_loss: 0.1030\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0992 - val_loss: 0.0885\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0945\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0915\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0846 - val_loss: 0.0934\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0910 - val_loss: 0.0815\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0853\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0843\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0853 - val_loss: 0.0860\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0940\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0840 - val_loss: 0.0845\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0891\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0817 - val_loss: 0.0849\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0822\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0847\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0819\n",
      "Epoch 00022: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.7842 - val_loss: 0.0704\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0568 - val_loss: 0.0455\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0389\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0300\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0329\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0291\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0258\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0250\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0322\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0264\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0250 - val_loss: 0.0231\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0267\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0244 - val_loss: 0.0229\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0251\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0228 - val_loss: 0.0230\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0266\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0233\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0240\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0219\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0270\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0248\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0209\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0195\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0238\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0207\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0202\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0191\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0258\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0222\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0209\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0195\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0235\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0228\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0207\n",
      "Epoch 00040: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd929458eda4f0fa14e31b9daf2565c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 1s 3ms/step - loss: 1.4606 - val_loss: 0.1050\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0706\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0566 - val_loss: 0.0372\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0338\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0308 - val_loss: 0.0318\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0299 - val_loss: 0.0284\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0230\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0223\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0232\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0223\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0214\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0210\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0195\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0227\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0397\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 15.6342 - val_loss: 19.9850\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 132.2667 - val_loss: 13.7239\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7182 - val_loss: 2.4885\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 9.7579 - val_loss: 3.4237\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 5.6315 - val_loss: 9.4886\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 3.9252 - val_loss: 10.3794\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 10.3219 - val_loss: 1.6637\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.0150 - val_loss: 1.1063\n",
      "Epoch 00025: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.8775 - val_loss: 0.1938\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1607 - val_loss: 0.1046\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.0936\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0941 - val_loss: 0.0939\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0878\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0884\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0928\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0877\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0901 - val_loss: 0.0996\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0926 - val_loss: 0.0995\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0930\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0988\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0883\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0911\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0928\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0861 - val_loss: 0.1010\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.0947\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0919 - val_loss: 0.0923\n",
      "Epoch 00018: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.6457 - val_loss: 0.2004\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.1486\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1492\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1456\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1457 - val_loss: 0.1409\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1387 - val_loss: 0.1400\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1376 - val_loss: 0.1337\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1400\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1348 - val_loss: 0.1360\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1367\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1361\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1422\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1541\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1395\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1424 - val_loss: 0.1566\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.1446 - val_loss: 0.1428\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1408 - val_loss: 0.1395\n",
      "Epoch 00017: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.0234 - val_loss: 0.1886\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1216\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.0940\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0967\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 1ms/step - loss: 0.0946 - val_loss: 0.1104\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0862\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0895 - val_loss: 0.0944\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0830\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0838\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0886 - val_loss: 0.0889\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0821\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0899\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0865 - val_loss: 0.0842\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0898\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0961\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.1021\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0837\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0967\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.1090\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 1.3514 - val_loss: 111.3998\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 30.7945 - val_loss: 1.8185\n",
      "Epoch 00021: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 1.0989 - val_loss: 0.2239\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1727 - val_loss: 0.0561\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0482\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0296\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0274\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0290\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.0560 - val_loss: 0.1054\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 2.5502 - val_loss: 4.6529\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 10.4058 - val_loss: 5.1976\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 3.9402 - val_loss: 0.5017\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.8093 - val_loss: 0.9355\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5472 - val_loss: 1.3470\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.3972\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1703 - val_loss: 0.1070\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.0520\n",
      "Epoch 00015: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b293023e82834c64b6611803cdf0e5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7ca8f77ef04be8aa8d46153842d8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf2f2c110a74ff98e7652b180490775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0922 - val_loss: 0.0894\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0880 - val_loss: 0.0855\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0816\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0777\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0738\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0700\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0663\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0625\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0629 - val_loss: 0.0597\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0609 - val_loss: 0.0584\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0567\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0553\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0552 - val_loss: 0.0537\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0528\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0513\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0500\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0486\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0473\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0461\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0450\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0438\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0428\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0418\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0409\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0400\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0391\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0384\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0378\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0371\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0366\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0361\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0355\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0352\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0345\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0343\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0339\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0333\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0335\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0329\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0328\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0324\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0321\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0323\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0318\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0315\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0314\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0314\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0311\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0312\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0305\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0305\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0304\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0301\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0299\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0296\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0297\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0296\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0293\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0290\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0291\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0288\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0286\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0286\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0284\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0278\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0279\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0278\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0278\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0277\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0277\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0274\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0274\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0274\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0270\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0269\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0266\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0265\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0266\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0263\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0263\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0264\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0262\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0259\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0261\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0260\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0257\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0259\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0256\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0256\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0254\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0251\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0253\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0253\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0255\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0250\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0252\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0251\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0252\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0249\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0246\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.0251\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0247\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0246\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0250\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0246\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0243\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0244\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0244\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0242\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0243\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0241\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0238\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0241\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0240\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0241\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0240\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0239\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0240\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0237\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0237\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0237\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0240\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0236\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0241\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0237\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0235\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0234\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0235\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0238\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0235\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0236\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0234\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0235\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0235\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0236\n",
      "Epoch 00147: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 7ms/step - loss: 0.6513 - val_loss: 0.6279\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6132 - val_loss: 0.5882\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5730 - val_loss: 0.5478\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5342 - val_loss: 0.5084\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4974 - val_loss: 0.4704\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4617 - val_loss: 0.4312\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4251 - val_loss: 0.3899\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3877 - val_loss: 0.3493\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3481 - val_loss: 0.3167\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3201 - val_loss: 0.2952\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.2782\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2804 - val_loss: 0.2631\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2679 - val_loss: 0.2493\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2537 - val_loss: 0.2367\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2410 - val_loss: 0.2256\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2314 - val_loss: 0.2163\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2210 - val_loss: 0.2093\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.2039\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2077 - val_loss: 0.1997\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2015 - val_loss: 0.1962\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1974 - val_loss: 0.1935\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1937 - val_loss: 0.1904\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1871 - val_loss: 0.1877\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1863 - val_loss: 0.1853\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1840 - val_loss: 0.1830\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1793 - val_loss: 0.1805\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1765 - val_loss: 0.1784\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.1762\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1738\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.1716\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1678 - val_loss: 0.1698\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1678 - val_loss: 0.1678\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1639 - val_loss: 0.1663\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.1639\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.1628\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 0.1604\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1589\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1575\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.1557\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 0.1544\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1468 - val_loss: 0.1526\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1452 - val_loss: 0.1515\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1507\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1447 - val_loss: 0.1493\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1423 - val_loss: 0.1487\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1468\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1463\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1457\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1449\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1367 - val_loss: 0.1430\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1328 - val_loss: 0.1414\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1414\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1327 - val_loss: 0.1404\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.1393\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.1383\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 0.1376\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1369\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1294 - val_loss: 0.1367\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.1360\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1341\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1346\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1241 - val_loss: 0.1328\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1331\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1229 - val_loss: 0.1316\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1314\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 0.1308\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.1306\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1289\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.1300\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1190 - val_loss: 0.1280\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1183 - val_loss: 0.1281\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1168 - val_loss: 0.1278\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.1269\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1261\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1146 - val_loss: 0.1252\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1248\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.1251\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1142 - val_loss: 0.1244\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.1240\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1117 - val_loss: 0.1224\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1121 - val_loss: 0.1223\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1111 - val_loss: 0.1220\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1208\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.1204\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1082 - val_loss: 0.1207\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.1206\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.1197\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.1192\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.1193\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.1177\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1068 - val_loss: 0.1187\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.1163\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1046 - val_loss: 0.1156\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1037 - val_loss: 0.1158\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1057 - val_loss: 0.1163\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.1154\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.1156\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1153\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.1147\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.1146\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1023 - val_loss: 0.1139\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1146\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1002 - val_loss: 0.1143\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0996 - val_loss: 0.1130\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1009 - val_loss: 0.1134\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.1118\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.1121\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0994 - val_loss: 0.1120\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.1122\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.1113\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.1116\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1103\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1105\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0969 - val_loss: 0.1103\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.1116\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0976 - val_loss: 0.1099\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0963 - val_loss: 0.1089\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0954 - val_loss: 0.1091\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0942 - val_loss: 0.1087\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0954 - val_loss: 0.1088\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1090\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.1089\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.1090\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0944 - val_loss: 0.1079\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0928 - val_loss: 0.1068\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.1063\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0929 - val_loss: 0.1072\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0918 - val_loss: 0.1068\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.1068\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.1067\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0927 - val_loss: 0.1053\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0920 - val_loss: 0.1063\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0911 - val_loss: 0.1065\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.1043\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.1058\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0900 - val_loss: 0.1045\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0903 - val_loss: 0.1042\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.1058\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.1047\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.1053\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.1040\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0894 - val_loss: 0.1033\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0908 - val_loss: 0.1042\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.1038\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.1033\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.1029\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0886 - val_loss: 0.1030\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.1029\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.1027\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1025\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0879 - val_loss: 0.1030\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1027\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.1021\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.1019\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.1017\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.1013\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1012\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.1018\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.1018\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.1012\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.1007\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.1000\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.1004\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.1011\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.1005\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.1006\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.1012\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.1001\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0985\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0990\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0849 - val_loss: 0.1004\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0995\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0846 - val_loss: 0.0992\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0842 - val_loss: 0.0992\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0995\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0986\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0985\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0836 - val_loss: 0.0982\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.0983\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0982\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0991\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0974\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0974\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0974\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0974\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0971\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0978\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0972\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0964\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0969\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0969\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0975\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0957\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0963\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0952\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0955\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0956\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0954\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0961\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0954\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.9537 - val_loss: 1.8725\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.8343 - val_loss: 1.7558\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7127 - val_loss: 1.6451\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6016 - val_loss: 1.5389\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4911 - val_loss: 1.4394\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.4051 - val_loss: 1.3429\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3145 - val_loss: 1.2456\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2132 - val_loss: 1.1451\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1256 - val_loss: 1.0402\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0245 - val_loss: 0.9281\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9215 - val_loss: 0.8155\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8160 - val_loss: 0.7161\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7371 - val_loss: 0.6436\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6708 - val_loss: 0.5907\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6259 - val_loss: 0.5500\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5769 - val_loss: 0.5162\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5433 - val_loss: 0.4864\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5152 - val_loss: 0.4607\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4855 - val_loss: 0.4395\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4609 - val_loss: 0.4229\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4400 - val_loss: 0.4084\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4244 - val_loss: 0.3962\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.3860\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3914 - val_loss: 0.3765\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3782 - val_loss: 0.3685\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3749 - val_loss: 0.3606\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3630 - val_loss: 0.3536\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3555 - val_loss: 0.3473\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3467 - val_loss: 0.3413\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3429 - val_loss: 0.3360\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3297 - val_loss: 0.3309\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3281 - val_loss: 0.3267\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3257 - val_loss: 0.3221\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3165 - val_loss: 0.3181\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.3141\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3105 - val_loss: 0.3105\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3072 - val_loss: 0.3072\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3030 - val_loss: 0.3040\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2957 - val_loss: 0.3010\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2970 - val_loss: 0.2981\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2910 - val_loss: 0.2951\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2899 - val_loss: 0.2930\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2889 - val_loss: 0.2902\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2836 - val_loss: 0.2879\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2821 - val_loss: 0.2851\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2785 - val_loss: 0.2832\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2765 - val_loss: 0.2808\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2702 - val_loss: 0.2787\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2701 - val_loss: 0.2766\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2669 - val_loss: 0.2742\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2674 - val_loss: 0.2728\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2651 - val_loss: 0.2704\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2613 - val_loss: 0.2687\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2593 - val_loss: 0.2668\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2543 - val_loss: 0.2647\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2568 - val_loss: 0.2635\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2536 - val_loss: 0.2617\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2500 - val_loss: 0.2597\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2494 - val_loss: 0.2580\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2499 - val_loss: 0.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2468 - val_loss: 0.2546\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2434 - val_loss: 0.2527\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2410 - val_loss: 0.2513\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2410 - val_loss: 0.2496\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2394 - val_loss: 0.2484\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2383 - val_loss: 0.2463\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2379 - val_loss: 0.2449\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2352 - val_loss: 0.2428\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2362 - val_loss: 0.2420\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2299 - val_loss: 0.2407\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2299 - val_loss: 0.2387\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2272 - val_loss: 0.2375\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2261 - val_loss: 0.2357\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2256 - val_loss: 0.2350\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2250 - val_loss: 0.2326\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2237 - val_loss: 0.2316\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2204 - val_loss: 0.2300\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2211 - val_loss: 0.2289\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2186 - val_loss: 0.2281\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2167 - val_loss: 0.2262\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2139 - val_loss: 0.2248\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2133 - val_loss: 0.2235\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2133 - val_loss: 0.2224\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2122 - val_loss: 0.2213\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2109 - val_loss: 0.2203\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2082 - val_loss: 0.2186\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.2175\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.2059 - val_loss: 0.2162\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2060 - val_loss: 0.2157\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2041 - val_loss: 0.2141\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2054 - val_loss: 0.2128\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2028 - val_loss: 0.2118\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2025 - val_loss: 0.2110\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1998 - val_loss: 0.2098\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1991 - val_loss: 0.2089\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1958 - val_loss: 0.2075\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1965 - val_loss: 0.2064\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1946 - val_loss: 0.2052\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1941 - val_loss: 0.2045\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1932 - val_loss: 0.2032\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1901 - val_loss: 0.2028\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1915 - val_loss: 0.2015\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.2006\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1877 - val_loss: 0.2001\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1879 - val_loss: 0.1986\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.1980\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1868 - val_loss: 0.1974\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1851 - val_loss: 0.1969\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.1956\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1843 - val_loss: 0.1951\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.1936\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.1934\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.1921\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1784 - val_loss: 0.1920\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1782 - val_loss: 0.1913\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1788 - val_loss: 0.1904\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.1894\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1736 - val_loss: 0.1889\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1778 - val_loss: 0.1882\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1755 - val_loss: 0.1879\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1753 - val_loss: 0.1865\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.1858\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1853\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1694 - val_loss: 0.1846\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1839\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1707 - val_loss: 0.1834\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 0.1825\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1670 - val_loss: 0.1821\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1675 - val_loss: 0.1813\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1684 - val_loss: 0.1812\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1664 - val_loss: 0.1803\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1669 - val_loss: 0.1796\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 0.1795\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1648 - val_loss: 0.1783\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1635 - val_loss: 0.1782\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1650 - val_loss: 0.1781\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1658 - val_loss: 0.1774\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1624 - val_loss: 0.1768\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 0.1763\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1758\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1590 - val_loss: 0.1756\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1606 - val_loss: 0.1748\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1609 - val_loss: 0.1741\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1743\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.1737\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 0.1731\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1597 - val_loss: 0.1726\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1552 - val_loss: 0.1725\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1563 - val_loss: 0.1716\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1709\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1710\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1562 - val_loss: 0.1701\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1703\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1547 - val_loss: 0.1691\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1689\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1686\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1521 - val_loss: 0.1677\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1532 - val_loss: 0.1683\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1675\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.1675\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1509 - val_loss: 0.1671\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.1667\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1492 - val_loss: 0.1664\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1659\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1494 - val_loss: 0.1659\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1493 - val_loss: 0.1654\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.1653\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1486 - val_loss: 0.1653\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1640\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1479 - val_loss: 0.1644\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1475 - val_loss: 0.1642\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1640\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.1632\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1468 - val_loss: 0.1629\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1453 - val_loss: 0.1628\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1456 - val_loss: 0.1625\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1448 - val_loss: 0.1622\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1466 - val_loss: 0.1625\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1451 - val_loss: 0.1618\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.1615\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1451 - val_loss: 0.1614\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1613\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1609\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1429 - val_loss: 0.1607\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1598\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1430 - val_loss: 0.1606\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1598\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1432 - val_loss: 0.1598\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1418 - val_loss: 0.1595\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1595\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1585\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1409 - val_loss: 0.1587\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1582\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.1585\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1576\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1576\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1389 - val_loss: 0.1577\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1575\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1404 - val_loss: 0.1571\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1391 - val_loss: 0.1569\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.2022 - val_loss: 3.0291\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.9988 - val_loss: 2.8157\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.7785 - val_loss: 2.5991\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.5523 - val_loss: 2.3801\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.3420 - val_loss: 2.1606\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.1340 - val_loss: 1.9428\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9246 - val_loss: 1.7233\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7237 - val_loss: 1.5033\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5287 - val_loss: 1.2915\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.3233 - val_loss: 1.1078\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1563 - val_loss: 0.9544\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.0098 - val_loss: 0.8281\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8847 - val_loss: 0.7280\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7803 - val_loss: 0.6487\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6926 - val_loss: 0.5833\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6276 - val_loss: 0.5321\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5578 - val_loss: 0.4929\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5239 - val_loss: 0.4620\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4946 - val_loss: 0.4375\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4500 - val_loss: 0.4183\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4289 - val_loss: 0.4020\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4115 - val_loss: 0.3885\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3947 - val_loss: 0.3768\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3803 - val_loss: 0.3655\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3633 - val_loss: 0.3553\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3499 - val_loss: 0.3462\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3426 - val_loss: 0.3371\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.3289\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3198 - val_loss: 0.3209\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3184 - val_loss: 0.3129\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3048 - val_loss: 0.3054\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2977 - val_loss: 0.2981\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2925 - val_loss: 0.2913\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2851\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2771 - val_loss: 0.2791\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2735 - val_loss: 0.2738\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2652 - val_loss: 0.2685\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2618 - val_loss: 0.2631\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2550 - val_loss: 0.2584\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2523 - val_loss: 0.2538\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2456 - val_loss: 0.2498\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2423 - val_loss: 0.2455\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2343 - val_loss: 0.2413\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2359 - val_loss: 0.2376\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.2339\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2257 - val_loss: 0.2308\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2242 - val_loss: 0.2274\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2213 - val_loss: 0.2245\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2165 - val_loss: 0.2216\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2150 - val_loss: 0.2186\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2134 - val_loss: 0.2157\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2088 - val_loss: 0.2133\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2107\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2039 - val_loss: 0.2086\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.2064\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1992 - val_loss: 0.2043\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1961 - val_loss: 0.2023\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1955 - val_loss: 0.2001\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1915 - val_loss: 0.1983\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1919 - val_loss: 0.1966\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.1949\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.1935\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.1920\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1845 - val_loss: 0.1903\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1808 - val_loss: 0.1887\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1803 - val_loss: 0.1872\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1778 - val_loss: 0.1863\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.1844\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1762 - val_loss: 0.1829\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1740 - val_loss: 0.1817\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1718 - val_loss: 0.1808\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1709 - val_loss: 0.1793\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1693 - val_loss: 0.1781\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1677 - val_loss: 0.1768\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1680 - val_loss: 0.1754\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1657 - val_loss: 0.1743\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1657 - val_loss: 0.1734\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1652 - val_loss: 0.1722\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1650 - val_loss: 0.1709\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1614 - val_loss: 0.1698\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1686\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1601 - val_loss: 0.1675\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1568 - val_loss: 0.1662\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1656\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1642\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1633\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1527 - val_loss: 0.1622\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1522 - val_loss: 0.1612\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1515 - val_loss: 0.1603\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1501 - val_loss: 0.1593\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1519 - val_loss: 0.1584\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1489 - val_loss: 0.1573\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1488 - val_loss: 0.1562\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1471 - val_loss: 0.1558\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1469 - val_loss: 0.1544\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1468 - val_loss: 0.1535\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1525\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1436 - val_loss: 0.1516\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1430 - val_loss: 0.1510\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1413 - val_loss: 0.1499\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1404 - val_loss: 0.1491\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1415 - val_loss: 0.1482\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.1472\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1363 - val_loss: 0.1463\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1367 - val_loss: 0.1456\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1447\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1441\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1431\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1352 - val_loss: 0.1423\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1415\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.1409\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1400\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1394\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1306 - val_loss: 0.1386\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1381\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1372\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.1365\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1362\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.1355\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.1347\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1266 - val_loss: 0.1340\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1246 - val_loss: 0.1329\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1258 - val_loss: 0.1326\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1259 - val_loss: 0.1321\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1246 - val_loss: 0.1316\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1244 - val_loss: 0.1309\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1302\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1202 - val_loss: 0.1296\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1221 - val_loss: 0.1293\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 0.1288\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1282\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.1276\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1197 - val_loss: 0.1271\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1184 - val_loss: 0.1264\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.1262\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1184 - val_loss: 0.1255\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.1250\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.1245\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1241\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.1236\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1148 - val_loss: 0.1229\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.1225\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.1218\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1218\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1212\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1122 - val_loss: 0.1207\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1123 - val_loss: 0.1202\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1198\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.1193\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.1189\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.1185\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.1179\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1101 - val_loss: 0.1175\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.1088 - val_loss: 0.1171\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.1165\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.1165\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1084 - val_loss: 0.1160\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1155\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.1152\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1148\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.1146\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1140\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1046 - val_loss: 0.1139\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1055 - val_loss: 0.1134\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.1130\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.1126\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1041 - val_loss: 0.1123\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1035 - val_loss: 0.1119\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1114\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.1114\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.1107\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.1103\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1020 - val_loss: 0.1100\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.1096\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.1094\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1008 - val_loss: 0.1090\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0999 - val_loss: 0.1085\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1003 - val_loss: 0.1087\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0991 - val_loss: 0.1085\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.1077\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.1071\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0970 - val_loss: 0.1070\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0980 - val_loss: 0.1066\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0973 - val_loss: 0.1061\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0978 - val_loss: 0.1059\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.1059\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1057\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0972 - val_loss: 0.1049\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1044\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1044\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.1041\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1038\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0955 - val_loss: 0.1035\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.1036\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.1028\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.1024\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1023\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.1020\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1017\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.1014\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.9132 - val_loss: 3.7363\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.6953 - val_loss: 3.5143\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.4637 - val_loss: 3.2892\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 3.2388 - val_loss: 3.0589\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.9979 - val_loss: 2.8181\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.7536 - val_loss: 2.5673\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.4945 - val_loss: 2.3109\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2482 - val_loss: 2.0530\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.9871 - val_loss: 1.8043\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.7762 - val_loss: 1.5671\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.5250 - val_loss: 1.3514\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.2988 - val_loss: 1.1603\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 1.1309 - val_loss: 0.9928\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9657 - val_loss: 0.8421\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8289 - val_loss: 0.7105\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.5998\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.5051\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4859 - val_loss: 0.4260\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4131 - val_loss: 0.3609\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3580 - val_loss: 0.3076\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.2649\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2610 - val_loss: 0.2326\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2221 - val_loss: 0.2084\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2036 - val_loss: 0.1894\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.1745\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.1620\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1546 - val_loss: 0.1517\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1456 - val_loss: 0.1437\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1370\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.1311\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.1261\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1178 - val_loss: 0.1217\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1179\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1088 - val_loss: 0.1144\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.1114\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.1086\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1061\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0960 - val_loss: 0.1042\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1024\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0927 - val_loss: 0.1008\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0948 - val_loss: 0.0995\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0982\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0969\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.0958\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0946\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0936\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0926\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0916\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0907\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0897\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0888\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0880\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0873\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0794 - val_loss: 0.0865\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0858\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0850\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0843\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0835\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0829\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0822\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0815\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0809\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0804\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0798\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0793\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0787\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0701 - val_loss: 0.0782\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0776\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0771\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0766\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0761\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0755\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0750\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0745\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0666 - val_loss: 0.0740\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0735\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0729\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0724\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0719\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0713\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0708\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0636 - val_loss: 0.0702\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0626 - val_loss: 0.0697\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0622 - val_loss: 0.0692\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0687\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0682\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0677\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0598 - val_loss: 0.0672\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0668\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0664\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0659\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0654\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0650\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0646\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0641\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0637\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0632\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0628\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0551 - val_loss: 0.0623\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0553 - val_loss: 0.0618\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0614\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0550 - val_loss: 0.0609\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0557 - val_loss: 0.0605\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0547 - val_loss: 0.0600\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0596\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0591\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0587\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0583\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0578\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0574\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0570\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0566\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0562\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0558\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0553\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0550\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0546\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0543\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0539\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0537\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0534\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0531\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0527\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0525\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0523\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0520\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0516\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0513\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.0511\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0508\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0504\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0501\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0445 - val_loss: 0.0499\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0496\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0494\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0491\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0488\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0486\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0482\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0479\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0477\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0474\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0470\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0470\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0467\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0425 - val_loss: 0.0464\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0462\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0460\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0458\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0455\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0453\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0451\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0449\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0446\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0444\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0441\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0440\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0438\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0435\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0434\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0430\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0430\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0427\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0425\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0424\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0423\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0421\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0421\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0418\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0416\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0415\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0415\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0413\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0412\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0410\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0408\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0407\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0406\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0402\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0402\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0400\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0399\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0396\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0395\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0395\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0393\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0393\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0391\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0390\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0388\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0388\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0387\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0386\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.0386\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0384\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0384\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0382\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0380\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0379\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c397989f320245d98e7832773bd8374e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0787 - val_loss: 0.0517\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0415\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0373\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0328\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0318\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0327\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0284\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0289\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0267\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0267\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0250\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0239\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0249\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0234\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0220\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0220\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0213\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0221\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0211\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0216\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0230\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0210\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0216\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0201\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0224\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0220\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0215\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0205\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0217\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0210\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0217\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0238\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5468 - val_loss: 0.3122\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3007 - val_loss: 0.2168\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2094 - val_loss: 0.1838\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.1663\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1581 - val_loss: 0.1529\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1475 - val_loss: 0.1439\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1361 - val_loss: 0.1310\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1282\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1227 - val_loss: 0.1214\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 0.1166\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.1135\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.1108\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1092\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1000 - val_loss: 0.1077\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0975 - val_loss: 0.1056\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.1017\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1012\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0919 - val_loss: 0.0999\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.1008\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0977\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0968\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0865 - val_loss: 0.0966\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0953\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.0945\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0958\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0935\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0917\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0938\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0939\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0904\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0928\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0912\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0910\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0918\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0908\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0905\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0910\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0897\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0881\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0903\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0886\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0883\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0897\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0912\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0887\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0893\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0882\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0883\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0896\n",
      "Epoch 00049: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7938 - val_loss: 1.0081\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.8466 - val_loss: 0.5814\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5380 - val_loss: 0.4210\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3851 - val_loss: 0.3387\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3171 - val_loss: 0.3085\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2827 - val_loss: 0.2841\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2586 - val_loss: 0.2652\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2426 - val_loss: 0.2519\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2276 - val_loss: 0.2349\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2162 - val_loss: 0.2232\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2044 - val_loss: 0.2151\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1962 - val_loss: 0.2076\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1902 - val_loss: 0.1989\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1804 - val_loss: 0.1914\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1758 - val_loss: 0.1862\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1675 - val_loss: 0.1807\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1651 - val_loss: 0.1768\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1746\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1704\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1661\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1524 - val_loss: 0.1639\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1478 - val_loss: 0.1603\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1466 - val_loss: 0.1612\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1487 - val_loss: 0.1577\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.1552\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 0.1552\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.1543\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 0.1515\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1377 - val_loss: 0.1496\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1347 - val_loss: 0.1511\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 0.1471\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1355 - val_loss: 0.1480\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1344 - val_loss: 0.1483\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1446\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 0.1445\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.1443\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1282 - val_loss: 0.1448\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.1431\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1417\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 0.1402\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1268 - val_loss: 0.1416\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1267 - val_loss: 0.1445\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1270 - val_loss: 0.1410\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1253 - val_loss: 0.1415\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1267 - val_loss: 0.1408\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1270 - val_loss: 0.1402\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1253 - val_loss: 0.1402\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1236 - val_loss: 0.1382\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1241 - val_loss: 0.1390\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1390\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1222 - val_loss: 0.1390\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.1384\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1235 - val_loss: 0.1374\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1220 - val_loss: 0.1399\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1413\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1223 - val_loss: 0.1403\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1224 - val_loss: 0.1388\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1374\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.1381\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1373\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.1370\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1204 - val_loss: 0.1387\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.1374\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.1377\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1374\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1373\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1372\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1377\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1176 - val_loss: 0.1375\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1177 - val_loss: 0.1385\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.1387\n",
      "Epoch 00071: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.5341 - val_loss: 1.1596\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9328 - val_loss: 0.4557\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4366 - val_loss: 0.3663\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3355 - val_loss: 0.2826\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2663 - val_loss: 0.2394\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2294 - val_loss: 0.2142\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1990 - val_loss: 0.1952\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1839 - val_loss: 0.1816\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1729 - val_loss: 0.1709\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1618 - val_loss: 0.1621\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1541\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1522\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1426\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1356 - val_loss: 0.1387\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1319 - val_loss: 0.1356\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1268 - val_loss: 0.1300\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1266\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1203 - val_loss: 0.1238\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1155 - val_loss: 0.1212\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1167\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.1164\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1086 - val_loss: 0.1130\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1111\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1046 - val_loss: 0.1069\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.1063\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1045\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.1025\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.1011\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.1020\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0964 - val_loss: 0.1015\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0943 - val_loss: 0.0993\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.0962\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0930 - val_loss: 0.0962\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0952\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0930\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.0920\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0866 - val_loss: 0.0916\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0906\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0891\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.0887\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0889\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0884\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0859\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0877\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0865\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0838\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0832\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0844\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0790 - val_loss: 0.0832\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0827\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0836\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0815\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0825\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0831\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0829\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0812\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0826\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0812\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0808\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0817\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0757 - val_loss: 0.0803\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0812\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0829\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0807\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0839\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0828\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0818\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0824\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0809\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0735 - val_loss: 0.0797\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0827\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0803\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0820\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0809\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0792\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0803\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0815\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0817\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0804\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0807\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0813\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0811\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0809\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0788\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0819\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0792\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0822\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0794\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0708 - val_loss: 0.0803\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0696 - val_loss: 0.0812\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0828\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0789\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0806\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0796\n",
      "Epoch 00094: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 3.9536 - val_loss: 2.6628\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 2.2065 - val_loss: 0.9606\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.7193 - val_loss: 0.2472\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.1239\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1070\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1019 - val_loss: 0.0980\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0959 - val_loss: 0.0910\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0854\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0796\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0739\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0685\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0644\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0606\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0565\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0539 - val_loss: 0.0539\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0513 - val_loss: 0.0517\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.0489\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0456 - val_loss: 0.0475\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0457\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0438\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0426\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0411\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0401\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0392\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0380\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0370\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0365\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0356\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0350\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0348\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0342\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0344\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0335\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0336\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0328\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0335\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0333\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0321\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0327\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0326\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0316\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0321\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0320\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0313\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0309\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0309\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0298\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0302\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0302\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0298\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0294\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0304\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0287\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0291\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0286\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0286\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0283\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0279\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0273\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0278\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0274\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0279\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0265\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0268\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0269\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0264\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0262\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0259\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0259\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0254\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0251\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0252\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0254\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0255\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0244\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0250\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0248\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0237\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0237\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0244\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0238\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0232\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0231\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0235\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0238\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0229\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0238\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0234\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0231\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0230\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0227\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0230\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0216\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0231\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0228\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0222\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0224\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0225\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0213\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0222\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0217\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0229\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0222\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0221\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0215\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0215\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0209\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0223\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0209\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0216\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0238\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0206\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0215\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0207\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0213\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0212\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0214\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0213\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0210\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0216\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0208\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0204\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0205\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0204\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0203\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0210\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0210\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0217\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0203\n",
      "Epoch 00142: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73440895d08d476381f221b6a37d35bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0658 - val_loss: 0.0434\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0320\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0259\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0204\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0219\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0225\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0242\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0230\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0195\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0208\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0211\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0218\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0238\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0218\n",
      "Epoch 00023: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3638 - val_loss: 0.1548\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1386 - val_loss: 0.1128\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1075 - val_loss: 0.1078\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.1016\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0959\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0939\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0990\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0863 - val_loss: 0.0925\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0837 - val_loss: 0.0876\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0865\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0855\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0968\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0810 - val_loss: 0.0858\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0928\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0867\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0895\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0918\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0873\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0872\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0832\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0855\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0838\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0854\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0738 - val_loss: 0.0881\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0888\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0745 - val_loss: 0.0836\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0868\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0841\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0916\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0755 - val_loss: 0.0872\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 1s 7ms/step - loss: 0.8467 - val_loss: 0.2833\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2570 - val_loss: 0.2157\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1978 - val_loss: 0.1947\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1640\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1553 - val_loss: 0.1613\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.1532\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1473\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.1504\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1384 - val_loss: 0.1434\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1458\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 0.1427\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1418\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.1444\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1372 - val_loss: 0.1408\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1382\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 0.1386\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1374\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1307 - val_loss: 0.1342\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1275 - val_loss: 0.1363\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1273 - val_loss: 0.1325\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1234 - val_loss: 0.1344\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.1438\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.1355\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1246 - val_loss: 0.1343\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1283 - val_loss: 0.1386\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.1395\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1239 - val_loss: 0.1404\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1246 - val_loss: 0.1389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1341\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1216 - val_loss: 0.1360\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3690 - val_loss: 0.2835\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2605 - val_loss: 0.1809\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1644 - val_loss: 0.1515\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1340 - val_loss: 0.1240\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1163 - val_loss: 0.1143\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1078 - val_loss: 0.1091\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1027\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.0977\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0952\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0915\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0850\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0880\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0925\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.1016\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0873\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0967\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0874\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0992\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0859\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0822\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0839\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0846\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0861\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0819\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0788 - val_loss: 0.0788\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0841\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0851\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0852\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0845\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0826\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0724 - val_loss: 0.0855\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0841\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0858\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0901\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0847\n",
      "Epoch 00035: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.5132 - val_loss: 0.3138\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2393 - val_loss: 0.0794\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0568\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0458\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0386\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0361\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0344\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0332\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0310\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0277\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0264\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0277\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0268\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0255\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0262\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0251\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0251\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0218\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0236\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0254\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0213\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0237\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0218\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0211\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0193\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0210\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0218\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0209\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0187\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0251\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0189\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0219\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0200\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0203\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0194\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0265\n",
      "Epoch 00049: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dbfcb1ffce41b3be45267e23bafb18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.5438 - val_loss: 0.5824\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6194 - val_loss: 0.5776\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4178 - val_loss: 0.1811\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1686 - val_loss: 0.0718\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0589\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.1172\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0425\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0344\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0292\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0319\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0250\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0332\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0280\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0241\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0213\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0233\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0221\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0221\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0222\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0239\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0204\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0229\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0190\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0198\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0199\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0208\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0192\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0199\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0218\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0189\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0214\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0195\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0199\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0192\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0196\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0194\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0207\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0194\n",
      "Epoch 00046: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3898 - val_loss: 0.5643\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4325 - val_loss: 0.2318\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2102 - val_loss: 0.1503\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1074\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.0930\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0951 - val_loss: 0.0924\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0904 - val_loss: 0.0895\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.0906\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0925\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0931\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0965\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0975\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0944\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0934\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0917\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0886\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0940\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0888\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0886\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0881\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0926\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0919\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0851\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0866\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0894\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0809 - val_loss: 0.0860\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0885\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0876\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0884\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0807 - val_loss: 0.0894\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0864\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0860\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0875\n",
      "Epoch 00033: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.0971 - val_loss: 0.4005\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3377 - val_loss: 0.1942\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1751 - val_loss: 0.1655\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1592 - val_loss: 0.1659\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1470\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1395 - val_loss: 0.1427\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1371\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1544\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1429 - val_loss: 0.1476\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1385\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1376 - val_loss: 0.1375\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1336 - val_loss: 0.1379\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.1361\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1318 - val_loss: 0.1352\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.1328\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1390\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1376\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1356 - val_loss: 0.1360\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1310\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1276 - val_loss: 0.1394\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1296\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.1308\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.1293\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.1364\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 0.1304\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1340 - val_loss: 0.1395\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1374\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1280 - val_loss: 0.1330\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.1467\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1355 - val_loss: 0.1339\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.1354\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1336 - val_loss: 0.1412\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1311 - val_loss: 0.1374\n",
      "Epoch 00033: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4125 - val_loss: 0.4468\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5066 - val_loss: 0.2072\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1640 - val_loss: 0.1106\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.0988\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1002 - val_loss: 0.0952\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.0965\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.1018\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.0915\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0915\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0856 - val_loss: 0.0880\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0818\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0850\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0837\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0818\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0813\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0809\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0802 - val_loss: 0.0796\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0819\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0800\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0849\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0815\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0822 - val_loss: 0.0793\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0831\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0856\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0932\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0900\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0830 - val_loss: 0.0812\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0766 - val_loss: 0.0818\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0767 - val_loss: 0.0807\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0797 - val_loss: 0.0855\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0804 - val_loss: 0.0831\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0841\n",
      "Epoch 00032: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 1.3621 - val_loss: 1.1839\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.9198 - val_loss: 0.2020\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3748 - val_loss: 0.1406\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1072 - val_loss: 0.0667\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0524 - val_loss: 0.0498\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0386\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0320\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0461\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0251\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0216\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0278\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0248\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0220\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0225\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0319\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0224\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0425\n",
      "Epoch 00020: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249374843a7942a8b3de3b51dc32168b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487f525b42b341cf88f9868bad31bd46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed7953211cf44c8b408d75484ae82c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0903 - val_loss: 0.0878\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0878 - val_loss: 0.0853\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0853 - val_loss: 0.0828\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0827 - val_loss: 0.0803\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0801 - val_loss: 0.0777\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0773 - val_loss: 0.0751\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0724\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0725 - val_loss: 0.0698\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.0673\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0684 - val_loss: 0.0651\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0662 - val_loss: 0.0628\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0634 - val_loss: 0.0605\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0612 - val_loss: 0.0580\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0588 - val_loss: 0.0558\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0569 - val_loss: 0.0541\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0559 - val_loss: 0.0529\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0543 - val_loss: 0.0519\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0533 - val_loss: 0.0508\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0524 - val_loss: 0.0498\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0518 - val_loss: 0.0490\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0506 - val_loss: 0.0478\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0494 - val_loss: 0.0468\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0489 - val_loss: 0.0460\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0480 - val_loss: 0.0452\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0472 - val_loss: 0.0443\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0436\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0456 - val_loss: 0.0426\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0418\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0438 - val_loss: 0.0410\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0427 - val_loss: 0.0402\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0426 - val_loss: 0.0396\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0389\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0383\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0378\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.0371\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0395 - val_loss: 0.0365\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.0360\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0388 - val_loss: 0.0356\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.0352\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0349\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0371 - val_loss: 0.0345\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0340\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0361 - val_loss: 0.0337\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0357 - val_loss: 0.0333\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0353 - val_loss: 0.0330\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0351 - val_loss: 0.0326\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.0324\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0347 - val_loss: 0.0322\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0343 - val_loss: 0.0319\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0338 - val_loss: 0.0317\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0316\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0335 - val_loss: 0.0313\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0334 - val_loss: 0.0311\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.0309\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0308\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0306\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0305\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0304\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0302\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0316 - val_loss: 0.0301\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0299\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0298\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0308 - val_loss: 0.0298\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0295\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0294\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.0293\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0292\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0289\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.0288\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0295 - val_loss: 0.0287\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0285\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.0284\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.0283\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.0281\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0289 - val_loss: 0.0280\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0279\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0278\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0283 - val_loss: 0.0278\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0277\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0276\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0274\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0274\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0275 - val_loss: 0.0273\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0273\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0270\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0269\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0269\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0269\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0267\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0267\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0267\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0266\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0266\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0265\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0262 - val_loss: 0.0264\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0265\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0264\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0264\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.0263\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0256 - val_loss: 0.0264\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0262\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0262\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.0262\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0262\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0262\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0261\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0260\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0260\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0260\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0259\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0258\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0259\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0259\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0258\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0258\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0258\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.0258\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0258\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0256\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0258\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0244 - val_loss: 0.0257\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0256\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0257\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0257\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.0256\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0256\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0238 - val_loss: 0.0255\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0255\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0256\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0254\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0254\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0255\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0254\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0253\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0254\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0251\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0254\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0252\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0253\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0252\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0251\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0252\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0252\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0250\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0248\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0250\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0249\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0248\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0248\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0248\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0245\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0246\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0246\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0245\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0244\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0245\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0243\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0245\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0243\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0244\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0242\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0244\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0242\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0242\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0243\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0241\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0241\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0242\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0239\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0240\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0238\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0241\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0238\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0239\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0238\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0238\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0237\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0237\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0238\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 40ms/step - loss: 0.5665 - val_loss: 0.5613\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5475 - val_loss: 0.5423\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5327 - val_loss: 0.5255\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5150 - val_loss: 0.5097\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4990 - val_loss: 0.4937\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4854 - val_loss: 0.4775\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4702 - val_loss: 0.4611\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4537 - val_loss: 0.4443\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4400 - val_loss: 0.4267\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4229 - val_loss: 0.4088\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4050 - val_loss: 0.3904\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3854 - val_loss: 0.3711\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3674 - val_loss: 0.3508\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3493 - val_loss: 0.3315\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3297 - val_loss: 0.3150\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3131 - val_loss: 0.3010\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3001 - val_loss: 0.2887\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2895 - val_loss: 0.2775\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2764 - val_loss: 0.2671\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2647 - val_loss: 0.2575\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2568 - val_loss: 0.2480\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2490 - val_loss: 0.2394\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2382 - val_loss: 0.2315\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2324 - val_loss: 0.2239\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2250 - val_loss: 0.2172\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2185 - val_loss: 0.2115\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2132 - val_loss: 0.2076\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2065 - val_loss: 0.2022\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2031 - val_loss: 0.1986\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2007 - val_loss: 0.1949\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1968 - val_loss: 0.1921\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.1894\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1901 - val_loss: 0.1875\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1886 - val_loss: 0.1848\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1852 - val_loss: 0.1831\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1852 - val_loss: 0.1813\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1794\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1815 - val_loss: 0.1776\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1793 - val_loss: 0.1762\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.1749\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1759 - val_loss: 0.1735\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1745 - val_loss: 0.1717\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1718 - val_loss: 0.1707\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1699 - val_loss: 0.1693\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1714 - val_loss: 0.1683\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1689 - val_loss: 0.1674\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1679 - val_loss: 0.1665\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1653 - val_loss: 0.1656\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1635 - val_loss: 0.1643\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1632 - val_loss: 0.1633\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1637 - val_loss: 0.1624\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1629 - val_loss: 0.1619\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1607\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1588 - val_loss: 0.1599\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1588 - val_loss: 0.1586\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1561 - val_loss: 0.1577\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1576 - val_loss: 0.1570\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1550 - val_loss: 0.1562\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1540 - val_loss: 0.1556\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1540 - val_loss: 0.1546\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1524 - val_loss: 0.1538\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1511 - val_loss: 0.1534\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1512 - val_loss: 0.1526\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1502 - val_loss: 0.1520\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1485 - val_loss: 0.1509\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1493 - val_loss: 0.1505\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1476 - val_loss: 0.1502\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1460 - val_loss: 0.1490\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1451 - val_loss: 0.1484\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1438 - val_loss: 0.1476\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1434 - val_loss: 0.1472\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1418 - val_loss: 0.1468\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1422 - val_loss: 0.1461\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1427 - val_loss: 0.1456\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.1448\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1402 - val_loss: 0.1443\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1396 - val_loss: 0.1433\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1387 - val_loss: 0.1431\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1376 - val_loss: 0.1426\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1375 - val_loss: 0.1420\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1361 - val_loss: 0.1414\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1357 - val_loss: 0.1408\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1352 - val_loss: 0.1405\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1341 - val_loss: 0.1401\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1339 - val_loss: 0.1388\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1347 - val_loss: 0.1390\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1333 - val_loss: 0.1383\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1324 - val_loss: 0.1379\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1316 - val_loss: 0.1376\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1325 - val_loss: 0.1369\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1298 - val_loss: 0.1366\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1311 - val_loss: 0.1361\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1290 - val_loss: 0.1357\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1292 - val_loss: 0.1352\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1280 - val_loss: 0.1346\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1282 - val_loss: 0.1343\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1275 - val_loss: 0.1335\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1273 - val_loss: 0.1332\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1266 - val_loss: 0.1331\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1248 - val_loss: 0.1329\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1254 - val_loss: 0.1319\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1261 - val_loss: 0.1320\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1257 - val_loss: 0.1312\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1248 - val_loss: 0.1308\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1244 - val_loss: 0.1309\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1232 - val_loss: 0.1297\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1215 - val_loss: 0.1296\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1233 - val_loss: 0.1294\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1219 - val_loss: 0.1288\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.1286\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1209 - val_loss: 0.1280\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.1275\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1196 - val_loss: 0.1276\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1204 - val_loss: 0.1266\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.1266\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1183 - val_loss: 0.1261\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1168 - val_loss: 0.1260\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1171 - val_loss: 0.1256\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1176 - val_loss: 0.1253\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1170 - val_loss: 0.1248\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1163 - val_loss: 0.1248\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1172 - val_loss: 0.1239\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1163 - val_loss: 0.1240\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1148 - val_loss: 0.1239\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1144 - val_loss: 0.1231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1155 - val_loss: 0.1233\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1159 - val_loss: 0.1222\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1143 - val_loss: 0.1225\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1145 - val_loss: 0.1219\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1137 - val_loss: 0.1216\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1141 - val_loss: 0.1215\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1120 - val_loss: 0.1212\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1120 - val_loss: 0.1209\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1110 - val_loss: 0.1204\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1116 - val_loss: 0.1200\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1109 - val_loss: 0.1198\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1111 - val_loss: 0.1196\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1114 - val_loss: 0.1197\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1105 - val_loss: 0.1188\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1098 - val_loss: 0.1191\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1102 - val_loss: 0.1183\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1087 - val_loss: 0.1186\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1097 - val_loss: 0.1177\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1183\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1096 - val_loss: 0.1172\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1092 - val_loss: 0.1172\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1087 - val_loss: 0.1175\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1086 - val_loss: 0.1172\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1072 - val_loss: 0.1164\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.1165\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1087 - val_loss: 0.1165\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.1159\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1068 - val_loss: 0.1157\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1065 - val_loss: 0.1156\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1074 - val_loss: 0.1152\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1058 - val_loss: 0.1152\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1048 - val_loss: 0.1148\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1054 - val_loss: 0.1145\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1049 - val_loss: 0.1145\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1051 - val_loss: 0.1138\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1045 - val_loss: 0.1138\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1023 - val_loss: 0.1137\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1027 - val_loss: 0.1137\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1030 - val_loss: 0.1130\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1032 - val_loss: 0.1131\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1029 - val_loss: 0.1129\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1032 - val_loss: 0.1122\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1024 - val_loss: 0.1122\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1031 - val_loss: 0.1118\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1015 - val_loss: 0.1121\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1025 - val_loss: 0.1114\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1014 - val_loss: 0.1118\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.1114\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.1106\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1008 - val_loss: 0.1109\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1001 - val_loss: 0.1105\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0998 - val_loss: 0.1103\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1002 - val_loss: 0.1102\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.1100\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0996 - val_loss: 0.1101\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0980 - val_loss: 0.1097\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.1091\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0984 - val_loss: 0.1096\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0980 - val_loss: 0.1085\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0992 - val_loss: 0.1089\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0979 - val_loss: 0.1088\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0984 - val_loss: 0.1085\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0973 - val_loss: 0.1078\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0975 - val_loss: 0.1081\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0979 - val_loss: 0.1078\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0961 - val_loss: 0.1078\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0962 - val_loss: 0.1074\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1070\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0968 - val_loss: 0.1074\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0960 - val_loss: 0.1067\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0972 - val_loss: 0.1067\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0962 - val_loss: 0.1063\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0960 - val_loss: 0.1066\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0954 - val_loss: 0.1057\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0959 - val_loss: 0.1059\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8602 - val_loss: 1.8241\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8029 - val_loss: 1.7692\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7484 - val_loss: 1.7139\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6935 - val_loss: 1.6576\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6393 - val_loss: 1.5996\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5768 - val_loss: 1.5398\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5202 - val_loss: 1.4778\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4555 - val_loss: 1.4136\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3919 - val_loss: 1.3475\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3267 - val_loss: 1.2800\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2575 - val_loss: 1.2108\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1883 - val_loss: 1.1404\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.1176 - val_loss: 1.0688\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0589 - val_loss: 0.9990\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9849 - val_loss: 0.9314\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9246 - val_loss: 0.8697\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8715 - val_loss: 0.8144\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8218 - val_loss: 0.7664\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.7784 - val_loss: 0.7259\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7425 - val_loss: 0.6900\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.6571\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.6273\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6509 - val_loss: 0.6010\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.5777\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6048 - val_loss: 0.5565\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.5373\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5649 - val_loss: 0.5187\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5503 - val_loss: 0.5017\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5279 - val_loss: 0.4859\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5125 - val_loss: 0.4717\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5015 - val_loss: 0.4587\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4804 - val_loss: 0.4473\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4720 - val_loss: 0.4373\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4607 - val_loss: 0.4277\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4489 - val_loss: 0.4194\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4413 - val_loss: 0.4119\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4322 - val_loss: 0.4052\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4244 - val_loss: 0.3991\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4177 - val_loss: 0.3932\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4070 - val_loss: 0.3878\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4009 - val_loss: 0.3829\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3964 - val_loss: 0.3782\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3865 - val_loss: 0.3741\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3842 - val_loss: 0.3700\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3823 - val_loss: 0.3662\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3730 - val_loss: 0.3623\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3699 - val_loss: 0.3587\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3669 - val_loss: 0.3552\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3607 - val_loss: 0.3517\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3561 - val_loss: 0.3483\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3531 - val_loss: 0.3451\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3464 - val_loss: 0.3421\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3464 - val_loss: 0.3390\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3420 - val_loss: 0.3362\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3381 - val_loss: 0.3335\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3365 - val_loss: 0.3309\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3382 - val_loss: 0.3282\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3324 - val_loss: 0.3256\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3301 - val_loss: 0.3230\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3302 - val_loss: 0.3206\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3243 - val_loss: 0.3182\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3229 - val_loss: 0.3161\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3189 - val_loss: 0.3137\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3198 - val_loss: 0.3115\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3175 - val_loss: 0.3095\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.3075\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3108 - val_loss: 0.3054\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3078 - val_loss: 0.3035\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3074 - val_loss: 0.3018\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3042 - val_loss: 0.2998\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3003 - val_loss: 0.2980\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3026 - val_loss: 0.2964\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2970 - val_loss: 0.2944\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2962 - val_loss: 0.2927\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2954 - val_loss: 0.2908\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2913 - val_loss: 0.2892\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2889 - val_loss: 0.2875\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2889 - val_loss: 0.2859\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2839 - val_loss: 0.2844\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2855 - val_loss: 0.2829\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2812 - val_loss: 0.2814\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2819 - val_loss: 0.2798\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2808 - val_loss: 0.2786\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2759 - val_loss: 0.2770\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2774 - val_loss: 0.2758\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2730 - val_loss: 0.2745\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2750 - val_loss: 0.2732\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2722 - val_loss: 0.2720\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2700 - val_loss: 0.2706\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2681 - val_loss: 0.2694\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2675 - val_loss: 0.2682\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2652 - val_loss: 0.2669\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2630 - val_loss: 0.2659\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2638 - val_loss: 0.2649\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2616 - val_loss: 0.2636\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.2622\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2558 - val_loss: 0.2609\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2572 - val_loss: 0.2597\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2527 - val_loss: 0.2587\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2545 - val_loss: 0.2577\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2539 - val_loss: 0.2566\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2526 - val_loss: 0.2557\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2494 - val_loss: 0.2544\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2512 - val_loss: 0.2534\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2477 - val_loss: 0.2526\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2495 - val_loss: 0.2521\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2467 - val_loss: 0.2513\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2440 - val_loss: 0.2497\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2426 - val_loss: 0.2490\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2405 - val_loss: 0.2479\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2425 - val_loss: 0.2469\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2399 - val_loss: 0.2463\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.2404 - val_loss: 0.2452\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.2382 - val_loss: 0.2441\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2353 - val_loss: 0.2433\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2357 - val_loss: 0.2423\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2357 - val_loss: 0.2414\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2324 - val_loss: 0.2406\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2308 - val_loss: 0.2397\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2332 - val_loss: 0.2387\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2299 - val_loss: 0.2376\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2307 - val_loss: 0.2368\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2287 - val_loss: 0.2359\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2275 - val_loss: 0.2351\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2262 - val_loss: 0.2341\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2264 - val_loss: 0.2334\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2248 - val_loss: 0.2322\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2254 - val_loss: 0.2311\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2209 - val_loss: 0.2304\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2210 - val_loss: 0.2298\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2218 - val_loss: 0.2285\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2213 - val_loss: 0.2277\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2205 - val_loss: 0.2269\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2208 - val_loss: 0.2262\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2166 - val_loss: 0.2251\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.2242\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.2235\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2138 - val_loss: 0.2227\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2154 - val_loss: 0.2219\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2122 - val_loss: 0.2212\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2115 - val_loss: 0.2205\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2093 - val_loss: 0.2196\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2109 - val_loss: 0.2192\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2102 - val_loss: 0.2182\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2060 - val_loss: 0.2172\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2081 - val_loss: 0.2166\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2073 - val_loss: 0.2157\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2070 - val_loss: 0.2150\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2052 - val_loss: 0.2143\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2048 - val_loss: 0.2135\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2033 - val_loss: 0.2124\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2027 - val_loss: 0.2119\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2052 - val_loss: 0.2114\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2023 - val_loss: 0.2105\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2022 - val_loss: 0.2097\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.2092\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2006 - val_loss: 0.2085\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2004 - val_loss: 0.2075\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1998 - val_loss: 0.2068\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1968 - val_loss: 0.2065\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1957 - val_loss: 0.2057\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1980 - val_loss: 0.2051\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1952 - val_loss: 0.2039\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1940 - val_loss: 0.2041\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1945 - val_loss: 0.2029\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1935 - val_loss: 0.2024\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1928 - val_loss: 0.2016\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1939 - val_loss: 0.2012\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1922 - val_loss: 0.2003\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1905 - val_loss: 0.2000\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1910 - val_loss: 0.1992\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1890 - val_loss: 0.1985\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.1977\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1894 - val_loss: 0.1975\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1870 - val_loss: 0.1963\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1862 - val_loss: 0.1964\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1869 - val_loss: 0.1953\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1884 - val_loss: 0.1948\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.1944\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1860 - val_loss: 0.1934\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1851 - val_loss: 0.1931\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1863 - val_loss: 0.1923\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1851 - val_loss: 0.1921\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1832 - val_loss: 0.1910\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1830 - val_loss: 0.1905\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1803 - val_loss: 0.1898\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1817 - val_loss: 0.1899\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1809 - val_loss: 0.1893\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1812 - val_loss: 0.1884\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1784 - val_loss: 0.1877\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1798 - val_loss: 0.1876\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1815 - val_loss: 0.1869\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1787 - val_loss: 0.1864\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1783 - val_loss: 0.1860\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1770 - val_loss: 0.1858\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1776 - val_loss: 0.1843\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1767 - val_loss: 0.1846\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1743 - val_loss: 0.1841\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1755 - val_loss: 0.1834\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1751 - val_loss: 0.1832\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.1681 - val_loss: 3.0940\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.0964 - val_loss: 3.0123\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.0058 - val_loss: 2.9299\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.9274 - val_loss: 2.8462\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.8484 - val_loss: 2.7615\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.7670 - val_loss: 2.6747\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.6843 - val_loss: 2.5860\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.5826 - val_loss: 2.4944\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.5029 - val_loss: 2.4000\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.4098 - val_loss: 2.3026\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.3079 - val_loss: 2.2033\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.2014 - val_loss: 2.1040\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1083 - val_loss: 2.0044\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0047 - val_loss: 1.9051\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9247 - val_loss: 1.8085\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8146 - val_loss: 1.7144\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7280 - val_loss: 1.6232\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6486 - val_loss: 1.5355\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5489 - val_loss: 1.4514\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4760 - val_loss: 1.3707\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3889 - val_loss: 1.2914\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3218 - val_loss: 1.2165\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2505 - val_loss: 1.1466\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1849 - val_loss: 1.0822\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1111 - val_loss: 1.0213\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0620 - val_loss: 0.9640\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0123 - val_loss: 0.9094\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9496 - val_loss: 0.8588\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9057 - val_loss: 0.8128\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8528 - val_loss: 0.7702\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8072 - val_loss: 0.7299\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7571 - val_loss: 0.6928\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.6590\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.6282\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6005\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.5756\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.5526\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5674 - val_loss: 0.5318\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5420 - val_loss: 0.5130\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5283 - val_loss: 0.4958\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4966 - val_loss: 0.4799\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4931 - val_loss: 0.4659\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4711 - val_loss: 0.4533\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4528 - val_loss: 0.4425\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4406 - val_loss: 0.4328\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4285 - val_loss: 0.4238\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4211 - val_loss: 0.4152\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4048 - val_loss: 0.4074\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4040 - val_loss: 0.4000\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3905 - val_loss: 0.3932\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3862 - val_loss: 0.3868\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3775 - val_loss: 0.3808\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3681 - val_loss: 0.3750\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3650 - val_loss: 0.3695\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3561 - val_loss: 0.3642\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3516 - val_loss: 0.3592\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3493 - val_loss: 0.3543\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3436 - val_loss: 0.3497\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3361 - val_loss: 0.3454\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3362 - val_loss: 0.3412\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3289 - val_loss: 0.3372\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3258 - val_loss: 0.3331\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3195 - val_loss: 0.3290\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3173 - val_loss: 0.3251\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3109 - val_loss: 0.3212\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3083 - val_loss: 0.3175\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3013 - val_loss: 0.3139\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.3105\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2951 - val_loss: 0.3071\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2911 - val_loss: 0.3037\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2904 - val_loss: 0.3003\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2828 - val_loss: 0.2971\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2831 - val_loss: 0.2939\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.2907\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2738 - val_loss: 0.2876\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2720 - val_loss: 0.2846\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2692 - val_loss: 0.2815\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2684 - val_loss: 0.2786\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2644 - val_loss: 0.2756\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2607 - val_loss: 0.2728\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2607 - val_loss: 0.2701\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2569 - val_loss: 0.2675\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2517 - val_loss: 0.2649\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2487 - val_loss: 0.2623\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2461 - val_loss: 0.2597\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2472 - val_loss: 0.2572\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2440 - val_loss: 0.2548\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2411 - val_loss: 0.2525\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2360 - val_loss: 0.2503\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.2478\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.2456\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.2434\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2285 - val_loss: 0.2413\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2278 - val_loss: 0.2393\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2292 - val_loss: 0.2372\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2239 - val_loss: 0.2352\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2214 - val_loss: 0.2335\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2198 - val_loss: 0.2317\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2188 - val_loss: 0.2300\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2152 - val_loss: 0.2284\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2161 - val_loss: 0.2268\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2117 - val_loss: 0.2253\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2131 - val_loss: 0.2237\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2117 - val_loss: 0.2221\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2084 - val_loss: 0.2205\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2064 - val_loss: 0.2191\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2069 - val_loss: 0.2178\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2059 - val_loss: 0.2162\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2049 - val_loss: 0.2149\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2014 - val_loss: 0.2136\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2008 - val_loss: 0.2123\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2007 - val_loss: 0.2108\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1989 - val_loss: 0.2094\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1961 - val_loss: 0.2081\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1951 - val_loss: 0.2070\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1955 - val_loss: 0.2058\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1931 - val_loss: 0.2045\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1934 - val_loss: 0.2032\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1908 - val_loss: 0.2021\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1908 - val_loss: 0.2009\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1881 - val_loss: 0.1998\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1882 - val_loss: 0.1987\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1863 - val_loss: 0.1977\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1830 - val_loss: 0.1967\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1851 - val_loss: 0.1955\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1835 - val_loss: 0.1944\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1851 - val_loss: 0.1934\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1843 - val_loss: 0.1924\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1820 - val_loss: 0.1914\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1804 - val_loss: 0.1905\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1801 - val_loss: 0.1897\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1786 - val_loss: 0.1887\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1777 - val_loss: 0.1878\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1772 - val_loss: 0.1870\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1758 - val_loss: 0.1861\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1746 - val_loss: 0.1853\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.1846\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1750 - val_loss: 0.1839\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1722 - val_loss: 0.1830\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1749 - val_loss: 0.1823\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1714 - val_loss: 0.1815\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1694 - val_loss: 0.1808\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1701 - val_loss: 0.1800\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1694 - val_loss: 0.1791\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1670 - val_loss: 0.1785\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1672 - val_loss: 0.1779\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1676 - val_loss: 0.1771\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1682 - val_loss: 0.1762\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1685 - val_loss: 0.1756\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1653 - val_loss: 0.1751\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1663 - val_loss: 0.1743\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1637 - val_loss: 0.1735\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1630 - val_loss: 0.1729\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1631 - val_loss: 0.1724\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1716\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1710\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1614 - val_loss: 0.1703\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1697\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1692\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1598 - val_loss: 0.1686\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1567 - val_loss: 0.1679\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1590 - val_loss: 0.1674\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1582 - val_loss: 0.1667\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1570 - val_loss: 0.1662\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1552 - val_loss: 0.1655\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1543 - val_loss: 0.1652\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1561 - val_loss: 0.1645\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1556 - val_loss: 0.1641\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1541 - val_loss: 0.1635\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1536 - val_loss: 0.1632\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1627\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1526 - val_loss: 0.1623\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1515 - val_loss: 0.1615\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1529 - val_loss: 0.1613\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1508 - val_loss: 0.1607\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1513 - val_loss: 0.1601\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1502 - val_loss: 0.1597\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1491 - val_loss: 0.1592\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1483 - val_loss: 0.1586\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1487 - val_loss: 0.1581\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1478 - val_loss: 0.1577\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1467 - val_loss: 0.1573\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1480 - val_loss: 0.1567\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1458 - val_loss: 0.1563\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1470 - val_loss: 0.1560\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1456 - val_loss: 0.1554\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1457 - val_loss: 0.1550\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1454 - val_loss: 0.1545\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1458 - val_loss: 0.1541\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1444 - val_loss: 0.1534\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1443 - val_loss: 0.1531\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1437 - val_loss: 0.1524\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1442 - val_loss: 0.1519\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1421 - val_loss: 0.1516\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1433 - val_loss: 0.1509\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1428 - val_loss: 0.1507\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1415 - val_loss: 0.1500\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.1500\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1416 - val_loss: 0.1495\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1394 - val_loss: 0.1491\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.8052 - val_loss: 3.7167\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.6950 - val_loss: 3.6154\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.6140 - val_loss: 3.5142\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.4842 - val_loss: 3.4118\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.3894 - val_loss: 3.3082\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.2907 - val_loss: 3.2028\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.1712 - val_loss: 3.0952\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.0638 - val_loss: 2.9843\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.9598 - val_loss: 2.8698\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.8455 - val_loss: 2.7522\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.7203 - val_loss: 2.6317\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.5994 - val_loss: 2.5087\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 2.4838 - val_loss: 2.3839\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.3550 - val_loss: 2.2567\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.2120 - val_loss: 2.1278\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0965 - val_loss: 1.9990\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9854 - val_loss: 1.8724\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.8581 - val_loss: 1.7511\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.7406 - val_loss: 1.6336\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6346 - val_loss: 1.5223\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.5216 - val_loss: 1.4174\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4219 - val_loss: 1.3182\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.3293 - val_loss: 1.2243\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2153 - val_loss: 1.1374\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1378 - val_loss: 1.0576\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0619 - val_loss: 0.9839\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9789 - val_loss: 0.9148\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.9201 - val_loss: 0.8487\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.8436 - val_loss: 0.7872\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7599 - val_loss: 0.7304\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7067 - val_loss: 0.6765\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6568 - val_loss: 0.6250\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5915 - val_loss: 0.5758\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5534 - val_loss: 0.5307\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5227 - val_loss: 0.4890\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4740 - val_loss: 0.4519\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4302 - val_loss: 0.4170\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3946 - val_loss: 0.3844\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3682 - val_loss: 0.3544\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3404 - val_loss: 0.3275\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3253 - val_loss: 0.3037\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2909 - val_loss: 0.2831\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2686 - val_loss: 0.2643\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2485 - val_loss: 0.2472\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2334 - val_loss: 0.2322\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2182 - val_loss: 0.2184\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2025 - val_loss: 0.2060\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1938 - val_loss: 0.1952\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1797 - val_loss: 0.1853\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1783 - val_loss: 0.1765\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1709 - val_loss: 0.1682\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1643 - val_loss: 0.1610\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1500 - val_loss: 0.1547\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1454 - val_loss: 0.1490\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1409 - val_loss: 0.1442\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1361 - val_loss: 0.1398\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1312 - val_loss: 0.1358\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1270 - val_loss: 0.1324\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1244 - val_loss: 0.1294\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1220 - val_loss: 0.1267\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1194 - val_loss: 0.1241\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1187 - val_loss: 0.1217\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1134 - val_loss: 0.1194\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1138 - val_loss: 0.1172\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1083 - val_loss: 0.1152\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1070 - val_loss: 0.1134\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1046 - val_loss: 0.1117\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1047 - val_loss: 0.1102\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1015 - val_loss: 0.1088\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0999 - val_loss: 0.1076\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 0.1064\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0978 - val_loss: 0.1054\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0977 - val_loss: 0.1043\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.1033\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0935 - val_loss: 0.1024\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0951 - val_loss: 0.1014\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0912 - val_loss: 0.1005\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0910 - val_loss: 0.0997\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0907 - val_loss: 0.0989\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0905 - val_loss: 0.0980\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0896 - val_loss: 0.0973\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0893 - val_loss: 0.0966\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0872 - val_loss: 0.0959\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0873 - val_loss: 0.0952\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0871 - val_loss: 0.0946\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0864 - val_loss: 0.0940\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0875 - val_loss: 0.0933\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0857 - val_loss: 0.0927\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0845 - val_loss: 0.0922\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0916\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0823 - val_loss: 0.0911\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0826 - val_loss: 0.0905\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0816 - val_loss: 0.0901\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0818 - val_loss: 0.0896\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0891\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0817 - val_loss: 0.0886\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0812 - val_loss: 0.0882\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0799 - val_loss: 0.0877\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0796 - val_loss: 0.0873\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0868\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.0864\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.0860\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0779 - val_loss: 0.0855\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0851\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.0847\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0768 - val_loss: 0.0842\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0770 - val_loss: 0.0838\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0762 - val_loss: 0.0834\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0758 - val_loss: 0.0831\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0761 - val_loss: 0.0827\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0751 - val_loss: 0.0824\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0757 - val_loss: 0.0821\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0818\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0744 - val_loss: 0.0815\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0729 - val_loss: 0.0811\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0808\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0738 - val_loss: 0.0805\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0730 - val_loss: 0.0802\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0723 - val_loss: 0.0799\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0724 - val_loss: 0.0796\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0727 - val_loss: 0.0793\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0719 - val_loss: 0.0789\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0707 - val_loss: 0.0786\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0717 - val_loss: 0.0783\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0697 - val_loss: 0.0780\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0711 - val_loss: 0.0777\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0773\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0682 - val_loss: 0.0770\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0698 - val_loss: 0.0767\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0684 - val_loss: 0.0764\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0688 - val_loss: 0.0761\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0680 - val_loss: 0.0758\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0683 - val_loss: 0.0755\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0673 - val_loss: 0.0752\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0677 - val_loss: 0.0749\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.0746\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0664 - val_loss: 0.0744\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0668 - val_loss: 0.0741\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0667 - val_loss: 0.0738\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0735\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0733\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0654 - val_loss: 0.0730\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0655 - val_loss: 0.0728\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0651 - val_loss: 0.0725\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0648 - val_loss: 0.0722\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0642 - val_loss: 0.0720\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0717\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0639 - val_loss: 0.0714\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0626 - val_loss: 0.0712\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0625 - val_loss: 0.0709\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0631 - val_loss: 0.0707\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0623 - val_loss: 0.0704\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0624 - val_loss: 0.0702\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0610 - val_loss: 0.0699\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.0697\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0619 - val_loss: 0.0694\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0602 - val_loss: 0.0692\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0601 - val_loss: 0.0690\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0616 - val_loss: 0.0687\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0606 - val_loss: 0.0685\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0608 - val_loss: 0.0683\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0681\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0597 - val_loss: 0.0678\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.0676\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0596 - val_loss: 0.0673\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0594 - val_loss: 0.0671\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0584 - val_loss: 0.0668\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.0666\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0580 - val_loss: 0.0663\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0578 - val_loss: 0.0660\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0575 - val_loss: 0.0658\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0581 - val_loss: 0.0655\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0571 - val_loss: 0.0653\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0567 - val_loss: 0.0650\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0566 - val_loss: 0.0648\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0568 - val_loss: 0.0645\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0558 - val_loss: 0.0643\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0564 - val_loss: 0.0640\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0553 - val_loss: 0.0637\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0556 - val_loss: 0.0635\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0549 - val_loss: 0.0632\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0548 - val_loss: 0.0630\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0545 - val_loss: 0.0627\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0625\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.0622\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0544 - val_loss: 0.0620\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0537 - val_loss: 0.0618\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0615\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0534 - val_loss: 0.0613\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0535 - val_loss: 0.0611\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0529 - val_loss: 0.0609\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0531 - val_loss: 0.0607\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0524 - val_loss: 0.0605\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0526 - val_loss: 0.0602\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0519 - val_loss: 0.0600\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0511 - val_loss: 0.0598\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0520 - val_loss: 0.0596\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0594\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0513 - val_loss: 0.0592\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0511 - val_loss: 0.0590\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5042d4f89b1e4ab9a585433ff3ca79b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0752 - val_loss: 0.0604\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0593 - val_loss: 0.0515\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0503 - val_loss: 0.0440\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0433 - val_loss: 0.0381\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0379 - val_loss: 0.0357\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0346 - val_loss: 0.0330\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0329 - val_loss: 0.0321\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0320 - val_loss: 0.0307\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0294 - val_loss: 0.0293\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0283 - val_loss: 0.0283\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0269 - val_loss: 0.0265\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0260\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0255 - val_loss: 0.0252\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0249\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0241 - val_loss: 0.0247\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0237 - val_loss: 0.0237\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0235\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0232 - val_loss: 0.0232\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0223 - val_loss: 0.0232\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0219 - val_loss: 0.0226\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0217 - val_loss: 0.0218\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0216\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0205\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0204\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0208\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0209\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0200\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0203\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0198\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0187 - val_loss: 0.0208\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0185 - val_loss: 0.0207\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0199\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0195\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0198\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0218\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0211\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.017 - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0202\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0197\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0200\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0165 - val_loss: 0.0199\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0167 - val_loss: 0.0197\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0169 - val_loss: 0.0204\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0206\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0201\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0166 - val_loss: 0.0203\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0164 - val_loss: 0.0207\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0160 - val_loss: 0.0208\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 00065: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.5935 - val_loss: 0.4893\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4648 - val_loss: 0.3616\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3417 - val_loss: 0.2764\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2703 - val_loss: 0.2389\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2257 - val_loss: 0.2040\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1977 - val_loss: 0.1823\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1815 - val_loss: 0.1690\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1675 - val_loss: 0.1604\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1583 - val_loss: 0.1523\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1479 - val_loss: 0.1443\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1397 - val_loss: 0.1381\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1358 - val_loss: 0.1338\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1278 - val_loss: 0.1324\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1234 - val_loss: 0.1257\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1202 - val_loss: 0.1234\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1157 - val_loss: 0.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1117 - val_loss: 0.1166\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1102 - val_loss: 0.1147\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1075 - val_loss: 0.1127\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1037 - val_loss: 0.1118\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1026 - val_loss: 0.1081\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1012 - val_loss: 0.1072\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0995 - val_loss: 0.1047\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0975 - val_loss: 0.1039\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0963 - val_loss: 0.1037\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0941 - val_loss: 0.1009\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.0996\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0912 - val_loss: 0.0991\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.0977\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0898 - val_loss: 0.0971\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0893 - val_loss: 0.0952\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0878 - val_loss: 0.0961\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0873 - val_loss: 0.0935\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0859 - val_loss: 0.0945\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0847 - val_loss: 0.0927\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0851 - val_loss: 0.0941\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0844 - val_loss: 0.0911\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0817 - val_loss: 0.0921\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0839 - val_loss: 0.0908\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0827 - val_loss: 0.0905\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0825 - val_loss: 0.0925\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0820 - val_loss: 0.0923\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0815 - val_loss: 0.0914\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0807 - val_loss: 0.0893\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0803 - val_loss: 0.0902\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0799 - val_loss: 0.0879\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0792 - val_loss: 0.0898\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0791 - val_loss: 0.0893\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0784 - val_loss: 0.0878\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0777 - val_loss: 0.0877\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0777 - val_loss: 0.0876\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0767 - val_loss: 0.0878\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0760 - val_loss: 0.0873\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0756 - val_loss: 0.0871\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0755 - val_loss: 0.0876\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0751 - val_loss: 0.0875\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0756 - val_loss: 0.0859\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0759 - val_loss: 0.0869\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.0861\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0743 - val_loss: 0.0863\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0749 - val_loss: 0.0879\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0744 - val_loss: 0.0860\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0735 - val_loss: 0.0854\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0733 - val_loss: 0.0872\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0724 - val_loss: 0.0862\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0726 - val_loss: 0.0857\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0734 - val_loss: 0.0877\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0720 - val_loss: 0.0861\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0720 - val_loss: 0.0851\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0725 - val_loss: 0.0865\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0721 - val_loss: 0.0862\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0717 - val_loss: 0.0877\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0717 - val_loss: 0.0857\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0723 - val_loss: 0.0863\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0700 - val_loss: 0.0859\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0710 - val_loss: 0.0871\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0705 - val_loss: 0.0848\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0705 - val_loss: 0.0865\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0705 - val_loss: 0.0870\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0711 - val_loss: 0.0856\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0703 - val_loss: 0.0852\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0701 - val_loss: 0.0881\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0707 - val_loss: 0.0862\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0698 - val_loss: 0.0842\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0703 - val_loss: 0.0862\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0698 - val_loss: 0.0864\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0684 - val_loss: 0.0856\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0689 - val_loss: 0.0861\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0699 - val_loss: 0.0848\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0693 - val_loss: 0.0870\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0690 - val_loss: 0.0865\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0715 - val_loss: 0.0871\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0695 - val_loss: 0.0841\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0690 - val_loss: 0.0841\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0679 - val_loss: 0.0854\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0684 - val_loss: 0.0854\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0688 - val_loss: 0.0840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0690 - val_loss: 0.0849\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0674 - val_loss: 0.0867\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0692 - val_loss: 0.0855\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0675 - val_loss: 0.0850\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0674 - val_loss: 0.0856\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0675 - val_loss: 0.0840\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0669 - val_loss: 0.0847\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0676 - val_loss: 0.0863\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0673 - val_loss: 0.0844\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0666 - val_loss: 0.0853\n",
      "Epoch 00108: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7498 - val_loss: 1.2691\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.1932 - val_loss: 0.8049\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7748 - val_loss: 0.6129\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6081 - val_loss: 0.4888\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4898 - val_loss: 0.4041\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4064 - val_loss: 0.3563\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3550 - val_loss: 0.3235\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3192 - val_loss: 0.3030\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2937 - val_loss: 0.2857\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2736 - val_loss: 0.2728\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2588 - val_loss: 0.2594\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2459 - val_loss: 0.2499\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2351 - val_loss: 0.2384\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2238 - val_loss: 0.2308\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2185 - val_loss: 0.2221\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2116 - val_loss: 0.2161\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2055 - val_loss: 0.2090\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2007 - val_loss: 0.2046\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1956 - val_loss: 0.1999\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1908 - val_loss: 0.1950\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1863 - val_loss: 0.1904\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1827 - val_loss: 0.1882\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1782 - val_loss: 0.1820\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1744 - val_loss: 0.1803\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1733 - val_loss: 0.1775\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1692 - val_loss: 0.1755\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1663 - val_loss: 0.1737\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1648 - val_loss: 0.1728\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1640 - val_loss: 0.1683\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1599 - val_loss: 0.1675\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1567 - val_loss: 0.1655\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1536 - val_loss: 0.1633\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1534 - val_loss: 0.1629\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1538 - val_loss: 0.1620\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1498 - val_loss: 0.1593\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1492 - val_loss: 0.1581\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1482 - val_loss: 0.1571\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1452 - val_loss: 0.1541\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1441 - val_loss: 0.1551\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.1421 - val_loss: 0.1524\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1408 - val_loss: 0.1523\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1415 - val_loss: 0.1518\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1403 - val_loss: 0.1512\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1381 - val_loss: 0.1512\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1376 - val_loss: 0.1494\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1364 - val_loss: 0.1487\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1346 - val_loss: 0.1472\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1368 - val_loss: 0.1485\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1350 - val_loss: 0.1476\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1352 - val_loss: 0.1462\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1340 - val_loss: 0.1456\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.1448\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1323 - val_loss: 0.1440\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1301 - val_loss: 0.1442\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1309 - val_loss: 0.1447\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1315 - val_loss: 0.1456\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1304 - val_loss: 0.1421\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1289 - val_loss: 0.1436\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1272 - val_loss: 0.1413\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1295 - val_loss: 0.1428\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1287 - val_loss: 0.1419\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1279 - val_loss: 0.1424\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1273 - val_loss: 0.1422\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1273 - val_loss: 0.1408\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1264 - val_loss: 0.1397\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1279 - val_loss: 0.1403\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1262 - val_loss: 0.1397\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1244 - val_loss: 0.1409\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1269 - val_loss: 0.1413\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1233 - val_loss: 0.1385\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1233 - val_loss: 0.1378\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1243 - val_loss: 0.1393\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1238 - val_loss: 0.1384\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1236 - val_loss: 0.1401\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1242 - val_loss: 0.1378\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1244 - val_loss: 0.1374\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1227 - val_loss: 0.1413\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1214 - val_loss: 0.1376\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1227 - val_loss: 0.1370\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1223 - val_loss: 0.1365\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1228 - val_loss: 0.1383\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1225 - val_loss: 0.1366\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1205 - val_loss: 0.1357\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1200 - val_loss: 0.1382\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1211 - val_loss: 0.1357\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1212 - val_loss: 0.1368\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1196 - val_loss: 0.1369\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1201 - val_loss: 0.1360\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1203 - val_loss: 0.1352\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1203 - val_loss: 0.1366\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1204 - val_loss: 0.1372\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1196 - val_loss: 0.1355\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1187 - val_loss: 0.1351\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1172 - val_loss: 0.1371\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1190 - val_loss: 0.1370\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1189 - val_loss: 0.1364\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1191 - val_loss: 0.1367\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1187 - val_loss: 0.1331\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1180 - val_loss: 0.1365\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1186 - val_loss: 0.1347\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1168 - val_loss: 0.1342\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1167 - val_loss: 0.1361\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1173 - val_loss: 0.1349\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1187 - val_loss: 0.1361\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1162 - val_loss: 0.1349\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1171 - val_loss: 0.1344\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1155 - val_loss: 0.1357\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1175 - val_loss: 0.1345\n",
      "Epoch 00108: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 2.9533 - val_loss: 2.1133\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8245 - val_loss: 1.1177\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9835 - val_loss: 0.6092\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5722 - val_loss: 0.4464\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.4316 - val_loss: 0.3992\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3883 - val_loss: 0.3452\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3293 - val_loss: 0.2989\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2894 - val_loss: 0.2634\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2573 - val_loss: 0.2360\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2301 - val_loss: 0.2174\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2149 - val_loss: 0.2042\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.2013 - val_loss: 0.1926\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1912 - val_loss: 0.1836\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1829 - val_loss: 0.1782\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1754 - val_loss: 0.1722\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1700 - val_loss: 0.1671\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1647 - val_loss: 0.1626\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1583\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1571 - val_loss: 0.1546\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1519 - val_loss: 0.1517\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1496 - val_loss: 0.1487\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1458 - val_loss: 0.1461\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1425 - val_loss: 0.1432\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1397 - val_loss: 0.1398\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1374 - val_loss: 0.1378\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1337 - val_loss: 0.1355\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1309 - val_loss: 0.1336\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1285 - val_loss: 0.1314\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1262 - val_loss: 0.1287\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1238 - val_loss: 0.1269\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1230 - val_loss: 0.1258\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1205 - val_loss: 0.1230\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1185 - val_loss: 0.1244\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1184 - val_loss: 0.1205\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1159 - val_loss: 0.1180\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1135 - val_loss: 0.1174\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1126 - val_loss: 0.1143\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1110 - val_loss: 0.1125\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1103 - val_loss: 0.1112\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1084 - val_loss: 0.1096\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1061 - val_loss: 0.1094\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1059 - val_loss: 0.1075\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1044 - val_loss: 0.1058\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1023 - val_loss: 0.1046\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1010 - val_loss: 0.1042\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1006 - val_loss: 0.1024\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0995 - val_loss: 0.1014\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0988 - val_loss: 0.1010\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0982 - val_loss: 0.1003\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0965 - val_loss: 0.0998\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0967 - val_loss: 0.0989\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.0994\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0941 - val_loss: 0.0975\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0950 - val_loss: 0.0973\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0924 - val_loss: 0.0971\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0914 - val_loss: 0.0946\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0908 - val_loss: 0.0946\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0896 - val_loss: 0.0944\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0897 - val_loss: 0.0937\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0888 - val_loss: 0.0929\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0886 - val_loss: 0.0934\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0876 - val_loss: 0.0919\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0868 - val_loss: 0.0920\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0869 - val_loss: 0.0912\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0867 - val_loss: 0.0908\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0865 - val_loss: 0.0902\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0853 - val_loss: 0.0905\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0845 - val_loss: 0.0903\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0844 - val_loss: 0.0889\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0843 - val_loss: 0.0886\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0833 - val_loss: 0.0885\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0835 - val_loss: 0.0893\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0839 - val_loss: 0.0882\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0815 - val_loss: 0.0879\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0830 - val_loss: 0.0873\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0811 - val_loss: 0.0876\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0805 - val_loss: 0.0865\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0807 - val_loss: 0.0871\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0807 - val_loss: 0.0861\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0801 - val_loss: 0.0882\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0811 - val_loss: 0.0860\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0798 - val_loss: 0.0854\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.0863\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0811 - val_loss: 0.0854\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0801 - val_loss: 0.0853\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0785 - val_loss: 0.0856\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0781 - val_loss: 0.0847\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0775 - val_loss: 0.0846\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0777 - val_loss: 0.0833\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0768 - val_loss: 0.0847\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0775 - val_loss: 0.0842\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0768 - val_loss: 0.0846\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0765 - val_loss: 0.0843\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0762 - val_loss: 0.0844\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0758 - val_loss: 0.0835\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0751 - val_loss: 0.0837\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0758 - val_loss: 0.0829\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0750 - val_loss: 0.0834\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0764 - val_loss: 0.0828\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0754 - val_loss: 0.0847\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0754 - val_loss: 0.0828\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0754 - val_loss: 0.0837\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0741 - val_loss: 0.0838\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0738 - val_loss: 0.0830\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0857\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0832\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0751 - val_loss: 0.0858\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0738 - val_loss: 0.0841\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0747 - val_loss: 0.0819\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0745 - val_loss: 0.0837\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0730 - val_loss: 0.0820\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0734 - val_loss: 0.0834\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0741 - val_loss: 0.0840\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0738 - val_loss: 0.0826\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0727 - val_loss: 0.0824\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0713 - val_loss: 0.0814\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0730 - val_loss: 0.0814\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0727 - val_loss: 0.0826\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0732 - val_loss: 0.0831\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0715 - val_loss: 0.0834\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0704 - val_loss: 0.0832\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0726 - val_loss: 0.0837\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0717 - val_loss: 0.0822\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0708 - val_loss: 0.0820\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0706 - val_loss: 0.0830\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0724 - val_loss: 0.0826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00126: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 3.8312 - val_loss: 3.0357\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.8099 - val_loss: 1.9719\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7376 - val_loss: 0.9659\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8573 - val_loss: 0.3936\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.3717 - val_loss: 0.1753\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1768 - val_loss: 0.1193\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1183 - val_loss: 0.1073\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1041 - val_loss: 0.1023\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0987 - val_loss: 0.0984\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0949 - val_loss: 0.0951\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0903 - val_loss: 0.0921\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0880 - val_loss: 0.0891\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0843 - val_loss: 0.0860\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.081 - 0s 7ms/step - loss: 0.0815 - val_loss: 0.0830\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0788 - val_loss: 0.0803\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0756 - val_loss: 0.0775\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0726 - val_loss: 0.0752\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0707 - val_loss: 0.0728\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0686 - val_loss: 0.0708\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0651 - val_loss: 0.0692\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0637 - val_loss: 0.0676\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0614 - val_loss: 0.0661\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0603 - val_loss: 0.0648\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0575 - val_loss: 0.0630\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0558 - val_loss: 0.0615\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0537 - val_loss: 0.0604\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0533 - val_loss: 0.0591\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0521 - val_loss: 0.0578\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0500 - val_loss: 0.0567\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0496 - val_loss: 0.0557\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0484 - val_loss: 0.0547\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0476 - val_loss: 0.0539\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0452 - val_loss: 0.0532\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0450 - val_loss: 0.0524\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0438 - val_loss: 0.0516\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0432 - val_loss: 0.0508\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0426 - val_loss: 0.0502\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0424 - val_loss: 0.0497\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0406 - val_loss: 0.0487\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0408 - val_loss: 0.0480\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0391 - val_loss: 0.0474\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0389 - val_loss: 0.0470\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0381 - val_loss: 0.0463\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0382 - val_loss: 0.0459\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0454\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0369 - val_loss: 0.0449\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0362 - val_loss: 0.0444\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0444\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0353 - val_loss: 0.0435\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0350 - val_loss: 0.0438\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0348 - val_loss: 0.0425\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0337 - val_loss: 0.0431\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0337 - val_loss: 0.0423\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0334 - val_loss: 0.0422\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0325 - val_loss: 0.0413\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0330 - val_loss: 0.0410\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0409\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0320 - val_loss: 0.0405\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0313 - val_loss: 0.0403\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.0393\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0314 - val_loss: 0.0391\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0307 - val_loss: 0.0389\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0383\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0378\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0297 - val_loss: 0.0374\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0292 - val_loss: 0.0370\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0293 - val_loss: 0.0368\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0288 - val_loss: 0.0365\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0357\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0287 - val_loss: 0.0358\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0362\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0276 - val_loss: 0.0356\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0354\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0355\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0273 - val_loss: 0.0353\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0348\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0344\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0264 - val_loss: 0.0342\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0264 - val_loss: 0.0355\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0329\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.0337\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0262 - val_loss: 0.0324\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0255 - val_loss: 0.0342\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0333\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0325\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0249 - val_loss: 0.0328\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0245 - val_loss: 0.0321\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0321\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0322\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0243 - val_loss: 0.0322\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0239 - val_loss: 0.0318\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0238 - val_loss: 0.0308\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0235 - val_loss: 0.0308\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0311\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0305\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0301\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0298\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0298\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0294\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0292\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0292\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0288\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0291\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0288\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0218 - val_loss: 0.0289\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0292\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0291\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0286\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0212 - val_loss: 0.0282\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0282\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0284\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0208 - val_loss: 0.0269\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0273\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0272\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0264\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0271\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0268\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0264\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0204 - val_loss: 0.0275\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0256\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0263\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0266\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0261\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0263\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0261\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0258\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0261\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0261\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0191 - val_loss: 0.0256\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0259\n",
      "Epoch 00130: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9030e2fc59e4703bb5ac58971244929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0830 - val_loss: 0.0601\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.0385\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0396 - val_loss: 0.0324\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0328 - val_loss: 0.0277\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0278\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0239\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0234 - val_loss: 0.0232\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0229 - val_loss: 0.0233\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0228\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0208\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0215\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0210\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0214\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0198\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0193\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0200\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0203\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0198\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0222\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0196\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0207\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4362 - val_loss: 0.1973\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1842 - val_loss: 0.1618\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1472 - val_loss: 0.1190\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1219 - val_loss: 0.1126\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.0989\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0974 - val_loss: 0.0951\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0908 - val_loss: 0.0930\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0878 - val_loss: 0.0909\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0848 - val_loss: 0.0894\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0841 - val_loss: 0.0886\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.077 - 0s 5ms/step - loss: 0.0812 - val_loss: 0.0904\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0820 - val_loss: 0.0930\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0868\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0812 - val_loss: 0.0906\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.0890\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0969\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0794 - val_loss: 0.0915\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0796 - val_loss: 0.0927\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0798 - val_loss: 0.0906\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.0902\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0776 - val_loss: 0.0907\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0768 - val_loss: 0.0913\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0749 - val_loss: 0.0920\n",
      "Epoch 00023: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.3144 - val_loss: 0.5135\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4438 - val_loss: 0.3291\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3054 - val_loss: 0.2602\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2419 - val_loss: 0.2142\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2029 - val_loss: 0.1950\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1826 - val_loss: 0.1773\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1666 - val_loss: 0.1656\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1562 - val_loss: 0.1565\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1520 - val_loss: 0.1522\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1468 - val_loss: 0.1519\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1412 - val_loss: 0.1451\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1402 - val_loss: 0.1488\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1390 - val_loss: 0.1399\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1333 - val_loss: 0.1383\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1309 - val_loss: 0.1414\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1341 - val_loss: 0.1521\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1359 - val_loss: 0.1428\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.1318 - val_loss: 0.1436\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1304 - val_loss: 0.1438\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1306 - val_loss: 0.1397\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1295 - val_loss: 0.1370\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1252 - val_loss: 0.1395\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1269 - val_loss: 0.1374\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1248 - val_loss: 0.1377\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1264 - val_loss: 0.1431\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1292 - val_loss: 0.1421\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1298 - val_loss: 0.1414\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1242 - val_loss: 0.1341\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1216 - val_loss: 0.1411\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1269 - val_loss: 0.1335\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.1329\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1197 - val_loss: 0.1341\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1221 - val_loss: 0.1366\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1225 - val_loss: 0.1348\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1210 - val_loss: 0.1333\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1177 - val_loss: 0.1401\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1284 - val_loss: 0.1451\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1277 - val_loss: 0.1453\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1275 - val_loss: 0.1366\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1212 - val_loss: 0.1322\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1165 - val_loss: 0.1319\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1159 - val_loss: 0.1301\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1180 - val_loss: 0.1464\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1233 - val_loss: 0.1333\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1164 - val_loss: 0.1371\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1183 - val_loss: 0.1400\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1190 - val_loss: 0.1353\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1168 - val_loss: 0.1350\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1143 - val_loss: 0.1396\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1235 - val_loss: 0.1458\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1214 - val_loss: 0.1338\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1171 - val_loss: 0.1354\n",
      "Epoch 00052: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8787 - val_loss: 0.7118\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5092 - val_loss: 0.2875\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2592 - val_loss: 0.1954\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1888 - val_loss: 0.1703\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1589 - val_loss: 0.1450\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1363 - val_loss: 0.1286\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1229 - val_loss: 0.1177\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1118 - val_loss: 0.1108\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1068 - val_loss: 0.1045\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1020 - val_loss: 0.1050\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0973 - val_loss: 0.1005\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.093 - 0s 5ms/step - loss: 0.0947 - val_loss: 0.0959\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0895 - val_loss: 0.0926\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0863 - val_loss: 0.0875\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0852 - val_loss: 0.1006\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0913 - val_loss: 0.0830\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0843 - val_loss: 0.0875\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0827 - val_loss: 0.0849\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0829 - val_loss: 0.0942\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0839\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0828\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0775 - val_loss: 0.0825\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0790 - val_loss: 0.0836\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0787 - val_loss: 0.0866\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0792 - val_loss: 0.0816\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0771 - val_loss: 0.0876\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0784 - val_loss: 0.0858\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0790 - val_loss: 0.0946\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0869\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0801 - val_loss: 0.0840\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0783 - val_loss: 0.0877\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0804 - val_loss: 0.0819\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.0906\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0835\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.0851\n",
      "Epoch 00037: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9816 - val_loss: 0.2543\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2911 - val_loss: 0.3050\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2654 - val_loss: 0.1621\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1266 - val_loss: 0.0696\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0698 - val_loss: 0.0586\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0557 - val_loss: 0.0504\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0468 - val_loss: 0.0419\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0395 - val_loss: 0.0373\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0352 - val_loss: 0.0342\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0323 - val_loss: 0.0317\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0301 - val_loss: 0.0327\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.0311\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0290\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0309\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0267 - val_loss: 0.0314\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0282 - val_loss: 0.0299\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0264\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0259\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0235 - val_loss: 0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0254\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0241\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0241\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0246\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0233\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0253\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0224\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.0240\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0221\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0210\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0215\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0203\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0230\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0235\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0217\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0207\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0232\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0201\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0200\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0202\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0213\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0218\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0209\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0190\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0209\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0196\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0195\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0209\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0201\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0215\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0204\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0194\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0200\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0210\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0212\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0184\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0201\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0210\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0216\n",
      "Epoch 00067: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7e274b0e0145e7a4e4eaea2da471d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3.3935 - val_loss: 0.5360\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5642 - val_loss: 0.3524\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4198 - val_loss: 0.6729\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5060 - val_loss: 0.2218\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1762 - val_loss: 0.0997\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.2910\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.1632\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1309 - val_loss: 0.0934\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0781 - val_loss: 0.0718\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0643 - val_loss: 0.0584\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0479\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0479 - val_loss: 0.0485\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0427\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0439 - val_loss: 0.0405\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0377 - val_loss: 0.0358\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0346 - val_loss: 0.0347\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0311\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0299 - val_loss: 0.0335\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0294 - val_loss: 0.0333\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0267 - val_loss: 0.0261\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0266\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0245 - val_loss: 0.0268\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0263 - val_loss: 0.0248\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0252\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0247\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0242\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0250\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0242\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0264\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0234\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0207\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0214\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0199\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0274\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0229\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0236\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0203\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0208\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0198\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0209\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0207\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0207\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0200\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0234\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0193\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0197\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0209\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0202\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0193\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0210\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0193\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0237\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0209\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 00061: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.9851 - val_loss: 0.7576\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.7125 - val_loss: 0.5483\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.4478 - val_loss: 0.2564\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3313 - val_loss: 0.3132\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2290 - val_loss: 0.1501\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1459 - val_loss: 0.1268\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1193 - val_loss: 0.1267\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1142 - val_loss: 0.1012\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1006 - val_loss: 0.1021\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0973 - val_loss: 0.1010\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.0912\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0929 - val_loss: 0.1220\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1092 - val_loss: 0.1123\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1027 - val_loss: 0.0997\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0943 - val_loss: 0.0976\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0882 - val_loss: 0.0925\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.0901\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.0920\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.0915\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0852 - val_loss: 0.0951\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0859 - val_loss: 0.0906\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0833 - val_loss: 0.0915\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0824 - val_loss: 0.0905\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0806 - val_loss: 0.0864\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0796 - val_loss: 0.0867\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0787 - val_loss: 0.0945\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0808 - val_loss: 0.0879\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.0909\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0828 - val_loss: 0.0851\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0816 - val_loss: 0.0943\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0883\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0783 - val_loss: 0.0880\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0790 - val_loss: 0.0912\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0802 - val_loss: 0.0921\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.0853\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0778 - val_loss: 0.0910\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0817 - val_loss: 0.0853\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0761 - val_loss: 0.0841\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.0845\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0758 - val_loss: 0.0880\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0803 - val_loss: 0.0858\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0782 - val_loss: 0.0843\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0772 - val_loss: 0.0864\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0830\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0744 - val_loss: 0.0928\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0926\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0788 - val_loss: 0.0881\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0827 - val_loss: 0.0981\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0786 - val_loss: 0.0896\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0767 - val_loss: 0.0885\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0735 - val_loss: 0.0878\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0743 - val_loss: 0.0853\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0743 - val_loss: 0.0862\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0784 - val_loss: 0.0828\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0858\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0737 - val_loss: 0.0867\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0737 - val_loss: 0.0870\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0791 - val_loss: 0.0914\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0743 - val_loss: 0.0911\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0752 - val_loss: 0.0832\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0728 - val_loss: 0.0878\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0746 - val_loss: 0.0828\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0722 - val_loss: 0.0842\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0759 - val_loss: 0.0833\n",
      "Epoch 00064: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 14ms/step - loss: 2.5397 - val_loss: 0.7897\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.8589 - val_loss: 0.3864\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3914 - val_loss: 0.2773\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2817 - val_loss: 0.1844\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.1990\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1746 - val_loss: 0.1702\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1629 - val_loss: 0.1483\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1465 - val_loss: 0.1462\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1435 - val_loss: 0.1435\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1384 - val_loss: 0.1370\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1348 - val_loss: 0.1391\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1387 - val_loss: 0.1397\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1368 - val_loss: 0.1418\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1372 - val_loss: 0.1450\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1391 - val_loss: 0.1499\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1371 - val_loss: 0.1374\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1315 - val_loss: 0.1344\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1328 - val_loss: 0.1534\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1358 - val_loss: 0.1313\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1320 - val_loss: 0.1362\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1300 - val_loss: 0.1368\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1304 - val_loss: 0.1404\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1322 - val_loss: 0.1398\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1307 - val_loss: 0.1339\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1272 - val_loss: 0.1341\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1289 - val_loss: 0.1309\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1251 - val_loss: 0.1303\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1240 - val_loss: 0.1345\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1225 - val_loss: 0.1314\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1249 - val_loss: 0.1413\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1318 - val_loss: 0.1343\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1341 - val_loss: 0.1450\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1320 - val_loss: 0.1382\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 0.1353\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1237 - val_loss: 0.1418\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1276 - val_loss: 0.1362\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.1246 - val_loss: 0.1375\n",
      "Epoch 00037: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.0500 - val_loss: 1.0939\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9054 - val_loss: 0.3734\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3713 - val_loss: 0.2227\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1989 - val_loss: 0.1462\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1284 - val_loss: 0.1212\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1121 - val_loss: 0.1320\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1847 - val_loss: 0.1604\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1325 - val_loss: 0.1114\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1009 - val_loss: 0.0945\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.0903\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0866 - val_loss: 0.1082\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0966 - val_loss: 0.0926\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.0839\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0805 - val_loss: 0.0854\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0800 - val_loss: 0.0856\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0799 - val_loss: 0.0838\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0776 - val_loss: 0.0892\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0856\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0800 - val_loss: 0.0972\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0852 - val_loss: 0.0872\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0815 - val_loss: 0.0819\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0827\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0892\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0852\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0791\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.0801\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0750 - val_loss: 0.0807\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0749 - val_loss: 0.0807\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0744 - val_loss: 0.0857\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0770 - val_loss: 0.0819\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0786 - val_loss: 0.0904\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0833 - val_loss: 0.0798\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0874\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.0785 - val_loss: 0.0871\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0816 - val_loss: 0.0844\n",
      "Epoch 00035: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.5847 - val_loss: 1.6245\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.2205 - val_loss: 0.3810\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2953 - val_loss: 0.1274\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.1164 - val_loss: 0.0773\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0722 - val_loss: 0.0470\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0555 - val_loss: 0.2598\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2330 - val_loss: 0.1985\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.2232 - val_loss: 0.0631\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0729 - val_loss: 0.0453\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.0805 - val_loss: 0.4318\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3738 - val_loss: 1.9061\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.0101 - val_loss: 0.4324\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4097 - val_loss: 2.4667\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.1178 - val_loss: 0.6677\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.6210 - val_loss: 2.0151\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.7009 - val_loss: 2.9307\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 12.6369 - val_loss: 10.1551\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 14.2977 - val_loss: 9.0918\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 8.9995 - val_loss: 14.7113\n",
      "Epoch 00019: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de890225b3da4e7390d5ecbf99db9885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-d85b4a661713>:11: RuntimeWarning: overflow encountered in exp\n",
      "  results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (97,) (98,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-d85b4a661713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8a7828349cf7>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(predictions, target)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Calculate the CRPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"crps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Bonus useful Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8a7828349cf7>\u001b[0m in \u001b[0;36mCRPS\u001b[0;34m(predictions, actuals)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdifs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcdf_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifs_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8a7828349cf7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdifs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcdf_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifs_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8a7828349cf7>\u001b[0m in \u001b[0;36mcdf_dif\u001b[0;34m(prediction, actual)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdif\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mheavyside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# If the actual is outside the range of the prediction,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# we need to account for that areas outside the range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__mul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rmul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   4996\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4997\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4998\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5000\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (97,) (98,) "
     ]
    }
   ],
   "source": [
    "alls=[]\n",
    "\n",
    "for batch_size in tqdm([32,64,200,500,1000,2000]):\n",
    "    for epochs in tqdm([200]):\n",
    "        for lr in tqdm([0.0001,0.001,0.01,0.1]):\n",
    "\n",
    "            qreg = MLPQuantile(batch_size=batch_size,epochs=epochs,lr=lr)\n",
    "            qreg.fit(X_train_std,y_train)\n",
    "            preds = qreg.predict(X_test_std)\n",
    "            results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n",
    "\n",
    "            del results[\"all\"]\n",
    "            del results[\"target\"]\n",
    "            results[\"batch_size\"]=batch_size\n",
    "            results[\"epochs\"]=epochs\n",
    "            results[\"lr\"]=lr\n",
    "            alls.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crps</th>\n",
       "      <th>count</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>bias</th>\n",
       "      <th>corr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.321016e+01</td>\n",
       "      <td>448</td>\n",
       "      <td>26.616627</td>\n",
       "      <td>18.391448</td>\n",
       "      <td>0.051723</td>\n",
       "      <td>0.721878</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.365685e+01</td>\n",
       "      <td>437</td>\n",
       "      <td>27.098976</td>\n",
       "      <td>19.142774</td>\n",
       "      <td>-0.828149</td>\n",
       "      <td>0.713024</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.373145e+01</td>\n",
       "      <td>452</td>\n",
       "      <td>27.349485</td>\n",
       "      <td>19.145823</td>\n",
       "      <td>0.471469</td>\n",
       "      <td>0.705730</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.387997e+01</td>\n",
       "      <td>449</td>\n",
       "      <td>27.351222</td>\n",
       "      <td>19.479169</td>\n",
       "      <td>0.566238</td>\n",
       "      <td>0.703048</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.370337e+01</td>\n",
       "      <td>447</td>\n",
       "      <td>27.488187</td>\n",
       "      <td>19.324941</td>\n",
       "      <td>0.986346</td>\n",
       "      <td>0.700785</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.428967e+01</td>\n",
       "      <td>442</td>\n",
       "      <td>27.954319</td>\n",
       "      <td>19.786370</td>\n",
       "      <td>-2.448371</td>\n",
       "      <td>0.698197</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.420735e+01</td>\n",
       "      <td>451</td>\n",
       "      <td>28.168830</td>\n",
       "      <td>19.483845</td>\n",
       "      <td>2.873022</td>\n",
       "      <td>0.693409</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.355074e+01</td>\n",
       "      <td>453</td>\n",
       "      <td>28.185922</td>\n",
       "      <td>19.271307</td>\n",
       "      <td>7.253688</td>\n",
       "      <td>0.709076</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.402934e+01</td>\n",
       "      <td>449</td>\n",
       "      <td>28.254392</td>\n",
       "      <td>19.538328</td>\n",
       "      <td>2.440787</td>\n",
       "      <td>0.685368</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.449076e+01</td>\n",
       "      <td>447</td>\n",
       "      <td>28.820583</td>\n",
       "      <td>20.832350</td>\n",
       "      <td>1.122662</td>\n",
       "      <td>0.664688</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.450441e+01</td>\n",
       "      <td>448</td>\n",
       "      <td>28.835670</td>\n",
       "      <td>20.454174</td>\n",
       "      <td>-1.937973</td>\n",
       "      <td>0.687297</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.466378e+01</td>\n",
       "      <td>444</td>\n",
       "      <td>29.151535</td>\n",
       "      <td>20.713558</td>\n",
       "      <td>-1.917956</td>\n",
       "      <td>0.676557</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.533969e+01</td>\n",
       "      <td>454</td>\n",
       "      <td>29.473903</td>\n",
       "      <td>20.737474</td>\n",
       "      <td>-4.389579</td>\n",
       "      <td>0.686027</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.343569e+39</td>\n",
       "      <td>458</td>\n",
       "      <td>29.724570</td>\n",
       "      <td>20.958645</td>\n",
       "      <td>4.461039</td>\n",
       "      <td>0.655412</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.579058e+01</td>\n",
       "      <td>441</td>\n",
       "      <td>29.735519</td>\n",
       "      <td>21.766880</td>\n",
       "      <td>-7.531765</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.605805e+01</td>\n",
       "      <td>453</td>\n",
       "      <td>30.552731</td>\n",
       "      <td>21.869668</td>\n",
       "      <td>-1.139394</td>\n",
       "      <td>0.636332</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.216168e+02</td>\n",
       "      <td>458</td>\n",
       "      <td>35.237929</td>\n",
       "      <td>25.377031</td>\n",
       "      <td>4.894499</td>\n",
       "      <td>0.419278</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.993449e+01</td>\n",
       "      <td>446</td>\n",
       "      <td>36.784374</td>\n",
       "      <td>25.946289</td>\n",
       "      <td>-2.407217</td>\n",
       "      <td>0.573464</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.011372e+147</td>\n",
       "      <td>458</td>\n",
       "      <td>46.535297</td>\n",
       "      <td>35.159470</td>\n",
       "      <td>7.440117</td>\n",
       "      <td>-0.239562</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crps  count       rmse        mae      bias      corr  \\\n",
       "1    1.321016e+01    448  26.616627  18.391448  0.051723  0.721878   \n",
       "5    1.365685e+01    437  27.098976  19.142774 -0.828149  0.713024   \n",
       "14   1.373145e+01    452  27.349485  19.145823  0.471469  0.705730   \n",
       "8    1.387997e+01    449  27.351222  19.479169  0.566238  0.703048   \n",
       "0    1.370337e+01    447  27.488187  19.324941  0.986346  0.700785   \n",
       "17   1.428967e+01    442  27.954319  19.786370 -2.448371  0.698197   \n",
       "6    1.420735e+01    451  28.168830  19.483845  2.873022  0.693409   \n",
       "18   1.355074e+01    453  28.185922  19.271307  7.253688  0.709076   \n",
       "2    1.402934e+01    449  28.254392  19.538328  2.440787  0.685368   \n",
       "4    1.449076e+01    447  28.820583  20.832350  1.122662  0.664688   \n",
       "9    1.450441e+01    448  28.835670  20.454174 -1.937973  0.687297   \n",
       "13   1.466378e+01    444  29.151535  20.713558 -1.917956  0.676557   \n",
       "10   1.533969e+01    454  29.473903  20.737474 -4.389579  0.686027   \n",
       "11   5.343569e+39    458  29.724570  20.958645  4.461039  0.655412   \n",
       "15   1.579058e+01    441  29.735519  21.766880 -7.531765  0.692737   \n",
       "12   1.605805e+01    453  30.552731  21.869668 -1.139394  0.636332   \n",
       "7    1.216168e+02    458  35.237929  25.377031  4.894499  0.419278   \n",
       "16   1.993449e+01    446  36.784374  25.946289 -2.407217  0.573464   \n",
       "3   1.011372e+147    458  46.535297  35.159470  7.440117 -0.239562   \n",
       "\n",
       "    batch_size  epochs      lr  \n",
       "1           32     200  0.0010  \n",
       "5           64     200  0.0010  \n",
       "14         500     200  0.0100  \n",
       "8          200     200  0.0001  \n",
       "0           32     200  0.0001  \n",
       "17        1000     200  0.0010  \n",
       "6           64     200  0.0100  \n",
       "18        1000     200  0.0100  \n",
       "2           32     200  0.0100  \n",
       "4           64     200  0.0001  \n",
       "9          200     200  0.0010  \n",
       "13         500     200  0.0010  \n",
       "10         200     200  0.0100  \n",
       "11         200     200  0.1000  \n",
       "15         500     200  0.1000  \n",
       "12         500     200  0.0001  \n",
       "7           64     200  0.1000  \n",
       "16        1000     200  0.0001  \n",
       "3           32     200  0.1000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(alls).sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
