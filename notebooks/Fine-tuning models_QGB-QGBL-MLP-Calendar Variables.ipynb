{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Medida del CRPS\n",
    "def heavyside(prediction,actual):\n",
    "    return prediction >= actual\n",
    "\n",
    "def cdf_dif(prediction,actual):\n",
    "    quantiles = np.arange(1,100)/100.0\n",
    "    t=pd.Series(prediction)\n",
    "    dif=t-t.shift(1)\n",
    "    dif=dif.dropna()\n",
    "    fs = sum(dif*((quantiles-heavyside(prediction,actual))[1:]**2))\n",
    "    # If the actual is outside the range of the prediction, \n",
    "    # we need to account for that areas outside the range \n",
    "    if actual > prediction[-1]:\n",
    "        fs += (actual-prediction[-1]) * 1\n",
    "    if actual < prediction[0]:\n",
    "        fs += (prediction[0]-actual) * 1\n",
    "    return fs\n",
    "\n",
    "def CRPS(predictions, actuals):\n",
    "    difs_mean = [cdf_dif(predictions[i],actuals[i]) for i in range(len(actuals))]\n",
    "    return np.mean(difs_mean)\n",
    "\n",
    "def evaluate(predictions,target):\n",
    "\n",
    "    res={}\n",
    "    \n",
    "    # Calculate the CRPS\n",
    "    res[\"crps\"]=CRPS(predictions,target)\n",
    "    \n",
    "    # Bonus useful Feature\n",
    "    count = 0\n",
    "    for i in range(len(target)):\n",
    "        if (target[i]>predictions[i][0]) and (target[i]<predictions[i][-1]):\n",
    "            count+=1\n",
    "    res[\"count\"]=count\n",
    "    \n",
    "    ## Calculate as well measures for the quantile 50\n",
    "    total_df = pd.DataFrame(predictions)\n",
    "    quantiles = np.arange(1,100)/100.0 \n",
    "    total_df.columns=np.array(quantiles).astype(str)\n",
    "    #RMSE       \n",
    "    res[\"rmse\"]=np.sqrt(np.mean((target-total_df[\"0.5\"])**2))\n",
    "    #MAE    \n",
    "    res[\"mae\"]=np.mean(np.abs(target-total_df[\"0.5\"] ) )\n",
    "    #Bias \n",
    "    res[\"bias\"]=np.mean(target-total_df[\"0.5\"])\n",
    "    #Corr\n",
    "    res[\"corr\"]=np.corrcoef(target,total_df[\"0.5\"])[0][1]\n",
    "\n",
    "    res[\"all\"]=predictions\n",
    "    res[\"target\"]=target\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import  tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.fft import fft\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def prepare_data_from_horizon(df, horizon=12):\n",
    "    \n",
    "    data=df.copy()\n",
    "\n",
    "    sel = np.concatenate([[1,2,3,4],\n",
    "                         [12],\n",
    "                         24*np.arange(1,9),\n",
    "                         12+24*np.arange(1,9)])  \n",
    "    sel=np.concatenate([sel,sel-1,sel+1])  \n",
    "    \n",
    "    ## lagged NO2 values\n",
    "    for i in sel:\n",
    "        if (i>=horizon):\n",
    "            data[\"NO2 - \"+str(i)] = data[\"NO2\"].shift(i)\n",
    "\n",
    "    ## lagged O3 values\n",
    "    for i in 24*np.arange(1,4):\n",
    "        if (i>=horizon):\n",
    "            data[\"O3 - \"+str(i)] = data[\"O3\"].shift(i)\n",
    "\n",
    "    ## Remove empty values\n",
    "    data=data.dropna()\n",
    "\n",
    "    X=data[list(set(data.columns)-set(['DATE',\"NO2\",\"O3\",\"day\",\"dt_date\"]))]\n",
    "    y=data[\"NO2\"]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "#\"data/dataEscAgui.csv\"\n",
    "def get_data(path):\n",
    "\n",
    "    df = pd.read_csv(path,sep=\";\")\n",
    "\n",
    "    # Prepare data\n",
    "    data = df[[\"DATE\",\"SPA.NO2\",\"SPA.O3\",\"MACC.NO2\"]].copy()\n",
    "    data[\"DATE\"]=pd.to_datetime(data[\"DATE\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    data = data.sort_values(\"DATE\")\n",
    "    data.columns = [\"DATE\",\"NO2\",\"O3\",\"CAMS\"]\n",
    "\n",
    "    ## Remove everything from 2020\n",
    "    data=data[data[\"DATE\"].astype(str)<\"2020\"]\n",
    "\n",
    "    ## Fourier Columns\n",
    "    freqs = [2922,1461,209,1465,4]\n",
    "    l = 35064\n",
    "    n = np.arange(len(data))\n",
    "    fcols = []\n",
    "    for f in freqs:\n",
    "        data[\"c\"+str(f)]=np.cos(n*2*np.pi*f/l)\n",
    "        fcols.append(\"c\"+str(f))\n",
    "        data[\"s\"+str(f)]=np.cos(n*2*np.pi*f/l)\n",
    "        fcols.append(\"s\"+str(f))\n",
    "\n",
    "    data[\"NO2\"]=np.log1p(data[\"NO2\"])\n",
    "    data[\"O3\"]=np.log1p(data[\"O3\"])\n",
    "    data[\"CAMS\"]=np.log1p(data[\"CAMS\"])\n",
    "\n",
    "    ## Calendar Variables \n",
    "    ## # Day\n",
    "    data[\"day\"]=data[\"DATE\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    from datetime import date, timedelta, datetime\n",
    "\n",
    "    def get_alldates(starts,ends):\n",
    "        sdate = datetime.strptime(starts,\"%Y-%m-%d\")\n",
    "        edate = datetime.strptime(ends,\"%Y-%m-%d\") \n",
    "\n",
    "        delta = edate - sdate       # as timedelta\n",
    "\n",
    "        all_dates = []\n",
    "        for i in range(delta.days + 1):\n",
    "            day = sdate + timedelta(days=i)\n",
    "            all_dates.append(day.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "        return all_dates\n",
    "\n",
    "    # Escolar\n",
    "\n",
    "    cal_escolar = pd.read_csv(\"../cal_extract/cal_f_escolar.csv\")\n",
    "\n",
    "    ## No cogemos los dias con COVID 19\n",
    "    cal_escolar = cal_escolar[~cal_escolar[\"co_period\"].str.contains(\"covid19\")]\n",
    "\n",
    "    all_cal_days = []\n",
    "    for i,row in cal_escolar.iterrows():\n",
    "        all_dates = get_alldates(row[\"dt_start\"],row[\"dt_stop\"])\n",
    "\n",
    "        def process_date(date,typed):\n",
    "            return {\"day\":date,typed:\"1\"}\n",
    "\n",
    "        for element in map(lambda date: process_date(date,\"Calendar.School.\"+row[\"co_type\"]+\".\"+row[\"co_period\"]),all_dates):\n",
    "            all_cal_days.append(element)\n",
    "\n",
    "    all_cal_days_df = pd.DataFrame(all_cal_days).fillna(0)\n",
    "    \n",
    "    for col in all_cal_days_df.columns:\n",
    "        if col!=\"day\":\n",
    "            all_cal_days_df[col]=all_cal_days_df[col].astype(int)\n",
    "\n",
    "    ## Otros Festivos\n",
    "    \"\"\"\n",
    "    Calendar.Festivo.EqiNoc\n",
    "    Calendar.Festivo.FesNov\n",
    "    Calendar.Festivo.InmCns\n",
    "    Calendar.Festivo.NavAnu\n",
    "    Calendar.Festivo.PriVer\n",
    "    Calendar.Festivo.SemSan\n",
    "    Calendar.Festivo.VrgAgo\n",
    "    Calendar.NocheNav.NocheBuena\n",
    "    Calendar.NocheNav.NocheVieja\n",
    "    Calendar.OprRetorno\n",
    "    Calendar.OprSalida.PriNoLab\n",
    "    Calendar.OprSalida.Vispera\n",
    "    \"\"\" \n",
    "    cal_festivos = pd.read_csv(\"../cal_extract/cal_f_festivos.csv\")\n",
    "    \n",
    "    \n",
    "    ## For each type we take the OR of the columns\n",
    "    holiday_list = \"\"\"Festivo.EqiNoc\n",
    "    Calendar.Festivo.FesNov\n",
    "    Calendar.Festivo.InmCns\n",
    "    Calendar.Festivo.NavAnu\n",
    "    Calendar.Festivo.PriVer\n",
    "    Calendar.Festivo.SemSan\n",
    "    Calendar.Festivo.VrgAgo\n",
    "    Calendar.NocheNav.NocheBuena\n",
    "    Calendar.NocheNav.NocheVieja\n",
    "    Calendar.OprRetorno\n",
    "    Calendar.OprSalida.PriNoLab\n",
    "    Calendar.OprSalida.Vispera\"\"\".replace(\"Calendar.\",\"\").lower().replace(\".\",\"_\").split(\"\\n\")\n",
    "\n",
    "    def get_festivos(name,row):\n",
    "        cols = row.index[row.index.str.contains(name)]\n",
    "        res = row[cols].sum()\n",
    "        return res\n",
    "\n",
    "    res_festivos_df = pd.DataFrame()\n",
    "    for name in holiday_list:\n",
    "        print(name)\n",
    "        res_festivos_df[\"Calendar.\"+name]=cal_festivos.apply(lambda row:get_festivos(name,row),axis=1).astype(int).fillna(0)\n",
    "\n",
    "    res_festivos_df[\"day\"]=cal_festivos[\"dt_date\"]\n",
    "    \n",
    "    data = data.merge(all_cal_days_df,on=\"day\",how=\"left\")\n",
    "    data = data.merge(res_festivos_df,on=\"day\",how=\"left\")\n",
    "    \n",
    "    data=data.fillna(0)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tilted_loss(q,y,f):\n",
    "    e = (y-f)\n",
    "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)\n",
    "\n",
    "class MLPQuantile():\n",
    "    \n",
    "    def __init__(self,batch_size,epochs,lr):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr=lr\n",
    "        self.estimators = []\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        def MLPmodel():\n",
    "            model = Sequential()\n",
    "            model.add(Dense(len(X_train[0]), input_dim=len(X_train[0]), activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(int(len(X_train[0])/2), activation=LeakyReLU(alpha=0.3)))\n",
    "            model.add(Dense(1, activation='linear'))\n",
    "            return model\n",
    "        \n",
    "        print(\"training !\")\n",
    "\n",
    "        X_ttrain, X_val, y_ttrain, y_val = train_test_split(X_train,y_train,test_size=.05,random_state=2020)\n",
    "\n",
    "        for q in [0.022750131948179195,0.15865525393145707,0.5,0.8413447460685429,0.9772498680518208]:\n",
    "            print(f\"Quantile: {q}\")\n",
    "            model = MLPmodel()\n",
    "            optim=Adam(learning_rate=self.lr)\n",
    "            model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=optim)\n",
    "            es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=10)\n",
    "            history = model.fit(X_ttrain, y_ttrain, \n",
    "                                epochs=self.epochs, batch_size=self.batch_size,  \n",
    "                                verbose=1,callbacks=[es],\n",
    "                                validation_data=(X_val,y_val))\n",
    "            self.estimators.append(model)\n",
    "        print(\"Done\")\n",
    "        \n",
    "    def predict(self,X):\n",
    "        predictions_gbr = []\n",
    "        print(\"predicting\")\n",
    "        for reg in tqdm(self.estimators):\n",
    "            predictions_gbr.append(reg.predict(X))\n",
    "         \n",
    "        total_pred={}\n",
    "        for i in range(len(predictions_gbr)):\n",
    "            total_pred[i]=predictions_gbr[i][:,0]\n",
    "            \n",
    "        total_df=pd.DataFrame(total_pred)\n",
    "\n",
    "        def process_row(row):\n",
    "            v = row.values\n",
    "            dif_mean = np.abs(v-v[2])\n",
    "            mu = v[2]\n",
    "            s = np.mean([dif_mean[0]/2,dif_mean[1],dif_mean[3],dif_mean[4]/2])\n",
    "            mi_norm = stats.norm(mu,s)\n",
    "            quant=[]\n",
    "            for quantile in np.arange(1,100)/100.0 :\n",
    "                quant.append(mi_norm.ppf(quantile))\n",
    "            return pd.Series(quant)\n",
    " \n",
    "        total_df = total_df.apply(process_row,axis=1)\n",
    "        \n",
    "        return total_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "class TotalLGBQuantile():\n",
    "    \n",
    "    def __init__(self,n_estimators,max_depth):\n",
    "        self.n_estimators=n_estimators\n",
    "        self.max_depth=max_depth\n",
    "        self.quantiles=[0.022750131948179195,0.15865525393145707,0.5,0.8413447460685429,0.9772498680518208]\n",
    "        self.estimators = []\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        print(\"training !\")\n",
    "        for q in tqdm(self.quantiles):\n",
    "            print(f\"Quantile: {q}\")\n",
    "            reg = lgb.LGBMRegressor(n_estimators=self.n_estimators,\n",
    "                                    objective= 'quantile',\n",
    "                                    loss=\"quantile\",\n",
    "                                    alpha=q,\n",
    "                                    random_state=2020,\n",
    "                                   max_depth=self.max_depth)\n",
    "                                \n",
    "            reg.fit(X_train, y_train)\n",
    "            self.estimators.append(reg)\n",
    "        print(\"Done\")\n",
    "        \n",
    "    def predict(self,X):\n",
    "        predictions_gbr = []\n",
    "        print(\"predicting\")\n",
    "        for reg in tqdm(self.estimators):\n",
    "            predictions_gbr.append(reg.predict(X))\n",
    "         \n",
    "        total_pred={}\n",
    "        for i in range(len(predictions_gbr)):\n",
    "            total_pred[i]=predictions_gbr[i]\n",
    "            \n",
    "        total_df=pd.DataFrame(total_pred)\n",
    "\n",
    "        def process_row(row):\n",
    "            v = row.values\n",
    "            dif_mean = np.abs(v-v[2])\n",
    "            mu = v[2]\n",
    "            s = np.mean([dif_mean[0]/2,dif_mean[1],dif_mean[3],dif_mean[4]/2])\n",
    "            mi_norm = stats.norm(mu,s)\n",
    "            quant=[]\n",
    "            for quantile in np.arange(1,100)/100.0 :\n",
    "                quant.append(mi_norm.ppf(quantile))\n",
    "            return pd.Series(quant)\n",
    " \n",
    "        total_df = total_df.apply(process_row,axis=1)\n",
    "        \n",
    "        return total_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day Calendar.School.intensiva.inicio_curso  \\\n",
      "0  2011-09-05                                      1   \n",
      "1  2011-09-06                                      1   \n",
      "2  2011-09-07                                      1   \n",
      "3  2011-09-08                                      1   \n",
      "4  2011-09-09                                      1   \n",
      "\n",
      "  Calendar.School.no_lectivo.otros Calendar.School.vacaciones.navidad  \\\n",
      "0                                0                                  0   \n",
      "1                                0                                  0   \n",
      "2                                0                                  0   \n",
      "3                                0                                  0   \n",
      "4                                0                                  0   \n",
      "\n",
      "  Calendar.School.vacaciones.semana_santa Calendar.School.intensiva.fin_curso  \\\n",
      "0                                       0                                   0   \n",
      "1                                       0                                   0   \n",
      "2                                       0                                   0   \n",
      "3                                       0                                   0   \n",
      "4                                       0                                   0   \n",
      "\n",
      "  Calendar.School.vacaciones.verano Calendar.School.intensiva.navidad  \n",
      "0                                 0                                 0  \n",
      "1                                 0                                 0  \n",
      "2                                 0                                 0  \n",
      "3                                 0                                 0  \n",
      "4                                 0                                 0  \n",
      "festivo_eqinoc\n",
      "    festivo_fesnov\n",
      "    festivo_inmcns\n",
      "    festivo_navanu\n",
      "    festivo_priver\n",
      "    festivo_semsan\n",
      "    festivo_vrgago\n",
      "    nochenav_nochebuena\n",
      "    nochenav_nochevieja\n",
      "    oprretorno\n",
      "    oprsalida_prinolab\n",
      "    oprsalida_vispera\n"
     ]
    }
   ],
   "source": [
    "horizon = 13\n",
    "\n",
    "df = get_data(\"../2018_2019_data/28079008.csv\")\n",
    "X, y = prepare_data_from_horizon(df,horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(5,shuffle=True)\n",
    "train_index, test_index = list(kf.split(X))[1]\n",
    "\n",
    "train_index = X.index.values[train_index]\n",
    "test_index = X.index.values[test_index] \n",
    "        \n",
    "# Filter the test index when prediction time is 10:00\n",
    "ten_index = df[(df[\"DATE\"]-timedelta(hours=horizon)).dt.hour==10].index\n",
    "test_index_10 = test_index[pd.Series(test_index).isin(ten_index)]\n",
    "        \n",
    "# We retrieve the indexes that are related to the test indexes according to our AR model\n",
    "sel = np.concatenate([[1,2,3,4],\n",
    "                            [12],\n",
    "                            24*np.arange(1,9),\n",
    "                            12+24*np.arange(1,9)])  \n",
    "sel=np.concatenate([sel,sel-1,sel+1]) \n",
    "        \n",
    "all_index_related_test = set([])\n",
    "for i in sel:\n",
    "    all_index_related_test |= set(test_index_10+i)\n",
    "        \n",
    "train_index_CV = train_index[pd.Series(train_index).isin(list(all_index_related_test))]\n",
    "        \n",
    "X_train = X.loc[train_index_CV]\n",
    "y_train = y.loc[train_index_CV]\n",
    "        \n",
    "X_test = X.loc[test_index_10]\n",
    "y_test = y.loc[test_index_10]\n",
    "        \n",
    "scaler = RobustScaler()\n",
    "# Fit the scaler on the training features and transform these in one go\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "# Scale the test set\n",
    "X_test_std = scaler.transform(X_test)\n",
    "        \n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train_std,y_train)\n",
    "\n",
    "dif_train = y_train-lin.predict(X_train_std)\n",
    "dif_test = y_test-lin.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5bb6fa69ea4c1e9e8cffc7c5668b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4be51d7df2427f9043419b9ef95cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c2b27f9e1146b7b84a9a96b798aacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a40912bc8484ef0867e832b9030aa70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x11a1cf670>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastien.perez/anaconda3/lib/python3.8/site-packages/tqdm/std.py\", line 1122, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/sebastien.perez/anaconda3/lib/python3.8/site-packages/tqdm/notebook.py\", line 261, in close\n",
      "    self.sp(bar_style='danger')\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bf0ab60f394f888657e35c3ad33cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122581feee3b483cb3a0ae77475b3dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667b65a4938c4f979bbd4eeff9d93c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08fcc8a91514043b66ef0482176fb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107f9fcb11c74ca29a05ef1ac88c1106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1833e9c3be6b414e98687e668f0c6726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666fec7b0d314e078164109471f88b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2438b0bf33914f3ca597942f5b9daeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694dc64cb00b4d9d8d0f6a9ce3ad9c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d0a9091d2fa4f21aae6efbdf85071c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c103948a7a3f4d4684268e613758fe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e462851181a4348a4a9168ae17fbcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253f719545da4ba48ebaa403ead6d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de84eb8cd5c74f62871e486dae4b24ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e37b351ce040b3aa2bb68367d8136c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7330f1e81b6492da32582bbbd706bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae360044ab146ad9ec9ae67f7b3197b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d059f482bb4201bebc71817bd6820b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1343acf21eb4d59acd186da0cfdd7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d497c7b4435d42c59fd9e59839fd0cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ce40658a594206a42a7f3c19e51b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d71a34ac824510acdfda646cf3c8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d34164c0344b9b7867f9edac7375b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7560a697564a849a705a5cb78b57e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18afe42f94e4ee890451f2b1902bb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7541fd8cc2a549b3af0aee5f087b0aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac3999798884d7c827e137939cc05fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de21c4770174f5a824528894ea155b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd6ccf280144e708f70dc7b1b15a2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6aa6cce9cf741f7ba3806acc4dd685a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a416cd08ea74a919744c042d8ab2abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020d012ff67a4200a66c7715eb23cf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3a886382f246ecad0d248a30b74271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7ad144e3ef4589972a4b2c6d9d2917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbe257138c143e8a2c0dd65463371e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213dba94f47f42a490b2bc32de28b3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1c60013bc340cbab66b17a50edc2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb99845474447be80442d5291a86f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb358ef7ddd418f828d973875483f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068608acaa5a4ad6ae0c442086822975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96379e46b8d54da393024dbe586a547c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419855154b114a53a6cb4952ce7d142c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ff84a1e14e4fc3a5e3f0f67998a033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1295b81ba78c4a648125cb4f600f32bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2862a1d7217549db8fc40b047eeb53ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b117bd53d44959b9e7c5b43b99e240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746134b5916848919e663015d4d794e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2881757f4bd44fd8931f7a1af7c77601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a41476e9d8f4a4eaa9dd5c9d656bc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7a35996fab43e0a144aa20ccc684a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07a903574504335848c5b2366c9501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9f4f98e4474b78b71e085c7b4ad995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87911b07bd041e39e531b51ba55c65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e5645132a444bfad64beea90109e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa30df11eeb4b93ac7c00c3e32a0ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ff49515152412eba7d5dd0ee103e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6964af92d1944aaaafe2b9c5c0157c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd56c0ebfc5b46d3b1726e7044b1c76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22da95dcc7334f44b296f7319861b0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df4d3a2a5034537ab66fa1157f19da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b962cce56804a2082b105c7ab91290e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6a5ad105d642f5ae4a01ee1235791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9e697203174dfa90948a8d3c74f297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515239253ef5464fb8efadf54f1b93bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efa56c8e96d4638ad84da652718f66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d7e43e5268470bbd78104653ab4eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14486b0ab7fa48778232535e8604beab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1a4ed7c536462789fb28cd26b3f471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7390dec309f41b9b6c67c91ab3e82ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed58c5fac184b5c8c311d25de8cc2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12054acc3324e37852096cd21e6e71e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0002adafaf5d498db0b01e8a9089e1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5ba5711619436994a1b70e8ad82aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c80df3407e74468b5988c4e06870cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9652191a7a142628a654bdf4973af19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca071cf588347bb8e4dee957cc37926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8880be2e5646ca9667fc93b8038949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98880136e60948819e2f21d8408fd3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2158027236f4f0898dabd63190aebf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3caab94599a94e79a73dc43912a966a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b12c474e5434470838b51596ffd9766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26722d8c7ea243509446199416f6130b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f739527b65400ea25e0fe946d2c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d088a6847e4984b9875f4dc2554d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d7dd16a9b2499bbdb9d8988889b02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a63d6b39fc048a8850645b14c990a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e119f7fc4d4240fd84316c1ff3b8e697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00acf9300b544400adb1c4c9d83772e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alls=[]\n",
    "\n",
    "for n_estimator in tqdm([500,600,700,800,900,1000,1100]):\n",
    "    for max_depth in tqdm([4,6,8,10,12,14]):\n",
    "        qreg = TotalLGBQuantile(n_estimators=n_estimator,max_depth=max_depth)\n",
    "        qreg.fit(X_train_std,y_train)\n",
    "        preds = qreg.predict(X_test_std)\n",
    "        results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n",
    "        del results[\"all\"]\n",
    "        del results[\"target\"]\n",
    "        results[\"n_estimator\"]=n_estimator\n",
    "        results[\"max_depth\"]=max_depth\n",
    "        alls.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crps</th>\n",
       "      <th>count</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>bias</th>\n",
       "      <th>corr</th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>13.112044</td>\n",
       "      <td>465</td>\n",
       "      <td>26.195570</td>\n",
       "      <td>18.389143</td>\n",
       "      <td>2.557965</td>\n",
       "      <td>0.750437</td>\n",
       "      <td>1100</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.147471</td>\n",
       "      <td>465</td>\n",
       "      <td>26.276481</td>\n",
       "      <td>18.426206</td>\n",
       "      <td>2.578699</td>\n",
       "      <td>0.748572</td>\n",
       "      <td>1000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.158772</td>\n",
       "      <td>466</td>\n",
       "      <td>26.331609</td>\n",
       "      <td>18.480324</td>\n",
       "      <td>2.641233</td>\n",
       "      <td>0.747443</td>\n",
       "      <td>900</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>13.168241</td>\n",
       "      <td>458</td>\n",
       "      <td>26.344224</td>\n",
       "      <td>18.464018</td>\n",
       "      <td>2.598883</td>\n",
       "      <td>0.746472</td>\n",
       "      <td>1100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.189537</td>\n",
       "      <td>458</td>\n",
       "      <td>26.373749</td>\n",
       "      <td>18.490690</td>\n",
       "      <td>2.602618</td>\n",
       "      <td>0.745804</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.170047</td>\n",
       "      <td>466</td>\n",
       "      <td>26.398462</td>\n",
       "      <td>18.535942</td>\n",
       "      <td>2.678638</td>\n",
       "      <td>0.745948</td>\n",
       "      <td>800</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13.182804</td>\n",
       "      <td>461</td>\n",
       "      <td>26.418200</td>\n",
       "      <td>18.533462</td>\n",
       "      <td>2.567523</td>\n",
       "      <td>0.744575</td>\n",
       "      <td>800</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.253145</td>\n",
       "      <td>457</td>\n",
       "      <td>26.419564</td>\n",
       "      <td>18.516333</td>\n",
       "      <td>2.592532</td>\n",
       "      <td>0.744601</td>\n",
       "      <td>900</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.209801</td>\n",
       "      <td>466</td>\n",
       "      <td>26.457832</td>\n",
       "      <td>18.559086</td>\n",
       "      <td>2.721503</td>\n",
       "      <td>0.744805</td>\n",
       "      <td>700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.173501</td>\n",
       "      <td>464</td>\n",
       "      <td>26.500201</td>\n",
       "      <td>18.589906</td>\n",
       "      <td>2.596564</td>\n",
       "      <td>0.742723</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.207856</td>\n",
       "      <td>464</td>\n",
       "      <td>26.583122</td>\n",
       "      <td>18.658841</td>\n",
       "      <td>2.675238</td>\n",
       "      <td>0.741017</td>\n",
       "      <td>600</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>13.214594</td>\n",
       "      <td>462</td>\n",
       "      <td>26.628387</td>\n",
       "      <td>18.729899</td>\n",
       "      <td>2.550173</td>\n",
       "      <td>0.739668</td>\n",
       "      <td>1100</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.239615</td>\n",
       "      <td>468</td>\n",
       "      <td>26.670835</td>\n",
       "      <td>18.671833</td>\n",
       "      <td>2.889488</td>\n",
       "      <td>0.740474</td>\n",
       "      <td>600</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13.242377</td>\n",
       "      <td>462</td>\n",
       "      <td>26.681595</td>\n",
       "      <td>18.774120</td>\n",
       "      <td>2.523376</td>\n",
       "      <td>0.738324</td>\n",
       "      <td>1000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.290473</td>\n",
       "      <td>467</td>\n",
       "      <td>26.761717</td>\n",
       "      <td>18.720776</td>\n",
       "      <td>2.965302</td>\n",
       "      <td>0.738726</td>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.328099</td>\n",
       "      <td>464</td>\n",
       "      <td>26.772235</td>\n",
       "      <td>18.774527</td>\n",
       "      <td>2.711112</td>\n",
       "      <td>0.736561</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.264845</td>\n",
       "      <td>463</td>\n",
       "      <td>26.789537</td>\n",
       "      <td>18.814290</td>\n",
       "      <td>2.590395</td>\n",
       "      <td>0.735745</td>\n",
       "      <td>900</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.391757</td>\n",
       "      <td>461</td>\n",
       "      <td>26.871143</td>\n",
       "      <td>18.809838</td>\n",
       "      <td>2.924421</td>\n",
       "      <td>0.733967</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.428912</td>\n",
       "      <td>460</td>\n",
       "      <td>26.883767</td>\n",
       "      <td>18.802908</td>\n",
       "      <td>2.950958</td>\n",
       "      <td>0.733655</td>\n",
       "      <td>1100</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.311488</td>\n",
       "      <td>464</td>\n",
       "      <td>26.884413</td>\n",
       "      <td>18.870933</td>\n",
       "      <td>2.664711</td>\n",
       "      <td>0.733807</td>\n",
       "      <td>800</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.409029</td>\n",
       "      <td>462</td>\n",
       "      <td>26.910918</td>\n",
       "      <td>18.855735</td>\n",
       "      <td>2.942812</td>\n",
       "      <td>0.733054</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.333974</td>\n",
       "      <td>464</td>\n",
       "      <td>26.931550</td>\n",
       "      <td>18.922648</td>\n",
       "      <td>2.655267</td>\n",
       "      <td>0.732678</td>\n",
       "      <td>700</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13.440783</td>\n",
       "      <td>463</td>\n",
       "      <td>26.991979</td>\n",
       "      <td>18.910126</td>\n",
       "      <td>2.981060</td>\n",
       "      <td>0.731115</td>\n",
       "      <td>800</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.368955</td>\n",
       "      <td>466</td>\n",
       "      <td>26.994342</td>\n",
       "      <td>18.981971</td>\n",
       "      <td>2.703822</td>\n",
       "      <td>0.731361</td>\n",
       "      <td>600</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.440247</td>\n",
       "      <td>463</td>\n",
       "      <td>27.031085</td>\n",
       "      <td>18.930413</td>\n",
       "      <td>2.994990</td>\n",
       "      <td>0.730087</td>\n",
       "      <td>700</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.418337</td>\n",
       "      <td>467</td>\n",
       "      <td>27.091628</td>\n",
       "      <td>19.031871</td>\n",
       "      <td>2.779578</td>\n",
       "      <td>0.729212</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.427883</td>\n",
       "      <td>462</td>\n",
       "      <td>27.120764</td>\n",
       "      <td>18.948975</td>\n",
       "      <td>3.062111</td>\n",
       "      <td>0.728099</td>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.455343</td>\n",
       "      <td>465</td>\n",
       "      <td>27.171548</td>\n",
       "      <td>18.992467</td>\n",
       "      <td>3.074915</td>\n",
       "      <td>0.726990</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.477612</td>\n",
       "      <td>461</td>\n",
       "      <td>27.229100</td>\n",
       "      <td>18.916702</td>\n",
       "      <td>3.294832</td>\n",
       "      <td>0.727049</td>\n",
       "      <td>1100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.482239</td>\n",
       "      <td>462</td>\n",
       "      <td>27.262172</td>\n",
       "      <td>18.946083</td>\n",
       "      <td>3.287361</td>\n",
       "      <td>0.726217</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.508248</td>\n",
       "      <td>463</td>\n",
       "      <td>27.303024</td>\n",
       "      <td>18.976687</td>\n",
       "      <td>3.300612</td>\n",
       "      <td>0.725292</td>\n",
       "      <td>900</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.496189</td>\n",
       "      <td>465</td>\n",
       "      <td>27.332634</td>\n",
       "      <td>18.992233</td>\n",
       "      <td>3.345579</td>\n",
       "      <td>0.724919</td>\n",
       "      <td>800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.495303</td>\n",
       "      <td>465</td>\n",
       "      <td>27.345735</td>\n",
       "      <td>19.009154</td>\n",
       "      <td>3.277850</td>\n",
       "      <td>0.724351</td>\n",
       "      <td>700</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.461536</td>\n",
       "      <td>466</td>\n",
       "      <td>27.394730</td>\n",
       "      <td>19.031502</td>\n",
       "      <td>3.331097</td>\n",
       "      <td>0.723774</td>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.525943</td>\n",
       "      <td>468</td>\n",
       "      <td>27.454243</td>\n",
       "      <td>19.098036</td>\n",
       "      <td>3.377264</td>\n",
       "      <td>0.722550</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13.701616</td>\n",
       "      <td>469</td>\n",
       "      <td>27.727358</td>\n",
       "      <td>19.477162</td>\n",
       "      <td>3.432097</td>\n",
       "      <td>0.713756</td>\n",
       "      <td>1100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.776523</td>\n",
       "      <td>469</td>\n",
       "      <td>27.756053</td>\n",
       "      <td>19.521267</td>\n",
       "      <td>3.479917</td>\n",
       "      <td>0.713324</td>\n",
       "      <td>900</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.744390</td>\n",
       "      <td>469</td>\n",
       "      <td>27.756233</td>\n",
       "      <td>19.505297</td>\n",
       "      <td>3.406344</td>\n",
       "      <td>0.712911</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.780025</td>\n",
       "      <td>470</td>\n",
       "      <td>27.804232</td>\n",
       "      <td>19.559548</td>\n",
       "      <td>3.511091</td>\n",
       "      <td>0.712236</td>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.847462</td>\n",
       "      <td>470</td>\n",
       "      <td>27.858538</td>\n",
       "      <td>19.599348</td>\n",
       "      <td>3.523213</td>\n",
       "      <td>0.710899</td>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.842764</td>\n",
       "      <td>471</td>\n",
       "      <td>27.859563</td>\n",
       "      <td>19.603944</td>\n",
       "      <td>3.627682</td>\n",
       "      <td>0.711737</td>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.905345</td>\n",
       "      <td>472</td>\n",
       "      <td>27.946432</td>\n",
       "      <td>19.637701</td>\n",
       "      <td>3.666047</td>\n",
       "      <td>0.709569</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crps  count       rmse        mae      bias      corr  n_estimator  \\\n",
       "41  13.112044    465  26.195570  18.389143  2.557965  0.750437         1100   \n",
       "35  13.147471    465  26.276481  18.426206  2.578699  0.748572         1000   \n",
       "29  13.158772    466  26.331609  18.480324  2.641233  0.747443          900   \n",
       "39  13.168241    458  26.344224  18.464018  2.598883  0.746472         1100   \n",
       "33  13.189537    458  26.373749  18.490690  2.602618  0.745804         1000   \n",
       "23  13.170047    466  26.398462  18.535942  2.678638  0.745948          800   \n",
       "21  13.182804    461  26.418200  18.533462  2.567523  0.744575          800   \n",
       "27  13.253145    457  26.419564  18.516333  2.592532  0.744601          900   \n",
       "17  13.209801    466  26.457832  18.559086  2.721503  0.744805          700   \n",
       "15  13.173501    464  26.500201  18.589906  2.596564  0.742723          700   \n",
       "9   13.207856    464  26.583122  18.658841  2.675238  0.741017          600   \n",
       "40  13.214594    462  26.628387  18.729899  2.550173  0.739668         1100   \n",
       "11  13.239615    468  26.670835  18.671833  2.889488  0.740474          600   \n",
       "34  13.242377    462  26.681595  18.774120  2.523376  0.738324         1000   \n",
       "5   13.290473    467  26.761717  18.720776  2.965302  0.738726          500   \n",
       "3   13.328099    464  26.772235  18.774527  2.711112  0.736561          500   \n",
       "28  13.264845    463  26.789537  18.814290  2.590395  0.735745          900   \n",
       "32  13.391757    461  26.871143  18.809838  2.924421  0.733967         1000   \n",
       "38  13.428912    460  26.883767  18.802908  2.950958  0.733655         1100   \n",
       "22  13.311488    464  26.884413  18.870933  2.664711  0.733807          800   \n",
       "26  13.409029    462  26.910918  18.855735  2.942812  0.733054          900   \n",
       "16  13.333974    464  26.931550  18.922648  2.655267  0.732678          700   \n",
       "20  13.440783    463  26.991979  18.910126  2.981060  0.731115          800   \n",
       "10  13.368955    466  26.994342  18.981971  2.703822  0.731361          600   \n",
       "14  13.440247    463  27.031085  18.930413  2.994990  0.730087          700   \n",
       "4   13.418337    467  27.091628  19.031871  2.779578  0.729212          500   \n",
       "8   13.427883    462  27.120764  18.948975  3.062111  0.728099          600   \n",
       "2   13.455343    465  27.171548  18.992467  3.074915  0.726990          500   \n",
       "37  13.477612    461  27.229100  18.916702  3.294832  0.727049         1100   \n",
       "31  13.482239    462  27.262172  18.946083  3.287361  0.726217         1000   \n",
       "25  13.508248    463  27.303024  18.976687  3.300612  0.725292          900   \n",
       "19  13.496189    465  27.332634  18.992233  3.345579  0.724919          800   \n",
       "13  13.495303    465  27.345735  19.009154  3.277850  0.724351          700   \n",
       "7   13.461536    466  27.394730  19.031502  3.331097  0.723774          600   \n",
       "1   13.525943    468  27.454243  19.098036  3.377264  0.722550          500   \n",
       "36  13.701616    469  27.727358  19.477162  3.432097  0.713756         1100   \n",
       "24  13.776523    469  27.756053  19.521267  3.479917  0.713324          900   \n",
       "30  13.744390    469  27.756233  19.505297  3.406344  0.712911         1000   \n",
       "18  13.780025    470  27.804232  19.559548  3.511091  0.712236          800   \n",
       "12  13.847462    470  27.858538  19.599348  3.523213  0.710899          700   \n",
       "6   13.842764    471  27.859563  19.603944  3.627682  0.711737          600   \n",
       "0   13.905345    472  27.946432  19.637701  3.666047  0.709569          500   \n",
       "\n",
       "    max_depth  \n",
       "41         14  \n",
       "35         14  \n",
       "29         14  \n",
       "39         10  \n",
       "33         10  \n",
       "23         14  \n",
       "21         10  \n",
       "27         10  \n",
       "17         14  \n",
       "15         10  \n",
       "9          10  \n",
       "40         12  \n",
       "11         14  \n",
       "34         12  \n",
       "5          14  \n",
       "3          10  \n",
       "28         12  \n",
       "32          8  \n",
       "38          8  \n",
       "22         12  \n",
       "26          8  \n",
       "16         12  \n",
       "20          8  \n",
       "10         12  \n",
       "14          8  \n",
       "4          12  \n",
       "8           8  \n",
       "2           8  \n",
       "37          6  \n",
       "31          6  \n",
       "25          6  \n",
       "19          6  \n",
       "13          6  \n",
       "7           6  \n",
       "1           6  \n",
       "36          4  \n",
       "24          4  \n",
       "30          4  \n",
       "18          4  \n",
       "12          4  \n",
       "6           4  \n",
       "0           4  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(alls).sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c397c3fed8149cfa91bf84b03859225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a40c94ceed44f9bf2dd683fa344371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb8fa19b3fd43a9993142d3c2c5d469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17063b729794614befba0bb704003c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385c41477b9e4b14a1db5abd4d062017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380241b719864d7db6e99bf57640f9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bcb22e0e0244e09b0d892892f87a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69025528d1e14d38b4aa00bf448f0840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fd52e470af43839f8a4a9856593641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841218c2b6c1443b827b26f685953d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fef3805fbe3470b98969b81d2cc9b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3276834843b405e9cc7d7abc4278dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94babd5541004b95befc713d8ed97f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed125bc566be45208913223a9515e3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16be41fd7ec1456c9d299d3a9c5bb4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a296344a9cf64c0da9ef59d5277d7265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188882f74a634e6b8d42593de81eaed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171b78c71f5b47588446cf5c3a45b2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2ecbd1f1a042e39cb7dab673932ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd96e81781b47fb9e626505c1dfa3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76a6bb6661749918d494bf8d1cd258f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f03b762a5d94e12a0967207f07bcb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crps</th>\n",
       "      <th>count</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>bias</th>\n",
       "      <th>corr</th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.844544</td>\n",
       "      <td>506</td>\n",
       "      <td>24.586943</td>\n",
       "      <td>16.710684</td>\n",
       "      <td>2.939157</td>\n",
       "      <td>0.793963</td>\n",
       "      <td>1900</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.870154</td>\n",
       "      <td>506</td>\n",
       "      <td>24.656012</td>\n",
       "      <td>16.750462</td>\n",
       "      <td>2.935235</td>\n",
       "      <td>0.792500</td>\n",
       "      <td>1700</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.946960</td>\n",
       "      <td>505</td>\n",
       "      <td>24.744015</td>\n",
       "      <td>16.810188</td>\n",
       "      <td>2.940530</td>\n",
       "      <td>0.790726</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.910498</td>\n",
       "      <td>508</td>\n",
       "      <td>24.929993</td>\n",
       "      <td>16.691116</td>\n",
       "      <td>2.852361</td>\n",
       "      <td>0.785449</td>\n",
       "      <td>1900</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.928698</td>\n",
       "      <td>508</td>\n",
       "      <td>24.949022</td>\n",
       "      <td>16.715360</td>\n",
       "      <td>2.907771</td>\n",
       "      <td>0.785276</td>\n",
       "      <td>1700</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.964930</td>\n",
       "      <td>508</td>\n",
       "      <td>25.027565</td>\n",
       "      <td>16.787508</td>\n",
       "      <td>2.903996</td>\n",
       "      <td>0.783670</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.067769</td>\n",
       "      <td>508</td>\n",
       "      <td>25.037905</td>\n",
       "      <td>16.992165</td>\n",
       "      <td>2.818733</td>\n",
       "      <td>0.783291</td>\n",
       "      <td>1900</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.075730</td>\n",
       "      <td>508</td>\n",
       "      <td>25.050652</td>\n",
       "      <td>17.003337</td>\n",
       "      <td>2.819423</td>\n",
       "      <td>0.783022</td>\n",
       "      <td>1700</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.119178</td>\n",
       "      <td>508</td>\n",
       "      <td>25.100846</td>\n",
       "      <td>17.057005</td>\n",
       "      <td>2.832693</td>\n",
       "      <td>0.782127</td>\n",
       "      <td>1500</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crps  count       rmse        mae      bias      corr  n_estimator  \\\n",
       "6  11.844544    506  24.586943  16.710684  2.939157  0.793963         1900   \n",
       "3  11.870154    506  24.656012  16.750462  2.935235  0.792500         1700   \n",
       "0  11.946960    505  24.744015  16.810188  2.940530  0.790726         1500   \n",
       "8  11.910498    508  24.929993  16.691116  2.852361  0.785449         1900   \n",
       "5  11.928698    508  24.949022  16.715360  2.907771  0.785276         1700   \n",
       "2  11.964930    508  25.027565  16.787508  2.903996  0.783670         1500   \n",
       "7  12.067769    508  25.037905  16.992165  2.818733  0.783291         1900   \n",
       "4  12.075730    508  25.050652  17.003337  2.819423  0.783022         1700   \n",
       "1  12.119178    508  25.100846  17.057005  2.832693  0.782127         1500   \n",
       "\n",
       "   max_depth  \n",
       "6         16  \n",
       "3         16  \n",
       "0         16  \n",
       "8         20  \n",
       "5         20  \n",
       "2         20  \n",
       "7         18  \n",
       "4         18  \n",
       "1         18  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls=[]\n",
    "\n",
    "for n_estimator in tqdm([1500,1700,1900]):\n",
    "    for max_depth in tqdm([16,18,20]):\n",
    "        qreg = TotalLGBQuantile(n_estimators=n_estimator,max_depth=max_depth)\n",
    "        qreg.fit(X_train_std,y_train)\n",
    "        preds = qreg.predict(X_test_std)\n",
    "        results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n",
    "        del results[\"all\"]\n",
    "        del results[\"target\"]\n",
    "        results[\"n_estimator\"]=n_estimator\n",
    "        results[\"max_depth\"]=max_depth\n",
    "        alls.append(results)\n",
    "pd.DataFrame(alls).sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032c4d4a2fe240f6b1989335cc97d432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58a68ee82eb4c8b871d3f607f5a2145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601fdad785f4084ab3b4772e13f1363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c0e9928c2149d2acd316da6ceaa51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc1f720c3004eda989ca18515bc059b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc5353a44144aefab6ad80c3459718e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e550f0eeacb487b9fd54e6dc9a8019e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc13f991bcd48509ec54ad989d5cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd4afb334f344928474d2b21cc5df79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c773927bf2824f1c811e36a8cb808dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff46ea37844266853009327018f0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945440aaac70403781e240ce5ed8d041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cf70144b524114867a8ea115fd625d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab87c2220fa44efb8643c4c363a500c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811d373518724126a3445c9e08555a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a13e2e7e7494fb5f73afb3ac0cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2116aa9dcc9645dfbbe045cb11b4b40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdad480ede84165bcb1a79cb855014a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1101efc3c6478d948aaccb31de6db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286ef3a6234247b7b2fec33da50ad50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training !\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a243ca2e3e5f4c11a5b213971682211c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile: 0.022750131948179195\n",
      "[LightGBM] [Warning] Unknown parameter: loss\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Quantile: 0.15865525393145707\n",
      "Quantile: 0.5\n",
      "Quantile: 0.8413447460685429\n",
      "Quantile: 0.9772498680518208\n",
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca067c5675643ab95c9efda31780aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crps</th>\n",
       "      <th>count</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>bias</th>\n",
       "      <th>corr</th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.305422</td>\n",
       "      <td>501</td>\n",
       "      <td>25.323187</td>\n",
       "      <td>17.419142</td>\n",
       "      <td>2.393561</td>\n",
       "      <td>0.775451</td>\n",
       "      <td>1900</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.365605</td>\n",
       "      <td>500</td>\n",
       "      <td>25.403507</td>\n",
       "      <td>17.478062</td>\n",
       "      <td>2.382649</td>\n",
       "      <td>0.773622</td>\n",
       "      <td>1700</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.430092</td>\n",
       "      <td>500</td>\n",
       "      <td>25.511866</td>\n",
       "      <td>17.565425</td>\n",
       "      <td>2.420305</td>\n",
       "      <td>0.771363</td>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.478619</td>\n",
       "      <td>500</td>\n",
       "      <td>25.578052</td>\n",
       "      <td>17.493194</td>\n",
       "      <td>2.477631</td>\n",
       "      <td>0.770689</td>\n",
       "      <td>1900</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.559875</td>\n",
       "      <td>500</td>\n",
       "      <td>25.717836</td>\n",
       "      <td>17.597044</td>\n",
       "      <td>2.496593</td>\n",
       "      <td>0.767575</td>\n",
       "      <td>1700</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.584963</td>\n",
       "      <td>502</td>\n",
       "      <td>25.777273</td>\n",
       "      <td>17.665578</td>\n",
       "      <td>2.489691</td>\n",
       "      <td>0.766247</td>\n",
       "      <td>1500</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.630936</td>\n",
       "      <td>501</td>\n",
       "      <td>25.949323</td>\n",
       "      <td>17.885219</td>\n",
       "      <td>2.200429</td>\n",
       "      <td>0.760398</td>\n",
       "      <td>1900</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.693372</td>\n",
       "      <td>501</td>\n",
       "      <td>26.086942</td>\n",
       "      <td>17.973778</td>\n",
       "      <td>2.260202</td>\n",
       "      <td>0.757491</td>\n",
       "      <td>1700</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.754133</td>\n",
       "      <td>501</td>\n",
       "      <td>26.141296</td>\n",
       "      <td>18.032357</td>\n",
       "      <td>2.220521</td>\n",
       "      <td>0.756226</td>\n",
       "      <td>1500</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crps  count       rmse        mae      bias      corr  n_estimator  \\\n",
       "8  12.305422    501  25.323187  17.419142  2.393561  0.775451         1900   \n",
       "5  12.365605    500  25.403507  17.478062  2.382649  0.773622         1700   \n",
       "2  12.430092    500  25.511866  17.565425  2.420305  0.771363         1500   \n",
       "7  12.478619    500  25.578052  17.493194  2.477631  0.770689         1900   \n",
       "4  12.559875    500  25.717836  17.597044  2.496593  0.767575         1700   \n",
       "1  12.584963    502  25.777273  17.665578  2.489691  0.766247         1500   \n",
       "6  12.630936    501  25.949323  17.885219  2.200429  0.760398         1900   \n",
       "3  12.693372    501  26.086942  17.973778  2.260202  0.757491         1700   \n",
       "0  12.754133    501  26.141296  18.032357  2.220521  0.756226         1500   \n",
       "\n",
       "   max_depth  \n",
       "8         20  \n",
       "5         20  \n",
       "2         20  \n",
       "7         18  \n",
       "4         18  \n",
       "1         18  \n",
       "6         16  \n",
       "3         16  \n",
       "0         16  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alls=[]\n",
    "\n",
    "for n_estimator in tqdm([1500,1700,1900]):\n",
    "    for max_depth in tqdm([16,18,20]):\n",
    "        qreg = TotalLGBQuantile(n_estimators=n_estimator,max_depth=max_depth)\n",
    "        \n",
    "        qreg.fit(X_train,dif_train)\n",
    "        pred_difs = qreg.predict(X_test)\n",
    "        a=pd.DataFrame(pred_difs)\n",
    "        for col in a.columns:\n",
    "            a[col] += lin.predict(X_test_std) \n",
    "        \n",
    "        results=evaluate((np.exp(a)-1).values,(np.exp(y_test)-1).values)\n",
    "        del results[\"all\"]\n",
    "        del results[\"target\"]\n",
    "        results[\"n_estimator\"]=n_estimator\n",
    "        results[\"max_depth\"]=max_depth\n",
    "        alls.append(results)\n",
    "pd.DataFrame(alls).sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.0716 - val_loss: 0.0467\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 945us/step - loss: 0.0446 - val_loss: 0.0365\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 949us/step - loss: 0.0364 - val_loss: 0.0310\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 998us/step - loss: 0.0324 - val_loss: 0.0300\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 948us/step - loss: 0.0300 - val_loss: 0.0289\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 889us/step - loss: 0.0284 - val_loss: 0.0272\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 926us/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 921us/step - loss: 0.0260 - val_loss: 0.0254\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0250 - val_loss: 0.0247\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 925us/step - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 911us/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 893us/step - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 914us/step - loss: 0.0223 - val_loss: 0.0230\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0225\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 971us/step - loss: 0.0214 - val_loss: 0.0223\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 991us/step - loss: 0.0209 - val_loss: 0.0225\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 929us/step - loss: 0.0207 - val_loss: 0.0220\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 913us/step - loss: 0.0206 - val_loss: 0.0218\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 966us/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 997us/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0210\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0212\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 982us/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 946us/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 991us/step - loss: 0.0186 - val_loss: 0.0207\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 970us/step - loss: 0.0186 - val_loss: 0.0209\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 995us/step - loss: 0.0187 - val_loss: 0.0208\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 971us/step - loss: 0.0181 - val_loss: 0.0202\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 996us/step - loss: 0.0181 - val_loss: 0.0201\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 962us/step - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 958us/step - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0197\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 928us/step - loss: 0.0177 - val_loss: 0.0198\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 982us/step - loss: 0.0177 - val_loss: 0.0204\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0208\n",
      "Epoch 38/200\n",
      "377/377 [==============================] - 0s 896us/step - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 903us/step - loss: 0.0173 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 976us/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0200\n",
      "Epoch 42/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.0171 - val_loss: 0.0201\n",
      "Epoch 43/200\n",
      "377/377 [==============================] - 0s 922us/step - loss: 0.0169 - val_loss: 0.0202\n",
      "Epoch 44/200\n",
      "377/377 [==============================] - 0s 886us/step - loss: 0.0168 - val_loss: 0.0201\n",
      "Epoch 00044: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.5112 - val_loss: 0.2180\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 927us/step - loss: 0.2042 - val_loss: 0.1574\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 912us/step - loss: 0.1591 - val_loss: 0.1380\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 971us/step - loss: 0.1415 - val_loss: 0.1293\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1303 - val_loss: 0.1252\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1234 - val_loss: 0.1148\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 998us/step - loss: 0.1165 - val_loss: 0.1098\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1123 - val_loss: 0.1086\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1094 - val_loss: 0.1058\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 987us/step - loss: 0.1049 - val_loss: 0.1034\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1020 - val_loss: 0.1012\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 950us/step - loss: 0.1004 - val_loss: 0.0990\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0969 - val_loss: 0.1004\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 959us/step - loss: 0.0959 - val_loss: 0.0955\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0930 - val_loss: 0.0940\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 922us/step - loss: 0.0935 - val_loss: 0.0940\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 942us/step - loss: 0.0899 - val_loss: 0.0934\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 894us/step - loss: 0.0888 - val_loss: 0.0924\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 915us/step - loss: 0.0884 - val_loss: 0.0908\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0906\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0865 - val_loss: 0.0899\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0891\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 934us/step - loss: 0.0849 - val_loss: 0.0883\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0842 - val_loss: 0.0886\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0838 - val_loss: 0.0880\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0889\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0821 - val_loss: 0.0870\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0863\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 921us/step - loss: 0.0822 - val_loss: 0.0869\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 961us/step - loss: 0.0809 - val_loss: 0.0870\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0794 - val_loss: 0.0855\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0797 - val_loss: 0.0858\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 973us/step - loss: 0.0787 - val_loss: 0.0844\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0795 - val_loss: 0.0851\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0792 - val_loss: 0.0848\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0776 - val_loss: 0.0851\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0771 - val_loss: 0.0849\n",
      "Epoch 38/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0772 - val_loss: 0.0857\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 991us/step - loss: 0.0772 - val_loss: 0.0842\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 938us/step - loss: 0.0754 - val_loss: 0.0836\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 948us/step - loss: 0.0774 - val_loss: 0.0838\n",
      "Epoch 42/200\n",
      "377/377 [==============================] - 0s 903us/step - loss: 0.0758 - val_loss: 0.0836\n",
      "Epoch 43/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.0748 - val_loss: 0.0831\n",
      "Epoch 44/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0829\n",
      "Epoch 45/200\n",
      "377/377 [==============================] - 0s 937us/step - loss: 0.0749 - val_loss: 0.0828\n",
      "Epoch 46/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.0750 - val_loss: 0.0832\n",
      "Epoch 47/200\n",
      "377/377 [==============================] - 0s 990us/step - loss: 0.0745 - val_loss: 0.0833\n",
      "Epoch 48/200\n",
      "377/377 [==============================] - 0s 918us/step - loss: 0.0745 - val_loss: 0.0838\n",
      "Epoch 49/200\n",
      "377/377 [==============================] - 0s 922us/step - loss: 0.0738 - val_loss: 0.0826\n",
      "Epoch 50/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0827\n",
      "Epoch 51/200\n",
      "377/377 [==============================] - 0s 992us/step - loss: 0.0732 - val_loss: 0.0833\n",
      "Epoch 52/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0723 - val_loss: 0.0831\n",
      "Epoch 53/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0734 - val_loss: 0.0815\n",
      "Epoch 54/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0825\n",
      "Epoch 55/200\n",
      "377/377 [==============================] - 0s 928us/step - loss: 0.0726 - val_loss: 0.0825\n",
      "Epoch 56/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0705 - val_loss: 0.0825\n",
      "Epoch 57/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0821\n",
      "Epoch 58/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0732 - val_loss: 0.0829\n",
      "Epoch 59/200\n",
      "377/377 [==============================] - 0s 964us/step - loss: 0.0721 - val_loss: 0.0819\n",
      "Epoch 60/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0823\n",
      "Epoch 61/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0714 - val_loss: 0.0814\n",
      "Epoch 62/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0718 - val_loss: 0.0808\n",
      "Epoch 63/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0703 - val_loss: 0.0822\n",
      "Epoch 64/200\n",
      "377/377 [==============================] - 0s 958us/step - loss: 0.0708 - val_loss: 0.0817\n",
      "Epoch 65/200\n",
      "377/377 [==============================] - 0s 930us/step - loss: 0.0705 - val_loss: 0.0821\n",
      "Epoch 66/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0698 - val_loss: 0.0797\n",
      "Epoch 67/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0701 - val_loss: 0.0811\n",
      "Epoch 68/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0696 - val_loss: 0.0817\n",
      "Epoch 69/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0699 - val_loss: 0.0808\n",
      "Epoch 70/200\n",
      "377/377 [==============================] - 0s 934us/step - loss: 0.0699 - val_loss: 0.0806\n",
      "Epoch 71/200\n",
      "377/377 [==============================] - 0s 899us/step - loss: 0.0687 - val_loss: 0.0811\n",
      "Epoch 72/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0692 - val_loss: 0.0820\n",
      "Epoch 73/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0694 - val_loss: 0.0814\n",
      "Epoch 74/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.0696 - val_loss: 0.0809\n",
      "Epoch 75/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0690 - val_loss: 0.0802\n",
      "Epoch 76/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0691 - val_loss: 0.0800\n",
      "Epoch 00076: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 1.4569 - val_loss: 0.5299\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 901us/step - loss: 0.4667 - val_loss: 0.3221\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.2644\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.2628 - val_loss: 0.2360\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.2350 - val_loss: 0.2189\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.2172 - val_loss: 0.2105\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.2060 - val_loss: 0.1983\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1928 - val_loss: 0.1904\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.1888\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1806\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1728\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 903us/step - loss: 0.1677 - val_loss: 0.1699\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.1635 - val_loss: 0.1667\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.1593 - val_loss: 0.1650\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.1564 - val_loss: 0.1623\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1537 - val_loss: 0.1581\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1501 - val_loss: 0.1561\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1473 - val_loss: 0.1552\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1480 - val_loss: 0.1523\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1422 - val_loss: 0.1522\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1431 - val_loss: 0.1503\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.1415 - val_loss: 0.1499\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1413 - val_loss: 0.1474\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1358 - val_loss: 0.1481\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.1371 - val_loss: 0.1470\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1374 - val_loss: 0.1454\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1441\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1325 - val_loss: 0.1426\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1319 - val_loss: 0.1425\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 958us/step - loss: 0.1307 - val_loss: 0.1432\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1315 - val_loss: 0.1417\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.1310 - val_loss: 0.1417\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1291 - val_loss: 0.1408\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1290 - val_loss: 0.1396\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.1275 - val_loss: 0.1394\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1258 - val_loss: 0.1398\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.1267 - val_loss: 0.1391\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1251 - val_loss: 0.1406\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1243 - val_loss: 0.1396\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 992us/step - loss: 0.1244 - val_loss: 0.1386\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1255 - val_loss: 0.1385\n",
      "Epoch 42/200\n",
      "377/377 [==============================] - 0s 899us/step - loss: 0.1250 - val_loss: 0.1372\n",
      "Epoch 43/200\n",
      "377/377 [==============================] - 0s 925us/step - loss: 0.1227 - val_loss: 0.1372\n",
      "Epoch 44/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1239 - val_loss: 0.1366\n",
      "Epoch 45/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.1225 - val_loss: 0.1369\n",
      "Epoch 46/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.1226 - val_loss: 0.1376\n",
      "Epoch 47/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.1229 - val_loss: 0.1363\n",
      "Epoch 48/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.1236 - val_loss: 0.1367\n",
      "Epoch 49/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.1208 - val_loss: 0.1363\n",
      "Epoch 50/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.1215 - val_loss: 0.1364\n",
      "Epoch 51/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.1202 - val_loss: 0.1360\n",
      "Epoch 52/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.1194 - val_loss: 0.1354\n",
      "Epoch 53/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.1185 - val_loss: 0.1359\n",
      "Epoch 54/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.1186 - val_loss: 0.1350\n",
      "Epoch 55/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.1182 - val_loss: 0.1360\n",
      "Epoch 56/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1180 - val_loss: 0.1371\n",
      "Epoch 57/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.1174 - val_loss: 0.1355\n",
      "Epoch 58/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.1171 - val_loss: 0.1365\n",
      "Epoch 59/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.1174 - val_loss: 0.1341\n",
      "Epoch 60/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.1172 - val_loss: 0.1345\n",
      "Epoch 61/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.1157 - val_loss: 0.1359\n",
      "Epoch 62/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.1150 - val_loss: 0.1365\n",
      "Epoch 63/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.1170 - val_loss: 0.1358\n",
      "Epoch 64/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.1163 - val_loss: 0.1346\n",
      "Epoch 65/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1149 - val_loss: 0.1359\n",
      "Epoch 66/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.1168 - val_loss: 0.1354\n",
      "Epoch 67/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.1148 - val_loss: 0.1359\n",
      "Epoch 68/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.1143 - val_loss: 0.1352\n",
      "Epoch 69/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.1136 - val_loss: 0.1349\n",
      "Epoch 00069: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 2.4669 - val_loss: 0.4687\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 914us/step - loss: 0.4124 - val_loss: 0.2731\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.2610 - val_loss: 0.2131\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.2026 - val_loss: 0.1829\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 889us/step - loss: 0.1775 - val_loss: 0.1701\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1607 - val_loss: 0.1588\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 891us/step - loss: 0.1510 - val_loss: 0.1499\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.1426 - val_loss: 0.1427\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.1341 - val_loss: 0.1351\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.1269 - val_loss: 0.1310\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.1207 - val_loss: 0.1244\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1164 - val_loss: 0.1203\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.1111 - val_loss: 0.1159\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.1066 - val_loss: 0.1140\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.1035 - val_loss: 0.1100\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 896us/step - loss: 0.1008 - val_loss: 0.1063\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0974 - val_loss: 0.1047\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0957 - val_loss: 0.1030\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0924 - val_loss: 0.0995\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.0932 - val_loss: 0.0994\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 891us/step - loss: 0.0899 - val_loss: 0.0991\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.0895 - val_loss: 0.0965\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 912us/step - loss: 0.0882 - val_loss: 0.0949\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0867 - val_loss: 0.0944\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0852 - val_loss: 0.0934\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 903us/step - loss: 0.0837 - val_loss: 0.0927\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0829 - val_loss: 0.0919\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0819 - val_loss: 0.0907\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0821 - val_loss: 0.0902\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0817 - val_loss: 0.0898\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0816 - val_loss: 0.0900\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.0804 - val_loss: 0.0884\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0793 - val_loss: 0.0877\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0794 - val_loss: 0.0884\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0776 - val_loss: 0.0873\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0779 - val_loss: 0.0863\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0783 - val_loss: 0.0864\n",
      "Epoch 38/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0767 - val_loss: 0.0857\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.0769 - val_loss: 0.0862\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.0754 - val_loss: 0.0851\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.0759 - val_loss: 0.0875\n",
      "Epoch 42/200\n",
      "377/377 [==============================] - 0s 949us/step - loss: 0.0749 - val_loss: 0.0860\n",
      "Epoch 43/200\n",
      "377/377 [==============================] - 0s 900us/step - loss: 0.0755 - val_loss: 0.0859\n",
      "Epoch 44/200\n",
      "377/377 [==============================] - 0s 930us/step - loss: 0.0758 - val_loss: 0.0861\n",
      "Epoch 45/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0744 - val_loss: 0.0854\n",
      "Epoch 46/200\n",
      "377/377 [==============================] - 0s 905us/step - loss: 0.0737 - val_loss: 0.0854\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 889us/step - loss: 0.0721 - val_loss: 0.0853\n",
      "Epoch 48/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0724 - val_loss: 0.0850\n",
      "Epoch 49/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0729 - val_loss: 0.0832\n",
      "Epoch 50/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0730 - val_loss: 0.0851\n",
      "Epoch 51/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0721 - val_loss: 0.0856\n",
      "Epoch 52/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.0725 - val_loss: 0.0849\n",
      "Epoch 53/200\n",
      "377/377 [==============================] - 0s 929us/step - loss: 0.0724 - val_loss: 0.0843\n",
      "Epoch 54/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0710 - val_loss: 0.0839\n",
      "Epoch 55/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0716 - val_loss: 0.0831\n",
      "Epoch 56/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0707 - val_loss: 0.0843\n",
      "Epoch 57/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0701 - val_loss: 0.0834\n",
      "Epoch 58/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0699 - val_loss: 0.0833\n",
      "Epoch 59/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0707 - val_loss: 0.0846\n",
      "Epoch 60/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0696 - val_loss: 0.0862\n",
      "Epoch 61/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0698 - val_loss: 0.0841\n",
      "Epoch 62/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0698 - val_loss: 0.0845\n",
      "Epoch 63/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0697 - val_loss: 0.0824\n",
      "Epoch 64/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0691 - val_loss: 0.0828\n",
      "Epoch 65/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0697 - val_loss: 0.0835\n",
      "Epoch 66/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0691 - val_loss: 0.0829\n",
      "Epoch 67/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0686 - val_loss: 0.0835\n",
      "Epoch 68/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0686 - val_loss: 0.0837\n",
      "Epoch 69/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0681 - val_loss: 0.0835\n",
      "Epoch 70/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0687 - val_loss: 0.0846\n",
      "Epoch 71/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0685 - val_loss: 0.0830\n",
      "Epoch 72/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0692 - val_loss: 0.0834\n",
      "Epoch 73/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0677 - val_loss: 0.0831\n",
      "Epoch 00073: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 3.0610 - val_loss: 0.4652\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.2824 - val_loss: 0.1085\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.0892 - val_loss: 0.0782\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0716 - val_loss: 0.0663\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0631 - val_loss: 0.0583\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0543 - val_loss: 0.0511\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0500 - val_loss: 0.0464\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0465 - val_loss: 0.0433\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.0417 - val_loss: 0.0407\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 899us/step - loss: 0.0399 - val_loss: 0.0390\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 893us/step - loss: 0.0368 - val_loss: 0.0394\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0350 - val_loss: 0.0371\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0336 - val_loss: 0.0356\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0319 - val_loss: 0.0342\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 965us/step - loss: 0.0302 - val_loss: 0.0345\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0295 - val_loss: 0.0331\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0285 - val_loss: 0.0330\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0282 - val_loss: 0.0310\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0264 - val_loss: 0.0309\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0260 - val_loss: 0.0299\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0255 - val_loss: 0.0286\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0244 - val_loss: 0.0286\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 914us/step - loss: 0.0239 - val_loss: 0.0286\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0233 - val_loss: 0.0273\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0230 - val_loss: 0.0269\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0224 - val_loss: 0.0271\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.0225 - val_loss: 0.0268\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0216 - val_loss: 0.0252\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0212 - val_loss: 0.0261\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0206 - val_loss: 0.0260\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0202 - val_loss: 0.0268\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0201 - val_loss: 0.0248\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0200 - val_loss: 0.0242\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0192 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.0192 - val_loss: 0.0237\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.0189 - val_loss: 0.0238\n",
      "Epoch 38/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0188 - val_loss: 0.0242\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0186 - val_loss: 0.0232\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0182 - val_loss: 0.0231\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 42/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.0181 - val_loss: 0.0225\n",
      "Epoch 43/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0176 - val_loss: 0.0243\n",
      "Epoch 44/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0176 - val_loss: 0.0224\n",
      "Epoch 45/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0176 - val_loss: 0.0223\n",
      "Epoch 46/200\n",
      "377/377 [==============================] - 0s 886us/step - loss: 0.0173 - val_loss: 0.0222\n",
      "Epoch 47/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0173 - val_loss: 0.0224\n",
      "Epoch 48/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0170 - val_loss: 0.0213\n",
      "Epoch 49/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0170 - val_loss: 0.0221\n",
      "Epoch 50/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0168 - val_loss: 0.0225\n",
      "Epoch 51/200\n",
      "377/377 [==============================] - 0s 889us/step - loss: 0.0171 - val_loss: 0.0237\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 893us/step - loss: 0.0166 - val_loss: 0.0213\n",
      "Epoch 53/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0204\n",
      "Epoch 54/200\n",
      "377/377 [==============================] - 0s 964us/step - loss: 0.0163 - val_loss: 0.0209\n",
      "Epoch 55/200\n",
      "377/377 [==============================] - 0s 980us/step - loss: 0.0162 - val_loss: 0.0207\n",
      "Epoch 56/200\n",
      "377/377 [==============================] - 0s 893us/step - loss: 0.0161 - val_loss: 0.0215\n",
      "Epoch 57/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0161 - val_loss: 0.0221\n",
      "Epoch 58/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0160 - val_loss: 0.0217\n",
      "Epoch 59/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0159 - val_loss: 0.0226\n",
      "Epoch 60/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0159 - val_loss: 0.0220\n",
      "Epoch 61/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0156 - val_loss: 0.0213\n",
      "Epoch 62/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0157 - val_loss: 0.0213\n",
      "Epoch 63/200\n",
      "377/377 [==============================] - 0s 893us/step - loss: 0.0156 - val_loss: 0.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00063: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 15.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [02:06<06:20, 126.97s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.0479 - val_loss: 0.0308\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0288 - val_loss: 0.0264\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0254 - val_loss: 0.0238\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0234 - val_loss: 0.0237\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0232 - val_loss: 0.0216\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.0203 - val_loss: 0.0198\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0192 - val_loss: 0.0203\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0193 - val_loss: 0.0189\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 928us/step - loss: 0.0187 - val_loss: 0.0189\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0179 - val_loss: 0.0189\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0170 - val_loss: 0.0197\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0182\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0167 - val_loss: 0.0194\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0164 - val_loss: 0.0200\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.0168 - val_loss: 0.0191\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0165 - val_loss: 0.0191\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0169 - val_loss: 0.0179\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0163 - val_loss: 0.0190\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0165 - val_loss: 0.0191\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 999us/step - loss: 0.0163 - val_loss: 0.0190\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0159 - val_loss: 0.0188\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 896us/step - loss: 0.0161 - val_loss: 0.0215\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0159 - val_loss: 0.0202\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0161 - val_loss: 0.0186\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0158 - val_loss: 0.0194\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 900us/step - loss: 0.0156 - val_loss: 0.0189\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0155 - val_loss: 0.0210\n",
      "Epoch 00036: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.2473 - val_loss: 0.1167\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.1134 - val_loss: 0.1011\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0973 - val_loss: 0.0906\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.0866 - val_loss: 0.0906\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.0858 - val_loss: 0.0871\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0836 - val_loss: 0.0900\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.0816 - val_loss: 0.0863\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0816 - val_loss: 0.0820\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0814 - val_loss: 0.0933\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0783 - val_loss: 0.0871\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.0782 - val_loss: 0.0845\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0783 - val_loss: 0.0859\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 900us/step - loss: 0.0776 - val_loss: 0.0801\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.0782 - val_loss: 0.0821\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0766 - val_loss: 0.0777\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.0753 - val_loss: 0.0849\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.0762 - val_loss: 0.0841\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0733 - val_loss: 0.0810\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.0722 - val_loss: 0.0858\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0723 - val_loss: 0.0784\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0715 - val_loss: 0.0795\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 944us/step - loss: 0.0718 - val_loss: 0.0815\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.0738 - val_loss: 0.0789\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0719 - val_loss: 0.0820\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0703 - val_loss: 0.0770\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.0712 - val_loss: 0.0788\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0703 - val_loss: 0.0798\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0712 - val_loss: 0.0807\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0693 - val_loss: 0.0786\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0675 - val_loss: 0.0782\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0685 - val_loss: 0.0808\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0690 - val_loss: 0.0779\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 897us/step - loss: 0.0683 - val_loss: 0.0794\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0683 - val_loss: 0.0779\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0667 - val_loss: 0.0808\n",
      "Epoch 00036: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.5884 - val_loss: 0.2034\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1858\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1557 - val_loss: 0.1467\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.1477 - val_loss: 0.1449\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 921us/step - loss: 0.1395 - val_loss: 0.1470\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.1393 - val_loss: 0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.1329 - val_loss: 0.1355\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.1329 - val_loss: 0.1405\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.1320 - val_loss: 0.1362\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.1279 - val_loss: 0.1348\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1286 - val_loss: 0.1374\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.1261 - val_loss: 0.1418\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.1242 - val_loss: 0.1321\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 932us/step - loss: 0.1226 - val_loss: 0.1325\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.1226 - val_loss: 0.1303\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.1225 - val_loss: 0.1267\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.1208 - val_loss: 0.1324\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.1200 - val_loss: 0.1310\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.1199 - val_loss: 0.1277\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.1170 - val_loss: 0.1263\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.1195 - val_loss: 0.1274\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.1202 - val_loss: 0.1326\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.1199 - val_loss: 0.1311\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1161 - val_loss: 0.1252\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.1170 - val_loss: 0.1272\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1144 - val_loss: 0.1294\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.1149 - val_loss: 0.1299\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.1113 - val_loss: 0.1328\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.1126 - val_loss: 0.1290\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 898us/step - loss: 0.1119 - val_loss: 0.1351\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.1098 - val_loss: 0.1319\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1106 - val_loss: 0.1301\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.1104 - val_loss: 0.1270\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.1090 - val_loss: 0.1283\n",
      "Epoch 00034: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.7776 - val_loss: 0.1492\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.1289 - val_loss: 0.1097\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.1052 - val_loss: 0.1075\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0954 - val_loss: 0.0927\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0908 - val_loss: 0.0897\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0861 - val_loss: 0.0889\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0861 - val_loss: 0.0886\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0848 - val_loss: 0.0869\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0806 - val_loss: 0.0848\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.0801 - val_loss: 0.0864\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0796 - val_loss: 0.0804\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0786 - val_loss: 0.0900\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0804 - val_loss: 0.0820\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0774 - val_loss: 0.0837\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0769 - val_loss: 0.0852\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.0770 - val_loss: 0.0811\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0741 - val_loss: 0.0859\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0749 - val_loss: 0.0783\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0736 - val_loss: 0.0787\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 966us/step - loss: 0.0737 - val_loss: 0.0812\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0733 - val_loss: 0.0844\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0719 - val_loss: 0.0815\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0706 - val_loss: 0.0817\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0729 - val_loss: 0.0824\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0707 - val_loss: 0.0758\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.0704 - val_loss: 0.0895\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0684 - val_loss: 0.0783\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 899us/step - loss: 0.0681 - val_loss: 0.0789\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 945us/step - loss: 0.0683 - val_loss: 0.0806\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0680 - val_loss: 0.0793\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.0668 - val_loss: 0.0805\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 920us/step - loss: 0.0682 - val_loss: 0.0765\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0691 - val_loss: 0.0817\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0668 - val_loss: 0.0842\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 964us/step - loss: 0.0682 - val_loss: 0.0786\n",
      "Epoch 00035: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.8372 - val_loss: 0.0471\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 957us/step - loss: 0.0413 - val_loss: 0.0374\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0327 - val_loss: 0.0371\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0292 - val_loss: 0.0298\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0264 - val_loss: 0.0301\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0224 - val_loss: 0.0254\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 894us/step - loss: 0.0217 - val_loss: 0.0239\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0207 - val_loss: 0.0245\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.0196 - val_loss: 0.0214\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 894us/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0195 - val_loss: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 941us/step - loss: 0.0201 - val_loss: 0.0212\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.0185 - val_loss: 0.0208\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0186 - val_loss: 0.0230\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.0183 - val_loss: 0.0202\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 925us/step - loss: 0.0182 - val_loss: 0.0210\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 847us/step - loss: 0.0184 - val_loss: 0.0196\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.0179 - val_loss: 0.0194\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 886us/step - loss: 0.0177 - val_loss: 0.0249\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 844us/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 870us/step - loss: 0.0174 - val_loss: 0.0210\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0186\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.0172 - val_loss: 0.0202\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0169 - val_loss: 0.0214\n",
      "Epoch 31/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0176 - val_loss: 0.0179\n",
      "Epoch 32/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0167 - val_loss: 0.0194\n",
      "Epoch 33/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0170 - val_loss: 0.0198\n",
      "Epoch 34/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 35/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 36/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.0163 - val_loss: 0.0189\n",
      "Epoch 37/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0166 - val_loss: 0.0267\n",
      "Epoch 38/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0165 - val_loss: 0.0201\n",
      "Epoch 39/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 40/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0162 - val_loss: 0.0195\n",
      "Epoch 41/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0166 - val_loss: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00041: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 17.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [03:18<03:40, 110.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.0617 - val_loss: 0.0279\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 842us/step - loss: 0.0310 - val_loss: 0.0243\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 845us/step - loss: 0.0268 - val_loss: 0.0268\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.0248 - val_loss: 0.0252\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.0232 - val_loss: 0.0215\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.0241 - val_loss: 0.0214\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 841us/step - loss: 0.0229 - val_loss: 0.0189\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.0217 - val_loss: 0.0200\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0218 - val_loss: 0.0231\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 851us/step - loss: 0.0234 - val_loss: 0.0254\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.0235 - val_loss: 0.0278\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0242 - val_loss: 0.0190\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.0227 - val_loss: 0.0278\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.0234 - val_loss: 0.0220\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.0220 - val_loss: 0.0206\n",
      "Epoch 00017: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.2105 - val_loss: 0.0967\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.1007 - val_loss: 0.1023\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.1006 - val_loss: 0.0913\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.0965 - val_loss: 0.0962\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 917us/step - loss: 0.0923 - val_loss: 0.0968\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.0922 - val_loss: 0.0820\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.0870 - val_loss: 0.0900\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0907 - val_loss: 0.0853\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 901us/step - loss: 0.0889 - val_loss: 0.0901\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0916 - val_loss: 0.0911\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0910 - val_loss: 0.0824\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0880 - val_loss: 0.0804\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 0.0864 - val_loss: 0.0819\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.0886 - val_loss: 0.0824\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0864 - val_loss: 0.0848\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0884 - val_loss: 0.0818\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.0865 - val_loss: 0.0829\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.0844 - val_loss: 0.0897\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.0868 - val_loss: 0.0827\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 862us/step - loss: 0.0866 - val_loss: 0.0918\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.0862 - val_loss: 0.0869\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.0877 - val_loss: 0.0808\n",
      "Epoch 00022: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.3661 - val_loss: 0.1564\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 857us/step - loss: 0.1648 - val_loss: 0.1614\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.1581 - val_loss: 0.1428\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.1550 - val_loss: 0.1469\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.1541 - val_loss: 0.1733\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.1515 - val_loss: 0.1373\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.1444 - val_loss: 0.1414\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.1420 - val_loss: 0.1421\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.1458 - val_loss: 0.1452\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.1435 - val_loss: 0.1344\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.1419 - val_loss: 0.1349\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.1411 - val_loss: 0.1361\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.1393 - val_loss: 0.1357\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.1397 - val_loss: 0.1351\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.1378 - val_loss: 0.1309\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.1390 - val_loss: 0.1376\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.1383 - val_loss: 0.1448\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1389 - val_loss: 0.1296\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.1351 - val_loss: 0.1348\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.1383 - val_loss: 0.1271\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.1368 - val_loss: 0.1297\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 879us/step - loss: 0.1386 - val_loss: 0.1507\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 858us/step - loss: 0.1410 - val_loss: 0.1295\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.1334 - val_loss: 0.1351\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.1357 - val_loss: 0.1295\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 976us/step - loss: 0.1349 - val_loss: 0.1571\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.1368 - val_loss: 0.1318\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 931us/step - loss: 0.1342 - val_loss: 0.1367\n",
      "Epoch 29/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.1383 - val_loss: 0.1388\n",
      "Epoch 30/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.1337 - val_loss: 0.1289\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.3830 - val_loss: 0.1325\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 882us/step - loss: 0.1139 - val_loss: 0.0982\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 867us/step - loss: 0.1013 - val_loss: 0.0934\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0996 - val_loss: 0.0900\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 892us/step - loss: 0.0957 - val_loss: 0.0876\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 886us/step - loss: 0.0918 - val_loss: 0.0881\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0898 - val_loss: 0.0873\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 889us/step - loss: 0.0889 - val_loss: 0.0815\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 888us/step - loss: 0.0891 - val_loss: 0.0900\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.0877 - val_loss: 0.0974\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.0890 - val_loss: 0.1021\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.0875 - val_loss: 0.0828\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.0852 - val_loss: 0.0916\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 869us/step - loss: 0.0863 - val_loss: 0.0806\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.0863 - val_loss: 0.0872\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0853 - val_loss: 0.0884\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0851 - val_loss: 0.0867\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.0851 - val_loss: 0.0836\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.0837 - val_loss: 0.0816\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 848us/step - loss: 0.0837 - val_loss: 0.0925\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 856us/step - loss: 0.0853 - val_loss: 0.0967\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0833 - val_loss: 0.0880\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0833 - val_loss: 0.0840\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0825 - val_loss: 0.0829\n",
      "Epoch 00024: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.2569 - val_loss: 0.0393\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 875us/step - loss: 0.0391 - val_loss: 0.0276\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 861us/step - loss: 0.0348 - val_loss: 0.0270\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 851us/step - loss: 0.0307 - val_loss: 0.0252\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.0301 - val_loss: 0.0356\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0300 - val_loss: 0.0239\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 0.0237 - val_loss: 0.0241\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.0220 - val_loss: 0.0206\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 984us/step - loss: 0.0225 - val_loss: 0.0226\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 898us/step - loss: 0.0222 - val_loss: 0.0218\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.0224 - val_loss: 0.0217\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 907us/step - loss: 0.0206 - val_loss: 0.0199\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 995us/step - loss: 0.0208 - val_loss: 0.0238\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0239\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0214\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0213\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.0194 - val_loss: 0.0191\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0204\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.0218 - val_loss: 0.0241\n",
      "Epoch 22/200\n",
      "377/377 [==============================] - 0s 960us/step - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 23/200\n",
      "377/377 [==============================] - 0s 971us/step - loss: 0.0212 - val_loss: 0.0196\n",
      "Epoch 24/200\n",
      "377/377 [==============================] - 0s 928us/step - loss: 0.0202 - val_loss: 0.0202\n",
      "Epoch 25/200\n",
      "377/377 [==============================] - 0s 952us/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 26/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 27/200\n",
      "377/377 [==============================] - 0s 904us/step - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 28/200\n",
      "377/377 [==============================] - 0s 931us/step - loss: 0.0202 - val_loss: 0.0220\n",
      "Epoch 00028: early stopping"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [04:09<01:32, 92.45s/it] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.6631 - val_loss: 0.2704\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 891us/step - loss: 10.9201 - val_loss: 0.5241\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.5823 - val_loss: 0.2026\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.1934 - val_loss: 0.1009\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.1404 - val_loss: 0.2831\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.3003 - val_loss: 0.2993\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 922us/step - loss: 0.3240 - val_loss: 0.1068\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.0960 - val_loss: 0.0479\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 876us/step - loss: 0.0484 - val_loss: 0.0479\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 9.9181 - val_loss: 9.4102\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 4.8496 - val_loss: 0.8569\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 1.6932 - val_loss: 9.0620\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 878us/step - loss: 7.1843 - val_loss: 1.6430\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.6579 - val_loss: 0.1283\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 888us/step - loss: 0.1987 - val_loss: 0.2374\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.1793 - val_loss: 0.0752\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1111 - val_loss: 3.7219\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 874us/step - loss: 14.2294 - val_loss: 2.0626\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 3.2935 - val_loss: 0.5485\n",
      "Epoch 00019: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.9025 - val_loss: 0.1153\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 851us/step - loss: 0.1527 - val_loss: 0.2778\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 3.8910 - val_loss: 1.3470\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 844us/step - loss: 0.5013 - val_loss: 0.2891\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 842us/step - loss: 0.2189 - val_loss: 0.1298\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 885us/step - loss: 0.1840 - val_loss: 0.1474\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 846us/step - loss: 0.1897 - val_loss: 0.2029\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.2314 - val_loss: 0.1263\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.1836 - val_loss: 0.1040\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.1310 - val_loss: 0.1168\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 855us/step - loss: 0.1236 - val_loss: 0.1256\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 891us/step - loss: 0.1367 - val_loss: 0.1261\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.2701 - val_loss: 30.9349\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 27.9091 - val_loss: 0.5742\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 852us/step - loss: 0.4300 - val_loss: 0.2060\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.2515 - val_loss: 0.2228\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.1838 - val_loss: 0.1443\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 890us/step - loss: 0.2723 - val_loss: 1.3811\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.7481 - val_loss: 0.2490\n",
      "Epoch 00019: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.7099 - val_loss: 0.2455\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.5886 - val_loss: 1.5160\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 849us/step - loss: 0.6103 - val_loss: 0.2013\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 0.1926 - val_loss: 0.1698\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 859us/step - loss: 0.2171 - val_loss: 0.2817\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.2142 - val_loss: 0.1874\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 916us/step - loss: 0.2107 - val_loss: 0.1874\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 3.5638 - val_loss: 0.4427\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 887us/step - loss: 0.4775 - val_loss: 0.2677\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.2134 - val_loss: 0.4510\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 864us/step - loss: 0.2358 - val_loss: 0.1519\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.2215 - val_loss: 0.1763\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 873us/step - loss: 0.2441 - val_loss: 0.2331\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 883us/step - loss: 0.2498 - val_loss: 0.2238\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 962us/step - loss: 0.2353 - val_loss: 0.1743\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 877us/step - loss: 0.2194 - val_loss: 0.2007\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.2060 - val_loss: 0.2396\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 951us/step - loss: 0.2173 - val_loss: 0.1928\n",
      "Epoch 19/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.2303 - val_loss: 0.3239\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.2673 - val_loss: 0.3955\n",
      "Epoch 21/200\n",
      "377/377 [==============================] - 0s 884us/step - loss: 0.4198 - val_loss: 7.7164\n",
      "Epoch 00021: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.8341 - val_loss: 0.1075\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 850us/step - loss: 0.1219 - val_loss: 7.7182\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 13.8485 - val_loss: 0.3360\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 865us/step - loss: 0.2577 - val_loss: 0.2726\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 895us/step - loss: 0.1692 - val_loss: 0.1673\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 881us/step - loss: 0.3344 - val_loss: 0.4414\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 872us/step - loss: 0.3374 - val_loss: 0.1057\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 845us/step - loss: 0.1220 - val_loss: 0.1386\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 866us/step - loss: 0.1171 - val_loss: 0.2282\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.1401 - val_loss: 0.1024\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.1270 - val_loss: 0.4462\n",
      "Epoch 12/200\n",
      "377/377 [==============================] - 0s 937us/step - loss: 0.4102 - val_loss: 0.1145\n",
      "Epoch 13/200\n",
      "377/377 [==============================] - 0s 886us/step - loss: 0.1330 - val_loss: 0.1139\n",
      "Epoch 14/200\n",
      "377/377 [==============================] - 0s 871us/step - loss: 0.1107 - val_loss: 0.1125\n",
      "Epoch 15/200\n",
      "377/377 [==============================] - 0s 880us/step - loss: 0.1273 - val_loss: 0.2678\n",
      "Epoch 16/200\n",
      "377/377 [==============================] - 0s 868us/step - loss: 18.2665 - val_loss: 0.5260\n",
      "Epoch 17/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.6508 - val_loss: 0.2655\n",
      "Epoch 18/200\n",
      "377/377 [==============================] - 0s 860us/step - loss: 0.2793 - val_loss: 0.1710\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377/377 [==============================] - 0s 867us/step - loss: 0.1959 - val_loss: 0.2597\n",
      "Epoch 20/200\n",
      "377/377 [==============================] - 0s 863us/step - loss: 0.1748 - val_loss: 0.2986\n",
      "Epoch 00020: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "377/377 [==============================] - 1s 1ms/step - loss: 0.9225 - val_loss: 0.0506\n",
      "Epoch 2/200\n",
      "377/377 [==============================] - 0s 842us/step - loss: 0.0488 - val_loss: 0.0729\n",
      "Epoch 3/200\n",
      "377/377 [==============================] - 0s 847us/step - loss: 14.8296 - val_loss: 8.4387\n",
      "Epoch 4/200\n",
      "377/377 [==============================] - 0s 836us/step - loss: 3.0162 - val_loss: 1.5293\n",
      "Epoch 5/200\n",
      "377/377 [==============================] - 0s 853us/step - loss: 0.5608 - val_loss: 0.1372\n",
      "Epoch 6/200\n",
      "377/377 [==============================] - 0s 843us/step - loss: 0.2421 - val_loss: 0.1269\n",
      "Epoch 7/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 0.1877 - val_loss: 0.9829\n",
      "Epoch 8/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 1.1214 - val_loss: 1.0656\n",
      "Epoch 9/200\n",
      "377/377 [==============================] - 0s 854us/step - loss: 2.8995 - val_loss: 0.2035\n",
      "Epoch 10/200\n",
      "377/377 [==============================] - 1s 2ms/step - loss: 0.2346 - val_loss: 0.1426\n",
      "Epoch 11/200\n",
      "377/377 [==============================] - 0s 1ms/step - loss: 0.1260 - val_loss: 0.0591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 17.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [04:48<00:00, 72.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [04:48<00:00, 288.70s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [04:48<24:03, 288.70s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 1ms/step - loss: 0.0832 - val_loss: 0.0528\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0437\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 973us/step - loss: 0.0436 - val_loss: 0.0372\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 959us/step - loss: 0.0374 - val_loss: 0.0323\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0340 - val_loss: 0.0306\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0319 - val_loss: 0.0286\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 971us/step - loss: 0.0307 - val_loss: 0.0267\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0289 - val_loss: 0.0274\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 977us/step - loss: 0.0282 - val_loss: 0.0253\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0250\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0241\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.0254 - val_loss: 0.0244\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0254 - val_loss: 0.0240\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0237\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 951us/step - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 966us/step - loss: 0.0230 - val_loss: 0.0231\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 972us/step - loss: 0.0218 - val_loss: 0.0227\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 971us/step - loss: 0.0218 - val_loss: 0.0223\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0220\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 973us/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0219\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0202 - val_loss: 0.0210\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 972us/step - loss: 0.0200 - val_loss: 0.0210\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0197 - val_loss: 0.0212\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0207\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 988us/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0201\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0202\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0198\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0200\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 973us/step - loss: 0.0185 - val_loss: 0.0196\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0193\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0195\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0179 - val_loss: 0.0192\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0191\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 46/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.0173 - val_loss: 0.0193\n",
      "Epoch 47/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0190\n",
      "Epoch 48/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0188\n",
      "Epoch 49/200\n",
      "189/189 [==============================] - 0s 988us/step - loss: 0.0174 - val_loss: 0.0188\n",
      "Epoch 50/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 51/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 52/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 53/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0189\n",
      "Epoch 54/200\n",
      "189/189 [==============================] - 0s 975us/step - loss: 0.0168 - val_loss: 0.0190\n",
      "Epoch 55/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 56/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 57/200\n",
      "189/189 [==============================] - 0s 977us/step - loss: 0.0165 - val_loss: 0.0183\n",
      "Epoch 58/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 59/200\n",
      "189/189 [==============================] - 0s 977us/step - loss: 0.0167 - val_loss: 0.0184\n",
      "Epoch 60/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0184\n",
      "Epoch 61/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0186\n",
      "Epoch 62/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0180\n",
      "Epoch 63/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0166 - val_loss: 0.0186\n",
      "Epoch 64/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0186\n",
      "Epoch 65/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0185\n",
      "Epoch 66/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 67/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0190\n",
      "Epoch 68/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0180\n",
      "Epoch 69/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0186\n",
      "Epoch 70/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0182\n",
      "Epoch 71/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 72/200\n",
      "189/189 [==============================] - 0s 970us/step - loss: 0.0159 - val_loss: 0.0185\n",
      "Epoch 73/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0181\n",
      "Epoch 74/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0190\n",
      "Epoch 75/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0181\n",
      "Epoch 76/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0182\n",
      "Epoch 77/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0182\n",
      "Epoch 78/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0181\n",
      "Epoch 00078: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.5230 - val_loss: 0.2954\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2717 - val_loss: 0.2031\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1994 - val_loss: 0.1642\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1466\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1520 - val_loss: 0.1379\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.1444 - val_loss: 0.1303\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1354 - val_loss: 0.1242\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 997us/step - loss: 0.1289 - val_loss: 0.1206\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.1240 - val_loss: 0.1163\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 977us/step - loss: 0.1215 - val_loss: 0.1143\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1172 - val_loss: 0.1110\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1125 - val_loss: 0.1104\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1085 - val_loss: 0.1074\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 998us/step - loss: 0.1066 - val_loss: 0.1068\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 975us/step - loss: 0.1049 - val_loss: 0.1034\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.1030 - val_loss: 0.1017\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 973us/step - loss: 0.1010 - val_loss: 0.1015\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.0993 - val_loss: 0.1005\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0981 - val_loss: 0.0979\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 965us/step - loss: 0.0969 - val_loss: 0.0978\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 965us/step - loss: 0.0940 - val_loss: 0.0969\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0932 - val_loss: 0.0964\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0917 - val_loss: 0.0950\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.0896 - val_loss: 0.0946\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0899 - val_loss: 0.0932\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0929\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 953us/step - loss: 0.0870 - val_loss: 0.0926\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0929\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 956us/step - loss: 0.0860 - val_loss: 0.0913\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0907\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0848 - val_loss: 0.0893\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 969us/step - loss: 0.0854 - val_loss: 0.0894\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0887\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0889\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0819 - val_loss: 0.0877\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0876\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0815 - val_loss: 0.0879\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0872\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0810 - val_loss: 0.0870\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0805 - val_loss: 0.0860\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0800 - val_loss: 0.0864\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0790 - val_loss: 0.0857\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 981us/step - loss: 0.0796 - val_loss: 0.0864\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0847\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0785 - val_loss: 0.0858\n",
      "Epoch 46/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0841\n",
      "Epoch 47/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0769 - val_loss: 0.0847\n",
      "Epoch 48/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.0778 - val_loss: 0.0848\n",
      "Epoch 49/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0786 - val_loss: 0.0838\n",
      "Epoch 50/200\n",
      "189/189 [==============================] - 0s 983us/step - loss: 0.0771 - val_loss: 0.0852\n",
      "Epoch 51/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0758 - val_loss: 0.0858\n",
      "Epoch 52/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0842\n",
      "Epoch 53/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0853\n",
      "Epoch 54/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0760 - val_loss: 0.0841\n",
      "Epoch 55/200\n",
      "189/189 [==============================] - 0s 988us/step - loss: 0.0763 - val_loss: 0.0846\n",
      "Epoch 56/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0755 - val_loss: 0.0836\n",
      "Epoch 57/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0839\n",
      "Epoch 58/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0756 - val_loss: 0.0832\n",
      "Epoch 59/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0838\n",
      "Epoch 60/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0733 - val_loss: 0.0836\n",
      "Epoch 61/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.0746 - val_loss: 0.0839\n",
      "Epoch 62/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0745 - val_loss: 0.0834\n",
      "Epoch 63/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0736 - val_loss: 0.0836\n",
      "Epoch 64/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.0726 - val_loss: 0.0841\n",
      "Epoch 65/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0737 - val_loss: 0.0841\n",
      "Epoch 66/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0729 - val_loss: 0.0822\n",
      "Epoch 67/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0830\n",
      "Epoch 68/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0840\n",
      "Epoch 69/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0828\n",
      "Epoch 70/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0728 - val_loss: 0.0831\n",
      "Epoch 71/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0727 - val_loss: 0.0827\n",
      "Epoch 72/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0720 - val_loss: 0.0828\n",
      "Epoch 73/200\n",
      "189/189 [==============================] - 0s 983us/step - loss: 0.0722 - val_loss: 0.0832\n",
      "Epoch 74/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0828\n",
      "Epoch 75/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0715 - val_loss: 0.0835\n",
      "Epoch 76/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0834\n",
      "Epoch 00076: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.6866 - val_loss: 0.7470\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.6360 - val_loss: 0.4364\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.4137 - val_loss: 0.3467\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.2998\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2998 - val_loss: 0.2754\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 984us/step - loss: 0.2763 - val_loss: 0.2564\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 966us/step - loss: 0.2567 - val_loss: 0.2422\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2404 - val_loss: 0.2316\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2291 - val_loss: 0.2218\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 962us/step - loss: 0.2182 - val_loss: 0.2139\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2105 - val_loss: 0.2048\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2000 - val_loss: 0.1982\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1922\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.1872\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1831 - val_loss: 0.1806\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1777\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1745\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 989us/step - loss: 0.1715 - val_loss: 0.1676\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1649 - val_loss: 0.1666\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1665 - val_loss: 0.1632\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1607 - val_loss: 0.1592\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1573 - val_loss: 0.1598\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1542 - val_loss: 0.1565\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1552 - val_loss: 0.1559\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1514 - val_loss: 0.1558\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1509 - val_loss: 0.1520\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1479 - val_loss: 0.1514\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1468 - val_loss: 0.1493\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1454 - val_loss: 0.1500\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1441 - val_loss: 0.1491\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 967us/step - loss: 0.1411 - val_loss: 0.1472\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.1407 - val_loss: 0.1450\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1399 - val_loss: 0.1458\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 996us/step - loss: 0.1393 - val_loss: 0.1446\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1385 - val_loss: 0.1441\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1384 - val_loss: 0.1430\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1361 - val_loss: 0.1422\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1420\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1360 - val_loss: 0.1415\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.1338 - val_loss: 0.1404\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1331 - val_loss: 0.1418\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.1332 - val_loss: 0.1404\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 982us/step - loss: 0.1323 - val_loss: 0.1384\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1318 - val_loss: 0.1394\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 975us/step - loss: 0.1316 - val_loss: 0.1383\n",
      "Epoch 46/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1300 - val_loss: 0.1389\n",
      "Epoch 47/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1292 - val_loss: 0.1392\n",
      "Epoch 48/200\n",
      "189/189 [==============================] - 0s 959us/step - loss: 0.1292 - val_loss: 0.1373\n",
      "Epoch 49/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1299 - val_loss: 0.1379\n",
      "Epoch 50/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1301 - val_loss: 0.1368\n",
      "Epoch 51/200\n",
      "189/189 [==============================] - 0s 973us/step - loss: 0.1290 - val_loss: 0.1362\n",
      "Epoch 52/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.1290 - val_loss: 0.1362\n",
      "Epoch 53/200\n",
      "189/189 [==============================] - 0s 970us/step - loss: 0.1292 - val_loss: 0.1362\n",
      "Epoch 54/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1265 - val_loss: 0.1360\n",
      "Epoch 55/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1254 - val_loss: 0.1352\n",
      "Epoch 56/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1247 - val_loss: 0.1347\n",
      "Epoch 57/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1258 - val_loss: 0.1363\n",
      "Epoch 58/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1256 - val_loss: 0.1348\n",
      "Epoch 59/200\n",
      "189/189 [==============================] - 0s 995us/step - loss: 0.1251 - val_loss: 0.1336\n",
      "Epoch 60/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1262 - val_loss: 0.1345\n",
      "Epoch 61/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1256 - val_loss: 0.1339\n",
      "Epoch 62/200\n",
      "189/189 [==============================] - 0s 976us/step - loss: 0.1240 - val_loss: 0.1349\n",
      "Epoch 63/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1235 - val_loss: 0.1338\n",
      "Epoch 64/200\n",
      "189/189 [==============================] - 0s 949us/step - loss: 0.1257 - val_loss: 0.1356\n",
      "Epoch 65/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.1333\n",
      "Epoch 66/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1331\n",
      "Epoch 67/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1212 - val_loss: 0.1339\n",
      "Epoch 68/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1248 - val_loss: 0.1340\n",
      "Epoch 69/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1228 - val_loss: 0.1343\n",
      "Epoch 70/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1224 - val_loss: 0.1326\n",
      "Epoch 71/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1217 - val_loss: 0.1327\n",
      "Epoch 72/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.1225 - val_loss: 0.1329\n",
      "Epoch 73/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1213 - val_loss: 0.1324\n",
      "Epoch 74/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1201 - val_loss: 0.1333\n",
      "Epoch 75/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.1196 - val_loss: 0.1341\n",
      "Epoch 76/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1327\n",
      "Epoch 77/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1220 - val_loss: 0.1324\n",
      "Epoch 78/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1198 - val_loss: 0.1320\n",
      "Epoch 79/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1183 - val_loss: 0.1342\n",
      "Epoch 80/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1194 - val_loss: 0.1327\n",
      "Epoch 81/200\n",
      "189/189 [==============================] - 0s 987us/step - loss: 0.1200 - val_loss: 0.1326\n",
      "Epoch 82/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1183 - val_loss: 0.1329\n",
      "Epoch 83/200\n",
      "189/189 [==============================] - 0s 972us/step - loss: 0.1205 - val_loss: 0.1319\n",
      "Epoch 84/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1173 - val_loss: 0.1337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1191 - val_loss: 0.1320\n",
      "Epoch 86/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.1323\n",
      "Epoch 87/200\n",
      "189/189 [==============================] - 0s 962us/step - loss: 0.1182 - val_loss: 0.1319\n",
      "Epoch 88/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1171 - val_loss: 0.1316\n",
      "Epoch 89/200\n",
      "189/189 [==============================] - 0s 961us/step - loss: 0.1174 - val_loss: 0.1307\n",
      "Epoch 90/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.1183 - val_loss: 0.1314\n",
      "Epoch 91/200\n",
      "189/189 [==============================] - 0s 955us/step - loss: 0.1153 - val_loss: 0.1309\n",
      "Epoch 92/200\n",
      "189/189 [==============================] - 0s 966us/step - loss: 0.1167 - val_loss: 0.1307\n",
      "Epoch 93/200\n",
      "189/189 [==============================] - 0s 967us/step - loss: 0.1185 - val_loss: 0.1303\n",
      "Epoch 94/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.1304\n",
      "Epoch 95/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1174 - val_loss: 0.1327\n",
      "Epoch 96/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1169 - val_loss: 0.1310\n",
      "Epoch 97/200\n",
      "189/189 [==============================] - 0s 974us/step - loss: 0.1154 - val_loss: 0.1311\n",
      "Epoch 98/200\n",
      "189/189 [==============================] - 0s 971us/step - loss: 0.1156 - val_loss: 0.1315\n",
      "Epoch 99/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1148 - val_loss: 0.1308\n",
      "Epoch 100/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1139 - val_loss: 0.1303\n",
      "Epoch 101/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.1313\n",
      "Epoch 102/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1152 - val_loss: 0.1317\n",
      "Epoch 103/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1307\n",
      "Epoch 104/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1148 - val_loss: 0.1310\n",
      "Epoch 105/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1137 - val_loss: 0.1304\n",
      "Epoch 106/200\n",
      "189/189 [==============================] - 0s 963us/step - loss: 0.1151 - val_loss: 0.1306\n",
      "Epoch 107/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1135 - val_loss: 0.1307\n",
      "Epoch 108/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1144 - val_loss: 0.1308\n",
      "Epoch 109/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1143 - val_loss: 0.1307\n",
      "Epoch 110/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1130 - val_loss: 0.1294\n",
      "Epoch 111/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1112 - val_loss: 0.1315\n",
      "Epoch 112/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1304\n",
      "Epoch 113/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1119 - val_loss: 0.1322\n",
      "Epoch 114/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.1132 - val_loss: 0.1300\n",
      "Epoch 115/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1133 - val_loss: 0.1306\n",
      "Epoch 116/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1129 - val_loss: 0.1305\n",
      "Epoch 117/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1130 - val_loss: 0.1291\n",
      "Epoch 118/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1116 - val_loss: 0.1297\n",
      "Epoch 119/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1132 - val_loss: 0.1315\n",
      "Epoch 120/200\n",
      "189/189 [==============================] - 0s 980us/step - loss: 0.1125 - val_loss: 0.1311\n",
      "Epoch 121/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1121 - val_loss: 0.1305\n",
      "Epoch 122/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1128 - val_loss: 0.1295\n",
      "Epoch 123/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1114 - val_loss: 0.1307\n",
      "Epoch 124/200\n",
      "189/189 [==============================] - 0s 954us/step - loss: 0.1115 - val_loss: 0.1311\n",
      "Epoch 125/200\n",
      "189/189 [==============================] - 0s 972us/step - loss: 0.1090 - val_loss: 0.1303\n",
      "Epoch 126/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1099 - val_loss: 0.1292\n",
      "Epoch 127/200\n",
      "189/189 [==============================] - 0s 954us/step - loss: 0.1114 - val_loss: 0.1303\n",
      "Epoch 00127: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 1ms/step - loss: 2.3682 - val_loss: 0.7787\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.3368\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.2720\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.2310\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2246 - val_loss: 0.2027\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 962us/step - loss: 0.2007 - val_loss: 0.1856\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 969us/step - loss: 0.1840 - val_loss: 0.1755\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1689\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 983us/step - loss: 0.1623 - val_loss: 0.1613\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1570 - val_loss: 0.1555\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 947us/step - loss: 0.1503 - val_loss: 0.1511\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1000us/step - loss: 0.1456 - val_loss: 0.1465\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 960us/step - loss: 0.1413 - val_loss: 0.1435\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 967us/step - loss: 0.1338 - val_loss: 0.1399\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1327 - val_loss: 0.1346\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1299 - val_loss: 0.1313\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 966us/step - loss: 0.1230 - val_loss: 0.1294\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1204 - val_loss: 0.1247\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.1168 - val_loss: 0.1231\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 977us/step - loss: 0.1119 - val_loss: 0.1208\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1107 - val_loss: 0.1169\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 957us/step - loss: 0.1076 - val_loss: 0.1162\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1045 - val_loss: 0.1148\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1029 - val_loss: 0.1110\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.1102\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 969us/step - loss: 0.0986 - val_loss: 0.1074\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 983us/step - loss: 0.0959 - val_loss: 0.1074\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0943 - val_loss: 0.1070\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0927 - val_loss: 0.1044\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.1033\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0920 - val_loss: 0.1013\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 987us/step - loss: 0.0906 - val_loss: 0.0991\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0893 - val_loss: 0.0991\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0890 - val_loss: 0.0986\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 998us/step - loss: 0.0864 - val_loss: 0.0972\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0864 - val_loss: 0.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 957us/step - loss: 0.0858 - val_loss: 0.0946\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 974us/step - loss: 0.0850 - val_loss: 0.0937\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0941\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 954us/step - loss: 0.0833 - val_loss: 0.0920\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0913\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0817 - val_loss: 0.0922\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 962us/step - loss: 0.0806 - val_loss: 0.0906\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0806 - val_loss: 0.0907\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.0796 - val_loss: 0.0908\n",
      "Epoch 46/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0808 - val_loss: 0.0893\n",
      "Epoch 47/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0796 - val_loss: 0.0896\n",
      "Epoch 48/200\n",
      "189/189 [==============================] - 0s 965us/step - loss: 0.0791 - val_loss: 0.0885\n",
      "Epoch 49/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0788 - val_loss: 0.0883\n",
      "Epoch 50/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.0780 - val_loss: 0.0882\n",
      "Epoch 51/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0767 - val_loss: 0.0881\n",
      "Epoch 52/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0780 - val_loss: 0.0866\n",
      "Epoch 53/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0761 - val_loss: 0.0869\n",
      "Epoch 54/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0754 - val_loss: 0.0870\n",
      "Epoch 55/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0768 - val_loss: 0.0882\n",
      "Epoch 56/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0868\n",
      "Epoch 57/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0757 - val_loss: 0.0880\n",
      "Epoch 58/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0762 - val_loss: 0.0856\n",
      "Epoch 59/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0748 - val_loss: 0.0855\n",
      "Epoch 60/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0846\n",
      "Epoch 61/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0856\n",
      "Epoch 62/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0848\n",
      "Epoch 63/200\n",
      "189/189 [==============================] - 0s 972us/step - loss: 0.0737 - val_loss: 0.0872\n",
      "Epoch 64/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0859\n",
      "Epoch 65/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0743 - val_loss: 0.0869\n",
      "Epoch 66/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0857\n",
      "Epoch 67/200\n",
      "189/189 [==============================] - 0s 998us/step - loss: 0.0726 - val_loss: 0.0850\n",
      "Epoch 68/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0837\n",
      "Epoch 69/200\n",
      "189/189 [==============================] - 0s 965us/step - loss: 0.0722 - val_loss: 0.0842\n",
      "Epoch 70/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0725 - val_loss: 0.0845\n",
      "Epoch 71/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0717 - val_loss: 0.0836\n",
      "Epoch 72/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0710 - val_loss: 0.0833\n",
      "Epoch 73/200\n",
      "189/189 [==============================] - 0s 974us/step - loss: 0.0715 - val_loss: 0.0833\n",
      "Epoch 74/200\n",
      "189/189 [==============================] - 0s 986us/step - loss: 0.0727 - val_loss: 0.0841\n",
      "Epoch 75/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0713 - val_loss: 0.0840\n",
      "Epoch 76/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0722 - val_loss: 0.0830\n",
      "Epoch 77/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0824\n",
      "Epoch 78/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0824\n",
      "Epoch 79/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0829\n",
      "Epoch 80/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0708 - val_loss: 0.0828\n",
      "Epoch 81/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0835\n",
      "Epoch 82/200\n",
      "189/189 [==============================] - 0s 961us/step - loss: 0.0707 - val_loss: 0.0819\n",
      "Epoch 83/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0704 - val_loss: 0.0840\n",
      "Epoch 84/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0696 - val_loss: 0.0818\n",
      "Epoch 85/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0688 - val_loss: 0.0826\n",
      "Epoch 86/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0697 - val_loss: 0.0834\n",
      "Epoch 87/200\n",
      "189/189 [==============================] - 0s 961us/step - loss: 0.0692 - val_loss: 0.0827\n",
      "Epoch 88/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0691 - val_loss: 0.0825\n",
      "Epoch 89/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0684 - val_loss: 0.0819\n",
      "Epoch 90/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.0689 - val_loss: 0.0814\n",
      "Epoch 91/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0809\n",
      "Epoch 92/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0820\n",
      "Epoch 93/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0816\n",
      "Epoch 94/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0682 - val_loss: 0.0811\n",
      "Epoch 95/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0681 - val_loss: 0.0816\n",
      "Epoch 96/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.0685 - val_loss: 0.0816\n",
      "Epoch 97/200\n",
      "189/189 [==============================] - 0s 979us/step - loss: 0.0677 - val_loss: 0.0812\n",
      "Epoch 98/200\n",
      "189/189 [==============================] - 0s 980us/step - loss: 0.0676 - val_loss: 0.0836\n",
      "Epoch 99/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0673 - val_loss: 0.0809\n",
      "Epoch 100/200\n",
      "189/189 [==============================] - 0s 998us/step - loss: 0.0676 - val_loss: 0.0815\n",
      "Epoch 101/200\n",
      "189/189 [==============================] - 0s 986us/step - loss: 0.0671 - val_loss: 0.0807\n",
      "Epoch 102/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.0678 - val_loss: 0.0811\n",
      "Epoch 103/200\n",
      "189/189 [==============================] - 0s 960us/step - loss: 0.0662 - val_loss: 0.0811\n",
      "Epoch 104/200\n",
      "189/189 [==============================] - 0s 961us/step - loss: 0.0681 - val_loss: 0.0832\n",
      "Epoch 105/200\n",
      "189/189 [==============================] - 0s 980us/step - loss: 0.0667 - val_loss: 0.0802\n",
      "Epoch 106/200\n",
      "189/189 [==============================] - 0s 929us/step - loss: 0.0674 - val_loss: 0.0806\n",
      "Epoch 107/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0654 - val_loss: 0.0801\n",
      "Epoch 108/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0663 - val_loss: 0.0804\n",
      "Epoch 109/200\n",
      "189/189 [==============================] - 0s 891us/step - loss: 0.0653 - val_loss: 0.0802\n",
      "Epoch 110/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.0660 - val_loss: 0.0798\n",
      "Epoch 111/200\n",
      "189/189 [==============================] - 0s 968us/step - loss: 0.0668 - val_loss: 0.0811\n",
      "Epoch 112/200\n",
      "189/189 [==============================] - 0s 900us/step - loss: 0.0661 - val_loss: 0.0821\n",
      "Epoch 113/200\n",
      "189/189 [==============================] - 0s 894us/step - loss: 0.0661 - val_loss: 0.0814\n",
      "Epoch 114/200\n",
      "189/189 [==============================] - 0s 900us/step - loss: 0.0660 - val_loss: 0.0803\n",
      "Epoch 115/200\n",
      "189/189 [==============================] - 0s 890us/step - loss: 0.0664 - val_loss: 0.0800\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 896us/step - loss: 0.0646 - val_loss: 0.0844\n",
      "Epoch 117/200\n",
      "189/189 [==============================] - 0s 892us/step - loss: 0.0648 - val_loss: 0.0804\n",
      "Epoch 118/200\n",
      "189/189 [==============================] - 0s 896us/step - loss: 0.0666 - val_loss: 0.0814\n",
      "Epoch 119/200\n",
      "189/189 [==============================] - 0s 948us/step - loss: 0.0649 - val_loss: 0.0802\n",
      "Epoch 120/200\n",
      "189/189 [==============================] - 0s 912us/step - loss: 0.0658 - val_loss: 0.0796\n",
      "Epoch 121/200\n",
      "189/189 [==============================] - 0s 890us/step - loss: 0.0660 - val_loss: 0.0802\n",
      "Epoch 122/200\n",
      "189/189 [==============================] - 0s 895us/step - loss: 0.0660 - val_loss: 0.0822\n",
      "Epoch 123/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0661 - val_loss: 0.0804\n",
      "Epoch 124/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0656 - val_loss: 0.0803\n",
      "Epoch 125/200\n",
      "189/189 [==============================] - 0s 920us/step - loss: 0.0650 - val_loss: 0.0810\n",
      "Epoch 126/200\n",
      "189/189 [==============================] - 0s 921us/step - loss: 0.0649 - val_loss: 0.0797\n",
      "Epoch 127/200\n",
      "189/189 [==============================] - 0s 914us/step - loss: 0.0640 - val_loss: 0.0803\n",
      "Epoch 128/200\n",
      "189/189 [==============================] - 0s 913us/step - loss: 0.0652 - val_loss: 0.0796\n",
      "Epoch 129/200\n",
      "189/189 [==============================] - 0s 907us/step - loss: 0.0653 - val_loss: 0.0802\n",
      "Epoch 130/200\n",
      "189/189 [==============================] - 0s 906us/step - loss: 0.0658 - val_loss: 0.0800\n",
      "Epoch 131/200\n",
      "189/189 [==============================] - 0s 898us/step - loss: 0.0632 - val_loss: 0.0795\n",
      "Epoch 132/200\n",
      "189/189 [==============================] - 0s 889us/step - loss: 0.0640 - val_loss: 0.0797\n",
      "Epoch 133/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0640 - val_loss: 0.0800\n",
      "Epoch 134/200\n",
      "189/189 [==============================] - 0s 895us/step - loss: 0.0640 - val_loss: 0.0799\n",
      "Epoch 135/200\n",
      "189/189 [==============================] - 0s 886us/step - loss: 0.0642 - val_loss: 0.0790\n",
      "Epoch 136/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0656 - val_loss: 0.0809\n",
      "Epoch 137/200\n",
      "189/189 [==============================] - 0s 914us/step - loss: 0.0642 - val_loss: 0.0798\n",
      "Epoch 138/200\n",
      "189/189 [==============================] - 0s 955us/step - loss: 0.0628 - val_loss: 0.0799\n",
      "Epoch 139/200\n",
      "189/189 [==============================] - 0s 891us/step - loss: 0.0636 - val_loss: 0.0797\n",
      "Epoch 140/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0634 - val_loss: 0.0802\n",
      "Epoch 141/200\n",
      "189/189 [==============================] - 0s 894us/step - loss: 0.0635 - val_loss: 0.0801\n",
      "Epoch 142/200\n",
      "189/189 [==============================] - 0s 883us/step - loss: 0.0635 - val_loss: 0.0810\n",
      "Epoch 143/200\n",
      "189/189 [==============================] - 0s 888us/step - loss: 0.0638 - val_loss: 0.0803\n",
      "Epoch 144/200\n",
      "189/189 [==============================] - 0s 920us/step - loss: 0.0632 - val_loss: 0.0819\n",
      "Epoch 145/200\n",
      "189/189 [==============================] - 0s 912us/step - loss: 0.0628 - val_loss: 0.0815\n",
      "Epoch 00145: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 1ms/step - loss: 2.9653 - val_loss: 1.0535\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 978us/step - loss: 0.7203 - val_loss: 0.2104\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 987us/step - loss: 0.1653 - val_loss: 0.1053\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0990 - val_loss: 0.0876\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 962us/step - loss: 0.0831 - val_loss: 0.0793\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0763 - val_loss: 0.0730\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 967us/step - loss: 0.0689 - val_loss: 0.0676\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 963us/step - loss: 0.0649 - val_loss: 0.0628\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 946us/step - loss: 0.0597 - val_loss: 0.0583\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 930us/step - loss: 0.0553 - val_loss: 0.0545\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 924us/step - loss: 0.0514 - val_loss: 0.0518\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 909us/step - loss: 0.0489 - val_loss: 0.0495\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 916us/step - loss: 0.0466 - val_loss: 0.0472\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 921us/step - loss: 0.0440 - val_loss: 0.0455\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 907us/step - loss: 0.0423 - val_loss: 0.0444\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0398 - val_loss: 0.0433\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 899us/step - loss: 0.0385 - val_loss: 0.0426\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 921us/step - loss: 0.0370 - val_loss: 0.0419\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 917us/step - loss: 0.0361 - val_loss: 0.0408\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 920us/step - loss: 0.0346 - val_loss: 0.0409\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 931us/step - loss: 0.0341 - val_loss: 0.0395\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 912us/step - loss: 0.0325 - val_loss: 0.0386\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 919us/step - loss: 0.0319 - val_loss: 0.0373\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 918us/step - loss: 0.0311 - val_loss: 0.0371\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 898us/step - loss: 0.0298 - val_loss: 0.0361\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 896us/step - loss: 0.0291 - val_loss: 0.0355\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 929us/step - loss: 0.0285 - val_loss: 0.0359\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0284 - val_loss: 0.0343\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 900us/step - loss: 0.0272 - val_loss: 0.0338\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 919us/step - loss: 0.0268 - val_loss: 0.0341\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 919us/step - loss: 0.0266 - val_loss: 0.0326\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 931us/step - loss: 0.0257 - val_loss: 0.0312\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0254 - val_loss: 0.0312\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 893us/step - loss: 0.0256 - val_loss: 0.0320\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 899us/step - loss: 0.0245 - val_loss: 0.0303\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 900us/step - loss: 0.0240 - val_loss: 0.0305\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 895us/step - loss: 0.0234 - val_loss: 0.0296\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 898us/step - loss: 0.0228 - val_loss: 0.0286\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0228 - val_loss: 0.0287\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 893us/step - loss: 0.0226 - val_loss: 0.0284\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 908us/step - loss: 0.0224 - val_loss: 0.0280\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 896us/step - loss: 0.0222 - val_loss: 0.0281\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 901us/step - loss: 0.0218 - val_loss: 0.0273\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0214 - val_loss: 0.0280\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 893us/step - loss: 0.0209 - val_loss: 0.0271\n",
      "Epoch 46/200\n",
      "189/189 [==============================] - 0s 886us/step - loss: 0.0207 - val_loss: 0.0263\n",
      "Epoch 47/200\n",
      "189/189 [==============================] - 0s 892us/step - loss: 0.0209 - val_loss: 0.0261\n",
      "Epoch 48/200\n",
      "189/189 [==============================] - 0s 899us/step - loss: 0.0202 - val_loss: 0.0268\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 906us/step - loss: 0.0204 - val_loss: 0.0264\n",
      "Epoch 50/200\n",
      "189/189 [==============================] - 0s 893us/step - loss: 0.0203 - val_loss: 0.0256\n",
      "Epoch 51/200\n",
      "189/189 [==============================] - 0s 886us/step - loss: 0.0197 - val_loss: 0.0255\n",
      "Epoch 52/200\n",
      "189/189 [==============================] - 0s 898us/step - loss: 0.0196 - val_loss: 0.0261\n",
      "Epoch 53/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0195 - val_loss: 0.0256\n",
      "Epoch 54/200\n",
      "189/189 [==============================] - 0s 891us/step - loss: 0.0191 - val_loss: 0.0242\n",
      "Epoch 55/200\n",
      "189/189 [==============================] - 0s 891us/step - loss: 0.0194 - val_loss: 0.0255\n",
      "Epoch 56/200\n",
      "189/189 [==============================] - 0s 901us/step - loss: 0.0194 - val_loss: 0.0242\n",
      "Epoch 57/200\n",
      "189/189 [==============================] - 0s 947us/step - loss: 0.0188 - val_loss: 0.0241\n",
      "Epoch 58/200\n",
      "189/189 [==============================] - 0s 915us/step - loss: 0.0189 - val_loss: 0.0249\n",
      "Epoch 59/200\n",
      "189/189 [==============================] - 0s 903us/step - loss: 0.0184 - val_loss: 0.0246\n",
      "Epoch 60/200\n",
      "189/189 [==============================] - 0s 892us/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 61/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0245\n",
      "Epoch 62/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0183 - val_loss: 0.0243\n",
      "Epoch 63/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0245\n",
      "Epoch 64/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0180 - val_loss: 0.0243\n",
      "Epoch 65/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0242\n",
      "Epoch 66/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0177 - val_loss: 0.0247\n",
      "Epoch 67/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0178 - val_loss: 0.0236\n",
      "Epoch 68/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0230\n",
      "Epoch 69/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0239\n",
      "Epoch 70/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0226\n",
      "Epoch 71/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0236\n",
      "Epoch 72/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0236\n",
      "Epoch 73/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0173 - val_loss: 0.0235\n",
      "Epoch 74/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0240\n",
      "Epoch 75/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0225\n",
      "Epoch 76/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0165 - val_loss: 0.0229\n",
      "Epoch 77/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0231\n",
      "Epoch 78/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0233\n",
      "Epoch 79/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0223\n",
      "Epoch 80/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0225\n",
      "Epoch 81/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0235\n",
      "Epoch 82/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0230\n",
      "Epoch 83/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0225\n",
      "Epoch 84/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0221\n",
      "Epoch 85/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0223\n",
      "Epoch 86/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0220\n",
      "Epoch 87/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0160 - val_loss: 0.0219\n",
      "Epoch 88/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0224\n",
      "Epoch 89/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0157 - val_loss: 0.0219\n",
      "Epoch 90/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0217\n",
      "Epoch 91/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0214\n",
      "Epoch 92/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0219\n",
      "Epoch 93/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0216\n",
      "Epoch 94/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0220\n",
      "Epoch 95/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0220\n",
      "Epoch 96/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0158 - val_loss: 0.0221\n",
      "Epoch 97/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0223\n",
      "Epoch 98/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0220\n",
      "Epoch 99/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0214\n",
      "Epoch 100/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0208\n",
      "Epoch 101/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0153 - val_loss: 0.0218\n",
      "Epoch 102/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0230\n",
      "Epoch 103/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0213\n",
      "Epoch 104/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0228\n",
      "Epoch 105/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0211\n",
      "Epoch 106/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0151 - val_loss: 0.0223\n",
      "Epoch 107/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0212\n",
      "Epoch 108/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0217\n",
      "Epoch 109/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 110/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0149 - val_loss: 0.0208\n",
      "Epoch 111/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0206\n",
      "Epoch 112/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0220\n",
      "Epoch 113/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0216\n",
      "Epoch 114/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0215\n",
      "Epoch 115/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0213\n",
      "Epoch 116/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0148 - val_loss: 0.0220\n",
      "Epoch 117/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0209\n",
      "Epoch 118/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0212\n",
      "Epoch 119/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0147 - val_loss: 0.0211\n",
      "Epoch 120/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 121/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00121: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [02:00<06:00, 120.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.0583 - val_loss: 0.0332\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0313 - val_loss: 0.0279\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.0250\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0226\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0223 - val_loss: 0.0210\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.0225\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0212 - val_loss: 0.0199\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0187\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0201\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0211\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0189\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0192\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0178\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0176 - val_loss: 0.0177\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0163 - val_loss: 0.0193\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0171 - val_loss: 0.0190\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0167 - val_loss: 0.0193\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0169 - val_loss: 0.0189\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0164 - val_loss: 0.0165\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0177\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0161 - val_loss: 0.0180\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0167\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0185\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0155 - val_loss: 0.0198\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0156 - val_loss: 0.0191\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0162 - val_loss: 0.0181\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0154 - val_loss: 0.0166\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0152 - val_loss: 0.0179\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0150 - val_loss: 0.0189\n",
      "Epoch 00039: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2978 - val_loss: 0.1335\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1231 - val_loss: 0.1107\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1031 - val_loss: 0.1029\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0929\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0892 - val_loss: 0.0960\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0880 - val_loss: 0.0896\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0844 - val_loss: 0.0870\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0831 - val_loss: 0.0894\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0801 - val_loss: 0.0842\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0787 - val_loss: 0.0831\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0784 - val_loss: 0.0867\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0781 - val_loss: 0.0795\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0759 - val_loss: 0.0812\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0750 - val_loss: 0.0811\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0753 - val_loss: 0.0877\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0749 - val_loss: 0.0783\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0735 - val_loss: 0.0817\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0739 - val_loss: 0.0795\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0707 - val_loss: 0.0812\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0789\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0712 - val_loss: 0.0798\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0709 - val_loss: 0.0797\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0721 - val_loss: 0.0788\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0711 - val_loss: 0.0780\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0769\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0699 - val_loss: 0.0817\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0690 - val_loss: 0.0799\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0695 - val_loss: 0.0798\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0670 - val_loss: 0.0797\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0677 - val_loss: 0.0757\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0678 - val_loss: 0.0784\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0679 - val_loss: 0.0820\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0674 - val_loss: 0.0806\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0778\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0655 - val_loss: 0.0810\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0652 - val_loss: 0.0820\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0663 - val_loss: 0.0786\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0644 - val_loss: 0.0778\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0643 - val_loss: 0.0780\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0661 - val_loss: 0.0859\n",
      "Epoch 00040: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 2ms/step - loss: 0.8245 - val_loss: 0.2311\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2157 - val_loss: 0.1948\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1620\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1579 - val_loss: 0.1532\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1519 - val_loss: 0.1490\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1438 - val_loss: 0.1404\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1400 - val_loss: 0.1555\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1386 - val_loss: 0.1367\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1320 - val_loss: 0.1365\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1308 - val_loss: 0.1396\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1319 - val_loss: 0.1336\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1264 - val_loss: 0.1363\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1286 - val_loss: 0.1370\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1249 - val_loss: 0.1351\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1235 - val_loss: 0.1296\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1201 - val_loss: 0.1299\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1226 - val_loss: 0.1296\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1231 - val_loss: 0.1266\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1176 - val_loss: 0.1363\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1192 - val_loss: 0.1300\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1196 - val_loss: 0.1298\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1187 - val_loss: 0.1270\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1151 - val_loss: 0.1353\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1170 - val_loss: 0.1337\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1195 - val_loss: 0.1321\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1168 - val_loss: 0.1286\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 997us/step - loss: 0.1176 - val_loss: 0.1312\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 995us/step - loss: 0.1138 - val_loss: 0.1303\n",
      "Epoch 00028: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.0474 - val_loss: 0.1618\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 952us/step - loss: 0.1540 - val_loss: 0.1302\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 916us/step - loss: 0.1229 - val_loss: 0.1154\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 950us/step - loss: 0.1091 - val_loss: 0.1065\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 953us/step - loss: 0.0967 - val_loss: 0.0978\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0921 - val_loss: 0.0938\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0920\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 945us/step - loss: 0.0878 - val_loss: 0.0896\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 965us/step - loss: 0.0827 - val_loss: 0.0897\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 941us/step - loss: 0.0817 - val_loss: 0.0877\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0811 - val_loss: 0.0866\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 918us/step - loss: 0.0781 - val_loss: 0.0883\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 913us/step - loss: 0.0806 - val_loss: 0.0940\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 930us/step - loss: 0.0803 - val_loss: 0.0810\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0791 - val_loss: 0.0805\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 906us/step - loss: 0.0761 - val_loss: 0.0809\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 967us/step - loss: 0.0749 - val_loss: 0.0811\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0746 - val_loss: 0.0831\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 934us/step - loss: 0.0754 - val_loss: 0.0806\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 915us/step - loss: 0.0736 - val_loss: 0.0801\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 921us/step - loss: 0.0728 - val_loss: 0.0823\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 938us/step - loss: 0.0710 - val_loss: 0.0818\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 902us/step - loss: 0.0723 - val_loss: 0.0802\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 940us/step - loss: 0.0712 - val_loss: 0.0832\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 938us/step - loss: 0.0701 - val_loss: 0.0805\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 904us/step - loss: 0.0701 - val_loss: 0.0803\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 892us/step - loss: 0.0699 - val_loss: 0.0840\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 939us/step - loss: 0.0701 - val_loss: 0.0773\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 930us/step - loss: 0.0704 - val_loss: 0.0780\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 926us/step - loss: 0.0696 - val_loss: 0.0847\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 946us/step - loss: 0.0710 - val_loss: 0.0824\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 911us/step - loss: 0.0707 - val_loss: 0.0782\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 895us/step - loss: 0.0674 - val_loss: 0.0784\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 902us/step - loss: 0.0669 - val_loss: 0.0824\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 921us/step - loss: 0.0696 - val_loss: 0.0752\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 914us/step - loss: 0.0675 - val_loss: 0.0774\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 928us/step - loss: 0.0677 - val_loss: 0.0784\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 901us/step - loss: 0.0687 - val_loss: 0.0825\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 900us/step - loss: 0.0662 - val_loss: 0.0782\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 898us/step - loss: 0.0646 - val_loss: 0.0787\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0649 - val_loss: 0.0783\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 895us/step - loss: 0.0672 - val_loss: 0.0784\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 911us/step - loss: 0.0646 - val_loss: 0.0831\n",
      "Epoch 44/200\n",
      "189/189 [==============================] - 0s 922us/step - loss: 0.0657 - val_loss: 0.0817\n",
      "Epoch 45/200\n",
      "189/189 [==============================] - 0s 909us/step - loss: 0.0656 - val_loss: 0.0798\n",
      "Epoch 00045: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 1ms/step - loss: 1.3081 - val_loss: 0.0686\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 951us/step - loss: 0.0599 - val_loss: 0.0468\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0419\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0353 - val_loss: 0.0368\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 987us/step - loss: 0.0309 - val_loss: 0.0336\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 948us/step - loss: 0.0279 - val_loss: 0.0309\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0260 - val_loss: 0.0291\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 911us/step - loss: 0.0245 - val_loss: 0.0298\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 920us/step - loss: 0.0237 - val_loss: 0.0285\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 932us/step - loss: 0.0224 - val_loss: 0.0261\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 902us/step - loss: 0.0218 - val_loss: 0.0261\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 899us/step - loss: 0.0210 - val_loss: 0.0266\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0209 - val_loss: 0.0256\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0197 - val_loss: 0.0245\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 920us/step - loss: 0.0193 - val_loss: 0.0254\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 893us/step - loss: 0.0197 - val_loss: 0.0226\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 887us/step - loss: 0.0195 - val_loss: 0.0226\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 927us/step - loss: 0.0191 - val_loss: 0.0221\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 955us/step - loss: 0.0187 - val_loss: 0.0217\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 896us/step - loss: 0.0186 - val_loss: 0.0202\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 955us/step - loss: 0.0180 - val_loss: 0.0215\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 910us/step - loss: 0.0180 - val_loss: 0.0201\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 923us/step - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 937us/step - loss: 0.0181 - val_loss: 0.0214\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 906us/step - loss: 0.0179 - val_loss: 0.0203\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 917us/step - loss: 0.0172 - val_loss: 0.0178\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 957us/step - loss: 0.0176 - val_loss: 0.0212\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 957us/step - loss: 0.0170 - val_loss: 0.0192\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 926us/step - loss: 0.0172 - val_loss: 0.0193\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 890us/step - loss: 0.0165 - val_loss: 0.0198\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 897us/step - loss: 0.0170 - val_loss: 0.0195\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 894us/step - loss: 0.0167 - val_loss: 0.0199\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 892us/step - loss: 0.0164 - val_loss: 0.0187\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 894us/step - loss: 0.0184 - val_loss: 0.0221\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 958us/step - loss: 0.0166 - val_loss: 0.0228\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 964us/step - loss: 0.0177 - val_loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [00:00<00:00,  4.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [00:00<00:00,  5.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 11.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [02:50<03:18, 99.16s/it] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.0605 - val_loss: 0.0290\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0299 - val_loss: 0.0268\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0267 - val_loss: 0.0262\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0205\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.0205\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0196\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0229 - val_loss: 0.0247\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0188\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0211 - val_loss: 0.0199\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0215 - val_loss: 0.0194\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0210 - val_loss: 0.0219\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0209 - val_loss: 0.0189\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0179\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0197\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0196\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0205 - val_loss: 0.0188\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0227 - val_loss: 0.0226\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0203 - val_loss: 0.0192\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0192\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0210\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0193\n",
      "Epoch 00026: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.2425 - val_loss: 0.1289\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1122 - val_loss: 0.0964\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1009 - val_loss: 0.1016\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0957 - val_loss: 0.0873\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0910\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0903 - val_loss: 0.0859\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0911 - val_loss: 0.0819\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0869 - val_loss: 0.0792\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0863 - val_loss: 0.0907\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.0838\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0884 - val_loss: 0.0827\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0850 - val_loss: 0.0874\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0849 - val_loss: 0.0826\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0855 - val_loss: 0.0820\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0823 - val_loss: 0.0889\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0809\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0907 - val_loss: 0.0835\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0826 - val_loss: 0.0840\n",
      "Epoch 00018: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.4493 - val_loss: 0.1822\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1438\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1551 - val_loss: 0.1473\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1491 - val_loss: 0.1384\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1500 - val_loss: 0.1340\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1464 - val_loss: 0.1515\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1454 - val_loss: 0.1312\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1445 - val_loss: 0.1445\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1407 - val_loss: 0.1466\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1419 - val_loss: 0.1371\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1376 - val_loss: 0.1415\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1388 - val_loss: 0.1300\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1391\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1388 - val_loss: 0.1387\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1372 - val_loss: 0.1317\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1338 - val_loss: 0.1336\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1348 - val_loss: 0.1354\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1353 - val_loss: 0.1321\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1358 - val_loss: 0.1352\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1343 - val_loss: 0.1368\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1369 - val_loss: 0.1411\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1331 - val_loss: 0.1336\n",
      "Epoch 00022: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.4660 - val_loss: 0.1685\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1185 - val_loss: 0.1109\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1040 - val_loss: 0.1158\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1023 - val_loss: 0.0981\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0938 - val_loss: 0.1091\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0928 - val_loss: 0.0835\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0886 - val_loss: 0.0952\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0915 - val_loss: 0.0833\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0900 - val_loss: 0.0893\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0896 - val_loss: 0.0848\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0862 - val_loss: 0.0803\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0858 - val_loss: 0.0862\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0873 - val_loss: 0.0837\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0843 - val_loss: 0.0946\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0866 - val_loss: 0.0803\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0825 - val_loss: 0.0871\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0861 - val_loss: 0.0891\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0859 - val_loss: 0.0846\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0857 - val_loss: 0.0831\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0834\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0830 - val_loss: 0.0828\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0833 - val_loss: 0.0827\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0827 - val_loss: 0.0880\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0835 - val_loss: 0.0852\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0832 - val_loss: 0.0826\n",
      "Epoch 00025: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.3909 - val_loss: 0.0470\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0412\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0366 - val_loss: 0.0337\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0332 - val_loss: 0.0369\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0308 - val_loss: 0.0256\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0268 - val_loss: 0.0233\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0239 - val_loss: 0.0232\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0244 - val_loss: 0.0234\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0237\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0213\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0221 - val_loss: 0.0233\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0249 - val_loss: 0.0206\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.0260\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0238 - val_loss: 0.0288\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0206\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0229\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0217 - val_loss: 0.0190\n",
      "Epoch 20/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0208 - val_loss: 0.0222\n",
      "Epoch 21/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0199 - val_loss: 0.0229\n",
      "Epoch 22/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0198 - val_loss: 0.0233\n",
      "Epoch 23/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 24/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0218\n",
      "Epoch 25/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0200 - val_loss: 0.0205\n",
      "Epoch 26/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "Epoch 27/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0201 - val_loss: 0.0188\n",
      "Epoch 28/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 29/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 30/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0184 - val_loss: 0.0207\n",
      "Epoch 31/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0195\n",
      "Epoch 32/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0197\n",
      "Epoch 33/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0190 - val_loss: 0.0180\n",
      "Epoch 34/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0182 - val_loss: 0.0187\n",
      "Epoch 35/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 36/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0223\n",
      "Epoch 37/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.0214\n",
      "Epoch 38/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 39/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0204 - val_loss: 0.0246\n",
      "Epoch 40/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0193 - val_loss: 0.0198\n",
      "Epoch 41/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 42/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 43/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0196 - val_loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 13.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [03:33<01:22, 82.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.1054 - val_loss: 0.0511\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0281\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0283 - val_loss: 0.0264\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0252 - val_loss: 0.0282\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.1415\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 30.5075 - val_loss: 7.5247\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 4.7605 - val_loss: 0.8435\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.9354 - val_loss: 0.5398\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.4089\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2749 - val_loss: 0.1323\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.1605\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.0721\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1362 - val_loss: 0.1831\n",
      "Epoch 00013: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2387 - val_loss: 0.0924\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1071 - val_loss: 0.0906\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1227 - val_loss: 0.0908\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1030 - val_loss: 0.0987\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1007 - val_loss: 0.0992\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1117 - val_loss: 0.1148\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 4.1660 - val_loss: 1.3291\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.8197 - val_loss: 0.2370\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1990 - val_loss: 0.2263\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1446 - val_loss: 0.1142\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1106 - val_loss: 0.1063\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1238 - val_loss: 0.1105\n",
      "Epoch 00012: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.1180 - val_loss: 0.1527\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1645 - val_loss: 0.1733\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1953\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1951\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 2ms/step - loss: 0.2323 - val_loss: 0.1631\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2079 - val_loss: 0.3579\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.8639 - val_loss: 0.2540\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.1777\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1435\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1817\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.2130\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1856\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1473\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1613 - val_loss: 0.1787\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1799 - val_loss: 0.1578\n",
      "Epoch 16/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1484\n",
      "Epoch 17/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.2407\n",
      "Epoch 18/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.2230\n",
      "Epoch 19/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.2960\n",
      "Epoch 00019: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 0.9148 - val_loss: 0.1194\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1088 - val_loss: 0.0984\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1051 - val_loss: 0.1082\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1132 - val_loss: 0.1474\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 1.9591 - val_loss: 3.0303\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.3115 - val_loss: 0.2931\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1956 - val_loss: 0.1159\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1435 - val_loss: 0.1162\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1132 - val_loss: 0.1142\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1223 - val_loss: 0.1168\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1062 - val_loss: 0.1160\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1006 - val_loss: 0.1265\n",
      "Epoch 00012: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "189/189 [==============================] - 1s 2ms/step - loss: 1.2914 - val_loss: 0.0500\n",
      "Epoch 2/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.0260\n",
      "Epoch 3/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0271 - val_loss: 0.0289\n",
      "Epoch 4/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0265 - val_loss: 0.0233\n",
      "Epoch 5/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.0196\n",
      "Epoch 6/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.0256 - val_loss: 0.0360\n",
      "Epoch 7/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 29.7439 - val_loss: 2.3969\n",
      "Epoch 8/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 2.0963 - val_loss: 0.4546\n",
      "Epoch 9/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.2847\n",
      "Epoch 10/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.1122\n",
      "Epoch 11/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1337\n",
      "Epoch 12/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1539\n",
      "Epoch 13/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1292 - val_loss: 0.1307\n",
      "Epoch 14/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.1564 - val_loss: 0.3748\n",
      "Epoch 15/200\n",
      "189/189 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [04:02<00:00, 60.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [04:02<00:00, 242.16s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [08:50<18:18, 274.75s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0841\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0688\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0663 - val_loss: 0.0596\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0550\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0512\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0472\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0444\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0412\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0384\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0356\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0345\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0325\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0330 - val_loss: 0.0313\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0301\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0295\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0288\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0283\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0274\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0270\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0275 - val_loss: 0.0266\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0272 - val_loss: 0.0260\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0263 - val_loss: 0.0255\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0256\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0249\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0246\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0243\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0241\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0241\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0233\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0234\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0229\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0229\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0229\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0227\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0226\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0226\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0226\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0226\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0224\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0211 - val_loss: 0.0221\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0225\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0222\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0218\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0222\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0222\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0224\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0220\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0220\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0219\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0219\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0220\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0218\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0218\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0218\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0212\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0216\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0215\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0217\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0217\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0214\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0208\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0217\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0209\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0207\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0213\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0207\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0207\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0206\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0176 - val_loss: 0.0206\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0204\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0208\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0203\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0202\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0202\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0201\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0205\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0173 - val_loss: 0.0202\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0203\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0206\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0206\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0201\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0200\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0204\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0199\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0204\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0205\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0199\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0202\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0204\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0199\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0200\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0204\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0197\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0204\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0202\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0204\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0194\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0196\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0198\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0203\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0203\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0194\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0195\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0203\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0199\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0200\n",
      "Epoch 00131: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.5443 - val_loss: 0.4351\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.3274\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3197 - val_loss: 0.2832\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2759 - val_loss: 0.2425\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2369 - val_loss: 0.2093\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2081 - val_loss: 0.1867\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1905 - val_loss: 0.1724\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1776 - val_loss: 0.1626\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1677 - val_loss: 0.1564\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1608 - val_loss: 0.1519\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.1470\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1437\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1396\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1381\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1393 - val_loss: 0.1344\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1355 - val_loss: 0.1326\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1349 - val_loss: 0.1300\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1284\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1293 - val_loss: 0.1267\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1275 - val_loss: 0.1255\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.1229\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1212\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1202\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1179\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1162\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1158 - val_loss: 0.1147\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.1143\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1125\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1101 - val_loss: 0.1120\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.1102\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1093\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1058 - val_loss: 0.1088\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1043 - val_loss: 0.1075\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1044 - val_loss: 0.1071\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1042 - val_loss: 0.1060\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1047\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1007 - val_loss: 0.1037\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0998 - val_loss: 0.1033\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.1022\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0973 - val_loss: 0.1024\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.1012\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.1009\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.1003\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0947 - val_loss: 0.0993\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0990\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0981\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0944 - val_loss: 0.0980\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0975\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0917 - val_loss: 0.0977\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0963\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0957\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0890 - val_loss: 0.0960\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0904 - val_loss: 0.0951\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0951\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0891 - val_loss: 0.0946\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0943\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0883 - val_loss: 0.0936\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0879 - val_loss: 0.0932\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0932\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0930\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0927\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0930\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0922\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0917\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0914\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0929\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0915\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0831 - val_loss: 0.0909\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0913\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0911\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0904\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0834 - val_loss: 0.0903\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0823 - val_loss: 0.0909\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0900\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0900\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0894\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0895\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0895\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0810 - val_loss: 0.0891\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0888\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0897\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0889\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0887\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0880\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0884\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0801 - val_loss: 0.0878\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0792 - val_loss: 0.0882\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0876\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0879\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0790 - val_loss: 0.0877\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0870\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0870\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0873\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0873\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0861\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.0863\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0868\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0863\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0861\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0864\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0861\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0861\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0768 - val_loss: 0.0859\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0770 - val_loss: 0.0862\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0852\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0857\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0855\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0853\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0849\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0848\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0846\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0743 - val_loss: 0.0851\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0762 - val_loss: 0.0845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0844\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0840\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0846\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0839\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0754 - val_loss: 0.0838\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0839\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0840\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0838\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0840\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0833\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0836\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0834\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0830\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0744 - val_loss: 0.0833\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0842\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0837\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0830\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0829\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0829\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0825\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0727 - val_loss: 0.0831\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0828\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0826\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0832\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0824\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0825\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0735 - val_loss: 0.0827\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0824\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0728 - val_loss: 0.0824\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0826\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0823\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0823\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0822\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0828\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0826\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0823\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0819\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0822\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0819\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0819\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0815\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0825\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0819\n",
      "Epoch 157/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0819\n",
      "Epoch 158/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0821\n",
      "Epoch 159/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0824\n",
      "Epoch 160/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0819\n",
      "Epoch 161/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0818\n",
      "Epoch 162/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0818\n",
      "Epoch 163/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0818\n",
      "Epoch 164/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0813\n",
      "Epoch 165/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0816\n",
      "Epoch 166/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0813\n",
      "Epoch 167/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0817\n",
      "Epoch 168/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0812\n",
      "Epoch 169/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0815\n",
      "Epoch 170/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0813\n",
      "Epoch 171/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0811\n",
      "Epoch 172/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0808\n",
      "Epoch 173/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0822\n",
      "Epoch 174/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0814\n",
      "Epoch 175/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0810\n",
      "Epoch 176/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0811\n",
      "Epoch 177/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0814\n",
      "Epoch 178/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0811\n",
      "Epoch 179/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0681 - val_loss: 0.0811\n",
      "Epoch 180/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0809\n",
      "Epoch 181/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0808\n",
      "Epoch 182/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0807\n",
      "Epoch 183/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0806\n",
      "Epoch 184/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0689 - val_loss: 0.0809\n",
      "Epoch 185/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0810\n",
      "Epoch 186/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0810\n",
      "Epoch 187/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0810\n",
      "Epoch 188/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0691 - val_loss: 0.0806\n",
      "Epoch 189/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0808\n",
      "Epoch 190/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0805\n",
      "Epoch 191/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0811\n",
      "Epoch 192/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0685 - val_loss: 0.0805\n",
      "Epoch 193/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0804\n",
      "Epoch 194/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0807\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0805\n",
      "Epoch 196/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0804\n",
      "Epoch 197/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0674 - val_loss: 0.0803\n",
      "Epoch 198/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0805\n",
      "Epoch 199/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0801\n",
      "Epoch 200/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0800\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 1.7266 - val_loss: 1.4506\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.3679 - val_loss: 1.0982\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.0158 - val_loss: 0.7774\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.7370 - val_loss: 0.6263\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6088 - val_loss: 0.5285\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5126 - val_loss: 0.4454\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.3855\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3427\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3138\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.2925\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3110 - val_loss: 0.2750\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.2617\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2809 - val_loss: 0.2520\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2722 - val_loss: 0.2434\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2614 - val_loss: 0.2364\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2316\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2473 - val_loss: 0.2264\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2443 - val_loss: 0.2243\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2371 - val_loss: 0.2189\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2339 - val_loss: 0.2155\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2268 - val_loss: 0.2126\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2254 - val_loss: 0.2088\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2183 - val_loss: 0.2071\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2151 - val_loss: 0.2035\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2090 - val_loss: 0.2011\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2077 - val_loss: 0.1982\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.1961\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2021 - val_loss: 0.1937\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1986 - val_loss: 0.1919\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1975 - val_loss: 0.1900\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1934 - val_loss: 0.1875\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1933 - val_loss: 0.1857\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1851 - val_loss: 0.1849\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1853 - val_loss: 0.1819\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1810 - val_loss: 0.1806\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1786 - val_loss: 0.1788\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1773 - val_loss: 0.1764\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1751 - val_loss: 0.1761\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1734 - val_loss: 0.1737\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1725 - val_loss: 0.1722\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1696 - val_loss: 0.1711\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.1693\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1685\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1639 - val_loss: 0.1662\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1655\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1643\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1629\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1616\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1583 - val_loss: 0.1612\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1559 - val_loss: 0.1603\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1569 - val_loss: 0.1605\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.1582\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1578\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1498 - val_loss: 0.1567\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.1570\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1550\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1548\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1461 - val_loss: 0.1530\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1529\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1522\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1509\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1441 - val_loss: 0.1504\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1429 - val_loss: 0.1501\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1415 - val_loss: 0.1507\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1497\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1408 - val_loss: 0.1487\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1404 - val_loss: 0.1480\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1397 - val_loss: 0.1483\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1398 - val_loss: 0.1468\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1388 - val_loss: 0.1468\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.1462\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1376 - val_loss: 0.1452\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1371 - val_loss: 0.1452\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1370 - val_loss: 0.1451\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.1453\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.1443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1348 - val_loss: 0.1443\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1323 - val_loss: 0.1434\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.1429\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1336 - val_loss: 0.1432\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1341 - val_loss: 0.1430\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1329 - val_loss: 0.1429\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1421\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1420\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1316 - val_loss: 0.1413\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1312 - val_loss: 0.1410\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.1410\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.1407\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1299 - val_loss: 0.1409\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1298 - val_loss: 0.1410\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1405\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1402\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1288 - val_loss: 0.1400\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1286 - val_loss: 0.1399\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1283 - val_loss: 0.1396\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.1397\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1396\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1395\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1272 - val_loss: 0.1387\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1391\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1386\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1282 - val_loss: 0.1387\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1258 - val_loss: 0.1381\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1381\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.1378\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1250 - val_loss: 0.1376\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1255 - val_loss: 0.1376\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1252 - val_loss: 0.1372\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1372\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1240 - val_loss: 0.1374\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.1369\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1230 - val_loss: 0.1368\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.1369\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1241 - val_loss: 0.1372\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1239 - val_loss: 0.1371\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1367\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1237 - val_loss: 0.1369\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1235 - val_loss: 0.1370\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1231 - val_loss: 0.1365\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1208 - val_loss: 0.1359\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1360\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1223 - val_loss: 0.1358\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1364\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 0.1366\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1214 - val_loss: 0.1355\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1359\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1359\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1228 - val_loss: 0.1358\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1212 - val_loss: 0.1354\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1355\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1354\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1207 - val_loss: 0.1348\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1354\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.1350\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1352\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1213 - val_loss: 0.1358\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1349\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1193 - val_loss: 0.1351\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1350\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1351\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1353\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1344\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1200 - val_loss: 0.1348\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1187 - val_loss: 0.1348\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1352\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1184 - val_loss: 0.1346\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1202 - val_loss: 0.1345\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1188 - val_loss: 0.1346\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1167 - val_loss: 0.1352\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1181 - val_loss: 0.1349\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.1346\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1342\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1342\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1180 - val_loss: 0.1340\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1340\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1169 - val_loss: 0.1346\n",
      "Epoch 157/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1347\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1186 - val_loss: 0.1343\n",
      "Epoch 159/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1342\n",
      "Epoch 160/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1162 - val_loss: 0.1341\n",
      "Epoch 161/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.1347\n",
      "Epoch 162/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1340\n",
      "Epoch 163/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1336\n",
      "Epoch 164/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1347\n",
      "Epoch 165/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1342\n",
      "Epoch 166/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1341\n",
      "Epoch 167/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.1339\n",
      "Epoch 168/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1338\n",
      "Epoch 169/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1344\n",
      "Epoch 170/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1334\n",
      "Epoch 171/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1336\n",
      "Epoch 172/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1164 - val_loss: 0.1334\n",
      "Epoch 173/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1165 - val_loss: 0.1335\n",
      "Epoch 174/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.1339\n",
      "Epoch 175/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1151 - val_loss: 0.1331\n",
      "Epoch 176/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1334\n",
      "Epoch 177/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1339\n",
      "Epoch 178/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1157 - val_loss: 0.1330\n",
      "Epoch 179/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1333\n",
      "Epoch 180/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1329\n",
      "Epoch 181/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1142 - val_loss: 0.1328\n",
      "Epoch 182/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1141 - val_loss: 0.1333\n",
      "Epoch 183/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.1333\n",
      "Epoch 184/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.1335\n",
      "Epoch 185/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1337\n",
      "Epoch 186/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1150 - val_loss: 0.1332\n",
      "Epoch 187/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1144 - val_loss: 0.1333\n",
      "Epoch 188/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1119 - val_loss: 0.1331\n",
      "Epoch 189/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1324\n",
      "Epoch 190/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1329\n",
      "Epoch 191/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1135 - val_loss: 0.1332\n",
      "Epoch 192/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.1329\n",
      "Epoch 193/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1138 - val_loss: 0.1331\n",
      "Epoch 194/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1137 - val_loss: 0.1331\n",
      "Epoch 195/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.1340\n",
      "Epoch 196/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.1108 - val_loss: 0.1332\n",
      "Epoch 197/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1329\n",
      "Epoch 198/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1125 - val_loss: 0.1326\n",
      "Epoch 199/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1124 - val_loss: 0.1329\n",
      "Epoch 00199: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 2.9373 - val_loss: 2.4096\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.2287 - val_loss: 1.6620\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.4874 - val_loss: 0.9791\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8905 - val_loss: 0.6211\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5919 - val_loss: 0.4578\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.3799\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3715 - val_loss: 0.3388\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3353 - val_loss: 0.3105\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3010 - val_loss: 0.2862\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2837 - val_loss: 0.2653\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2629 - val_loss: 0.2469\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2510 - val_loss: 0.2325\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2348 - val_loss: 0.2216\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2250 - val_loss: 0.2127\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2132 - val_loss: 0.2053\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2035 - val_loss: 0.1995\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1977 - val_loss: 0.1941\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1912 - val_loss: 0.1891\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1875 - val_loss: 0.1850\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1823 - val_loss: 0.1814\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1771 - val_loss: 0.1779\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1749 - val_loss: 0.1751\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1717\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1662 - val_loss: 0.1697\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1666\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1607 - val_loss: 0.1641\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1612\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1585\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1568\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1544\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1529\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1501\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1473\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1417 - val_loss: 0.1461\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1404 - val_loss: 0.1441\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1372 - val_loss: 0.1416\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1345 - val_loss: 0.1394\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1383\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1310 - val_loss: 0.1363\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1305 - val_loss: 0.1341\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1325\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1253 - val_loss: 0.1309\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1254 - val_loss: 0.1291\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1276\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1211 - val_loss: 0.1261\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1222 - val_loss: 0.1249\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1189 - val_loss: 0.1233\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1222\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1214\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1197\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1132 - val_loss: 0.1181\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1145 - val_loss: 0.1173\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1160\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1103 - val_loss: 0.1146\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.1142\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1068 - val_loss: 0.1126\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1064 - val_loss: 0.1118\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1072 - val_loss: 0.1109\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1067 - val_loss: 0.1099\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1033 - val_loss: 0.1088\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1034 - val_loss: 0.1083\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1023 - val_loss: 0.1078\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1022 - val_loss: 0.1066\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0999 - val_loss: 0.1055\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1010 - val_loss: 0.1051\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.1042\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0976 - val_loss: 0.1035\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0977 - val_loss: 0.1031\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0960 - val_loss: 0.1028\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.1017\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.1011\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.1000\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.1002\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0988\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0984\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.0977\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0976\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0914 - val_loss: 0.0964\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0897 - val_loss: 0.0964\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0889 - val_loss: 0.0959\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0962\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0888 - val_loss: 0.0960\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0878 - val_loss: 0.0943\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0875 - val_loss: 0.0944\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0857 - val_loss: 0.0945\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0930\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0933\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0854 - val_loss: 0.0931\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0844 - val_loss: 0.0922\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0858 - val_loss: 0.0920\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0915\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0918\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0919\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0913\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0909\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0907\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0907\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0913\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0899\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0902\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0896\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0808 - val_loss: 0.0902\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0812 - val_loss: 0.0893\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0795 - val_loss: 0.0896\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0900\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0886\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0802 - val_loss: 0.0888\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0883\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0886\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0786 - val_loss: 0.0884\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0882\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0879\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0783 - val_loss: 0.0882\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0883\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0791 - val_loss: 0.0875\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0879\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0876\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0781 - val_loss: 0.0873\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0771 - val_loss: 0.0872\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0865\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0767 - val_loss: 0.0866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0867\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0869\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0867\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0871\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0760 - val_loss: 0.0864\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0763 - val_loss: 0.0858\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0757 - val_loss: 0.0858\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0750 - val_loss: 0.0857\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0758 - val_loss: 0.0866\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0854\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0756 - val_loss: 0.0851\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0855\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0855\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0847\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0848\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0854\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0847\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0844\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0738 - val_loss: 0.0854\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0742 - val_loss: 0.0848\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0846\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0841\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0859\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0842\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0840\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0841\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0834\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0841\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0721 - val_loss: 0.0840\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0838\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0838\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0833\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0845\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0840\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0724 - val_loss: 0.0839\n",
      "Epoch 157/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0836\n",
      "Epoch 158/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0838\n",
      "Epoch 159/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0833\n",
      "Epoch 160/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0710 - val_loss: 0.0833\n",
      "Epoch 161/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0830\n",
      "Epoch 162/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0829\n",
      "Epoch 163/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0841\n",
      "Epoch 164/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0718 - val_loss: 0.0827\n",
      "Epoch 165/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0828\n",
      "Epoch 166/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0713 - val_loss: 0.0828\n",
      "Epoch 167/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0701 - val_loss: 0.0829\n",
      "Epoch 168/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0824\n",
      "Epoch 169/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0824\n",
      "Epoch 170/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0712 - val_loss: 0.0832\n",
      "Epoch 171/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0703 - val_loss: 0.0830\n",
      "Epoch 172/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0826\n",
      "Epoch 173/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0829\n",
      "Epoch 174/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0821\n",
      "Epoch 175/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0698 - val_loss: 0.0817\n",
      "Epoch 176/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0829\n",
      "Epoch 177/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0825\n",
      "Epoch 178/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0826\n",
      "Epoch 179/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0825\n",
      "Epoch 180/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0821\n",
      "Epoch 181/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0819\n",
      "Epoch 182/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0820\n",
      "Epoch 183/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0683 - val_loss: 0.0819\n",
      "Epoch 184/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0821\n",
      "Epoch 185/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0693 - val_loss: 0.0821\n",
      "Epoch 00185: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 4.1790 - val_loss: 3.6170\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.3807 - val_loss: 2.7879\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 2.5524 - val_loss: 1.9277\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.6971 - val_loss: 1.1361\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9889 - val_loss: 0.6341\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5768 - val_loss: 0.3781\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3516 - val_loss: 0.2506\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2404 - val_loss: 0.1824\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1725 - val_loss: 0.1448\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1238\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1117\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1104 - val_loss: 0.1040\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.0976\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0926\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0888\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0874 - val_loss: 0.0857\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0818 - val_loss: 0.0810\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0792\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0772\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0753\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0735\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0714\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0697 - val_loss: 0.0696\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0669 - val_loss: 0.0679\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0656 - val_loss: 0.0665\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0633 - val_loss: 0.0650\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0608 - val_loss: 0.0636\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0603 - val_loss: 0.0622\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0604\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0558 - val_loss: 0.0592\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0554 - val_loss: 0.0576\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0527 - val_loss: 0.0545\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0519 - val_loss: 0.0531\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0504 - val_loss: 0.0521\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0510\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0500\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0492\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0484\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0474\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0465\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0458\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0450\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0442\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0435\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0430\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0425\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0417\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0416\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0410\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0406\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0401\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0397\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0391\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0357 - val_loss: 0.0386\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0351 - val_loss: 0.0386\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0380\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0350 - val_loss: 0.0380\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0346 - val_loss: 0.0371\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0371\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0329 - val_loss: 0.0368\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0336 - val_loss: 0.0364\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0322 - val_loss: 0.0359\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0326 - val_loss: 0.0360\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0317 - val_loss: 0.0357\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0352\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0312 - val_loss: 0.0350\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0355\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0311 - val_loss: 0.0354\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0303 - val_loss: 0.0351\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0349\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0298 - val_loss: 0.0347\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0295 - val_loss: 0.0344\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0291 - val_loss: 0.0347\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0293 - val_loss: 0.0339\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0288 - val_loss: 0.0341\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0286 - val_loss: 0.0340\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0341\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0339\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0279 - val_loss: 0.0337\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0277 - val_loss: 0.0335\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0270 - val_loss: 0.0330\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0332\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0267 - val_loss: 0.0327\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0268 - val_loss: 0.0328\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0265 - val_loss: 0.0329\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0322\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0322\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0323\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0314\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0253 - val_loss: 0.0316\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0251 - val_loss: 0.0331\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0247 - val_loss: 0.0311\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0321\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0312\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0312\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0239 - val_loss: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0311\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0241 - val_loss: 0.0313\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0307\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0301\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0304\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0302\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0299\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0226 - val_loss: 0.0311\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0294\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0291\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0299\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0291\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0291\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0293\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0290\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0293\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0286\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0278\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0281\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0287\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0280\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0283\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0281\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0282\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0208 - val_loss: 0.0282\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0274\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0274\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0278\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0278\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0267\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0276\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0270\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0271\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0273\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0266\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0265\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0274\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0259\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0271\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0260\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0263\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0274\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0269\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0262\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0268\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0263\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0254\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0256\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0261\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0262\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0259\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0261\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0261\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0262\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0254\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0257\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00156: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [01:57<05:51, 117.23s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.0587 - val_loss: 0.0348\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0334 - val_loss: 0.0297\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0292 - val_loss: 0.0276\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0261 - val_loss: 0.0268\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0232 - val_loss: 0.0241\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0220 - val_loss: 0.0234\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0244\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0232\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0212\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0219\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0192\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0211\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0182 - val_loss: 0.0206\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0166 - val_loss: 0.0200\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0167 - val_loss: 0.0192\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0206\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0202\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0194\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0188\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0184\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0186\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0201\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0180\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0184\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0199\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0154 - val_loss: 0.0192\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0197\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0185\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0150 - val_loss: 0.0199\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0204\n",
      "Epoch 00041: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.4826 - val_loss: 0.1772\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1660 - val_loss: 0.1314\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1319 - val_loss: 0.1202\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1103\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1055\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1016 - val_loss: 0.0971\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0982 - val_loss: 0.0950\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0921 - val_loss: 0.0917\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0898\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0849 - val_loss: 0.0894\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0872 - val_loss: 0.0873\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0856\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0842 - val_loss: 0.0870\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0876\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.0802 - val_loss: 0.0848\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0853\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0803 - val_loss: 0.0844\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0778 - val_loss: 0.0841\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0839\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0752 - val_loss: 0.0831\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0842\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0745 - val_loss: 0.0820\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0736 - val_loss: 0.0838\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0814\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0731 - val_loss: 0.0840\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0723 - val_loss: 0.0840\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0737 - val_loss: 0.0846\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0716 - val_loss: 0.0858\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0732 - val_loss: 0.0799\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0706 - val_loss: 0.0802\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0801\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0815\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0692 - val_loss: 0.0834\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0677 - val_loss: 0.0804\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0817\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0686 - val_loss: 0.0799\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0788\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0805\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0684 - val_loss: 0.0800\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0782\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0668 - val_loss: 0.0803\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0678 - val_loss: 0.0791\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0655 - val_loss: 0.0816\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0688 - val_loss: 0.0807\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0664 - val_loss: 0.0784\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0666 - val_loss: 0.0794\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0778\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0661 - val_loss: 0.0813\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0807\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0644 - val_loss: 0.0804\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0649 - val_loss: 0.0782\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0810\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0627 - val_loss: 0.0795\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0641 - val_loss: 0.0799\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0642 - val_loss: 0.0803\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0646 - val_loss: 0.0794\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0788\n",
      "Epoch 00057: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 1.1953 - val_loss: 0.3404\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.2481\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2426 - val_loss: 0.2173\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2077 - val_loss: 0.1914\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1893 - val_loss: 0.1802\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1722 - val_loss: 0.1699\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1620 - val_loss: 0.1640\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1610\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1520\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1596\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1421 - val_loss: 0.1456\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1406 - val_loss: 0.1455\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1357 - val_loss: 0.1410\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1320 - val_loss: 0.1386\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.1387\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1313 - val_loss: 0.1357\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1281 - val_loss: 0.1351\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1285 - val_loss: 0.1366\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1267 - val_loss: 0.1370\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1352\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1271 - val_loss: 0.1338\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1236 - val_loss: 0.1358\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1246 - val_loss: 0.1323\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1218 - val_loss: 0.1319\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1308\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1346\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1216 - val_loss: 0.1338\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1229 - val_loss: 0.1350\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1182 - val_loss: 0.1330\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1190 - val_loss: 0.1329\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1178 - val_loss: 0.1303\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1326\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1173 - val_loss: 0.1288\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1133 - val_loss: 0.1328\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1307\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1367\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1171 - val_loss: 0.1284\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1153 - val_loss: 0.1311\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1152 - val_loss: 0.1276\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.1375\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1301\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1241\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1108 - val_loss: 0.1337\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1122 - val_loss: 0.1262\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1092 - val_loss: 0.1303\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1098 - val_loss: 0.1286\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1074 - val_loss: 0.1389\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1115 - val_loss: 0.1283\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1093 - val_loss: 0.1308\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1300\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1083 - val_loss: 0.1326\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1086 - val_loss: 0.1264\n",
      "Epoch 00052: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 2.3416 - val_loss: 0.3748\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.2057\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1888 - val_loss: 0.1720\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.1505\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1401 - val_loss: 0.1391\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1294 - val_loss: 0.1312\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1204 - val_loss: 0.1270\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1183\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1073 - val_loss: 0.1118\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1014 - val_loss: 0.1093\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0984 - val_loss: 0.1055\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.1007\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0924 - val_loss: 0.0984\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0899 - val_loss: 0.0957\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0924\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.0935\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0852 - val_loss: 0.0915\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0884\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0951\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0816 - val_loss: 0.0887\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0809 - val_loss: 0.0899\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0800 - val_loss: 0.0836\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0788 - val_loss: 0.0860\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0909\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0816\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0846\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0753 - val_loss: 0.0850\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0829\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0766 - val_loss: 0.0819\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0749 - val_loss: 0.0877\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0751 - val_loss: 0.0814\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0733 - val_loss: 0.0803\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0739 - val_loss: 0.0826\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0719 - val_loss: 0.0802\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0715 - val_loss: 0.0813\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0714 - val_loss: 0.0829\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0717 - val_loss: 0.0829\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0803\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0705 - val_loss: 0.0829\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0850\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0725 - val_loss: 0.0829\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0696 - val_loss: 0.0830\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0702 - val_loss: 0.0827\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0690 - val_loss: 0.0815\n",
      "Epoch 00044: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 2.2208 - val_loss: 0.0963\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0902 - val_loss: 0.0782\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0709 - val_loss: 0.0624\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0572 - val_loss: 0.0516\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0495 - val_loss: 0.0462\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0421\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0393\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0388\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0327 - val_loss: 0.0351\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0358\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0300 - val_loss: 0.0338\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0287 - val_loss: 0.0327\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0283 - val_loss: 0.0324\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0269 - val_loss: 0.0310\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0257 - val_loss: 0.0327\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0254 - val_loss: 0.0303\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0238 - val_loss: 0.0294\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0305\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0269\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0278\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0274\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0267\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0253\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0260\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0270\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0255\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0239\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0253\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0239\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0243\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0248\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0228\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0234\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0180 - val_loss: 0.0216\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0221\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0177 - val_loss: 0.0244\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0212\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0220\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0207\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0207\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0199\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0218\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0220\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0215\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0229\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0198\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0219\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0192\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0200\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0198\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0219\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0240\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0219\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0217\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0233\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0208\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0209\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00061: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 12.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 12.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [02:42<03:11, 95.68s/it] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.0696 - val_loss: 0.0306\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0310 - val_loss: 0.0288\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0260 - val_loss: 0.0221\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0255 - val_loss: 0.0228\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0229 - val_loss: 0.0259\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0239\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0220\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0192\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0196\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0185\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0196\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0181\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0193\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0197\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0189\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0191\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0197\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 00023: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.2723 - val_loss: 0.1195\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1156 - val_loss: 0.0976\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.0875\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0908 - val_loss: 0.1016\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0959 - val_loss: 0.0888\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0904 - val_loss: 0.0876\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0836\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0900 - val_loss: 0.0887\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0887 - val_loss: 0.0859\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0853 - val_loss: 0.0872\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0882 - val_loss: 0.0811\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0843 - val_loss: 0.0893\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0800\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0834\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0855\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0841 - val_loss: 0.0891\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0820 - val_loss: 0.0921\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0863\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0825 - val_loss: 0.0790\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0859\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0905\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0878\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0819 - val_loss: 0.0886\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0827 - val_loss: 0.0937\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0804\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0803\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0793\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0784 - val_loss: 0.0808\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0779 - val_loss: 0.0818\n",
      "Epoch 00029: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6888 - val_loss: 0.1975\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1924 - val_loss: 0.1568\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1616 - val_loss: 0.1549\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1522 - val_loss: 0.1421\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1492\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1461 - val_loss: 0.1639\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 0.1471\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1423 - val_loss: 0.1349\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1361 - val_loss: 0.1412\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1363 - val_loss: 0.1314\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.1523\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1304\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1350\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1322\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1334 - val_loss: 0.1408\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1310 - val_loss: 0.1377\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1306 - val_loss: 0.1370\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1373 - val_loss: 0.1304\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1300 - val_loss: 0.1273\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1242 - val_loss: 0.1312\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1293 - val_loss: 0.1383\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1265 - val_loss: 0.1351\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1251 - val_loss: 0.1266\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.1368\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1330\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1251 - val_loss: 0.1366\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.1267 - val_loss: 0.1423\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1311 - val_loss: 0.1242\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.1218 - val_loss: 0.1286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.1387\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1300\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1347\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1220 - val_loss: 0.1364\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1270 - val_loss: 0.1273\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1195 - val_loss: 0.1352\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1229\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1174 - val_loss: 0.1262\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1227 - val_loss: 0.1269\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1314\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1294\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.1343\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1192 - val_loss: 0.1342\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1197 - val_loss: 0.1400\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1177 - val_loss: 0.1344\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1275\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1179 - val_loss: 0.1281\n",
      "Epoch 00046: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.8874 - val_loss: 0.1567\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1400 - val_loss: 0.1242\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1238 - val_loss: 0.1067\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1000 - val_loss: 0.0945\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.1357\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0954 - val_loss: 0.0950\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0903\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0871 - val_loss: 0.0900\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0880 - val_loss: 0.0842\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1081\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0906 - val_loss: 0.0927\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0864 - val_loss: 0.0859\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0886\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0829 - val_loss: 0.0862\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0985\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0832 - val_loss: 0.0930\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0846\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0799 - val_loss: 0.0899\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0824 - val_loss: 0.0809\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0814 - val_loss: 0.0838\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0854\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0798 - val_loss: 0.0918\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0815\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0807 - val_loss: 0.0814\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0773 - val_loss: 0.0836\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0748 - val_loss: 0.0856\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0850\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0785\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0793 - val_loss: 0.0869\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0804 - val_loss: 0.0865\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0785 - val_loss: 0.0847\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0787 - val_loss: 0.0875\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0806 - val_loss: 0.0824\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0794 - val_loss: 0.0805\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0741 - val_loss: 0.0827\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0825\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0774 - val_loss: 0.0799\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0769 - val_loss: 0.0821\n",
      "Epoch 00038: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6330 - val_loss: 0.0552\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0472\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0322\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0354 - val_loss: 0.0300\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0319 - val_loss: 0.0271\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0258\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0300\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0262 - val_loss: 0.0252\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0276\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0294\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0233 - val_loss: 0.0260\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0235 - val_loss: 0.0262\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0231 - val_loss: 0.0256\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0214 - val_loss: 0.0249\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0216\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0212 - val_loss: 0.0228\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0261\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0274\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0227\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0216\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0205 - val_loss: 0.0286\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0218\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0221\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0197\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0203\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0222\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0230\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0204 - val_loss: 0.0245\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0206\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0232\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0192\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0237\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0226\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0181\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0195\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0191 - val_loss: 0.0188\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0196\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0199\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0172 - val_loss: 0.0201\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0239\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0186 - val_loss: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00049: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [03:18<01:17, 77.61s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 2.1931 - val_loss: 0.4269\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1845 - val_loss: 0.0499\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0324\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0338 - val_loss: 0.0283\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0271 - val_loss: 0.0225\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0237 - val_loss: 0.0204\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0264\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0246 - val_loss: 0.0263\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0193\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0241\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0245 - val_loss: 0.0241\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0280 - val_loss: 0.0243\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0193\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0203 - val_loss: 0.0272\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0192\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0234\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0221 - val_loss: 0.0205\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0197\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0305\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0217 - val_loss: 0.0365\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 13.7369 - val_loss: 17.4491\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 8.2837 - val_loss: 5.2156\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.6356 - val_loss: 4.5997\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 3.0390 - val_loss: 3.6233\n",
      "Epoch 00025: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 3.1740 - val_loss: 0.2646\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1961 - val_loss: 0.1059\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1160 - val_loss: 0.1006\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1031 - val_loss: 0.0855\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0953 - val_loss: 0.0965\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0938 - val_loss: 0.0834\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0939 - val_loss: 0.0950\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0930 - val_loss: 0.0846\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0868 - val_loss: 0.1038\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0997 - val_loss: 0.0962\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0946 - val_loss: 0.0855\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.1072\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0874\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0929 - val_loss: 0.0863\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0940 - val_loss: 0.0848\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1333 - val_loss: 0.0966\n",
      "Epoch 00016: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 1.9979 - val_loss: 0.2449\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2017 - val_loss: 0.1684\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1602\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1528 - val_loss: 0.1437\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1385\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1274\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1417\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1431 - val_loss: 0.1298\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1443 - val_loss: 0.1483\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1350\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1469 - val_loss: 0.1532\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1407\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1484 - val_loss: 0.1506\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1662\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1524 - val_loss: 0.1487\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1445 - val_loss: 0.1513\n",
      "Epoch 00016: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 5ms/step - loss: 1.2670 - val_loss: 0.3875\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2111 - val_loss: 0.0955\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0952 - val_loss: 0.0994\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0967 - val_loss: 0.0950\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0863 - val_loss: 0.0892\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0850 - val_loss: 0.0808\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0814\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0845 - val_loss: 0.0917\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0877 - val_loss: 0.0968\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0930\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0898 - val_loss: 0.0939\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0860 - val_loss: 0.1009\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0913 - val_loss: 0.0865\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0876 - val_loss: 0.0869\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0862 - val_loss: 0.0923\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0928 - val_loss: 0.0942\n",
      "Epoch 00016: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 1.3156 - val_loss: 0.3883\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.1958 - val_loss: 0.0413\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0279\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0276\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0243 - val_loss: 0.0237\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0258\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "61/61 [==============================] - ETA: 0s - loss: 0.021 - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0210\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0209\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0193 - val_loss: 0.0201\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0201\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0241\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0201\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0197 - val_loss: 0.0205\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0210\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0210 - val_loss: 0.0192\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0219 - val_loss: 0.0205\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0196 - val_loss: 0.0219\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0200 - val_loss: 0.0222\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0219\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0195\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0215 - val_loss: 0.0274\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0234 - val_loss: 0.0224\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 13.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [03:44<00:00, 56.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [03:44<00:00, 224.10s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [12:34<12:58, 259.55s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 7ms/step - loss: 0.0762 - val_loss: 0.0706\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0651\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0593\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0553\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0561 - val_loss: 0.0530\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0528 - val_loss: 0.0508\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0491\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0454\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0436\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0420\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0405\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0394\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0379\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0369\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0361\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0354\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0345\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0337\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0330\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0325\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0319\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0314\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0310\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0306\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0301\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0293\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0290\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0288\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0288\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0283\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0280\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0279\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0276\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0270\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0268\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0267\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0264\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0260\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0261\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0257\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0259\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0250\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0252\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0253\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0251\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0248\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0250\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0247\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0244\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0244\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0234 - val_loss: 0.0245\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0243\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0243\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0241\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0241\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0240\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0238\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0235\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0237\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0235\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0236\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0236\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0237\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0232\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0233\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0232\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0230\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0230\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0229\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0229\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0229\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0227\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0227\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0227\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0224\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0225\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0225\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0224\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0223\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0223\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0224\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0222\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0223\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0221\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0221\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0221\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0219\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0218\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0218\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0218\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0218\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0216\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0217\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0216\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0213\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0215\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0214\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0213\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0212\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0213\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0212\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0212\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0210\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0209\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0210\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0208\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0207\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0209\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0209\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0206\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0207\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0204\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0205\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0206\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0204\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0207\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0206\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0200\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0204\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0204\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0206\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0203\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0204\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0203\n",
      "Epoch 00168: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5933 - val_loss: 0.5546\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5407 - val_loss: 0.5030\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4896 - val_loss: 0.4476\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4333 - val_loss: 0.3883\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3770 - val_loss: 0.3408\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3338 - val_loss: 0.3122\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3077 - val_loss: 0.2910\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.2722\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2673 - val_loss: 0.2541\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2519 - val_loss: 0.2370\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2349 - val_loss: 0.2221\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2227 - val_loss: 0.2085\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2083 - val_loss: 0.1984\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1978 - val_loss: 0.1901\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1925 - val_loss: 0.1842\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1892 - val_loss: 0.1792\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.1747\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1786 - val_loss: 0.1712\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1767 - val_loss: 0.1678\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.1656\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1695 - val_loss: 0.1626\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1648 - val_loss: 0.1600\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1647 - val_loss: 0.1574\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1607 - val_loss: 0.1551\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.1529\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.1509\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1540 - val_loss: 0.1489\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1516 - val_loss: 0.1468\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1452\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1456 - val_loss: 0.1433\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1443 - val_loss: 0.1416\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1403\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1387\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.1375\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1370 - val_loss: 0.1364\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1353\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1342\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1339 - val_loss: 0.1330\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1336 - val_loss: 0.1321\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 0.1312\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1285 - val_loss: 0.1298\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1284 - val_loss: 0.1291\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1277 - val_loss: 0.1283\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1278 - val_loss: 0.1273\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.1263\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1249 - val_loss: 0.1258\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1250\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.1242\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1215 - val_loss: 0.1237\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1209 - val_loss: 0.1230\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1197 - val_loss: 0.1217\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1195 - val_loss: 0.1213\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1205\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 0.1212\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1198\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1160 - val_loss: 0.1198\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.1187\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1137 - val_loss: 0.1184\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1182\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.1171\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1124 - val_loss: 0.1171\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1119 - val_loss: 0.1168\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1111 - val_loss: 0.1158\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1154\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1101 - val_loss: 0.1147\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.1146\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.1138\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1086 - val_loss: 0.1132\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1079 - val_loss: 0.1131\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.1128\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.1121\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1047 - val_loss: 0.1115\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1045 - val_loss: 0.1115\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1042 - val_loss: 0.1110\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1099\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1032 - val_loss: 0.1095\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1038 - val_loss: 0.1094\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1029 - val_loss: 0.1090\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1084\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1016 - val_loss: 0.1082\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.1077\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0999 - val_loss: 0.1074\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1007 - val_loss: 0.1069\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.1065\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1060\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.1053\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.1055\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0974 - val_loss: 0.1050\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0980 - val_loss: 0.1041\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.1042\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 0.1037\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.1033\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1029\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0946 - val_loss: 0.1027\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0949 - val_loss: 0.1018\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0949 - val_loss: 0.1018\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1016\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0944 - val_loss: 0.1012\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0948 - val_loss: 0.1014\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.1007\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0928 - val_loss: 0.1002\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0934 - val_loss: 0.1002\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.0998\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.0993\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.0990\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.0987\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.0987\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0905 - val_loss: 0.0983\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0979\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0911 - val_loss: 0.0976\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0888 - val_loss: 0.0977\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0887 - val_loss: 0.0969\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0969\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.0971\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.0966\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0876 - val_loss: 0.0964\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0959\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0875 - val_loss: 0.0957\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0958\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0955\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0869 - val_loss: 0.0954\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0867 - val_loss: 0.0953\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0950\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0948\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0945\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0948\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0941\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0943\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0941\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0935\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0940\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0938\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0931\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0841 - val_loss: 0.0931\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0850 - val_loss: 0.0928\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0928\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0926\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0926\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0926\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0922\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0922\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0922\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0823 - val_loss: 0.0921\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0920\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0825 - val_loss: 0.0918\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0914\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0918\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0911\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0819 - val_loss: 0.0911\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0913\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0908\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0909\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0903\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0905\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0906\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0905\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0904\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0898\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0905\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0900\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0903\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0813 - val_loss: 0.0906\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0899\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0898\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0800 - val_loss: 0.0894\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0792 - val_loss: 0.0892\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0895\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0791 - val_loss: 0.0895\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0791 - val_loss: 0.0893\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0888\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.0886\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0888\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0885\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0777 - val_loss: 0.0887\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0885\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0882\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0884\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0779 - val_loss: 0.0887\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0879\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0771 - val_loss: 0.0880\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0881\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0764 - val_loss: 0.0877\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0767 - val_loss: 0.0883\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0875\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0882\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0878\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0878\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0876\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0760 - val_loss: 0.0875\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0869\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0870\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0872\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0762 - val_loss: 0.0871\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0763 - val_loss: 0.0871\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0869\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0869\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0756 - val_loss: 0.0867\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0752 - val_loss: 0.0864\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0753 - val_loss: 0.0869\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0864\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 1.8399 - val_loss: 1.6937\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.6574 - val_loss: 1.5024\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4694 - val_loss: 1.3148\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.2826 - val_loss: 1.1362\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.1084 - val_loss: 0.9672\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.9396 - val_loss: 0.8263\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.8205 - val_loss: 0.7331\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7307 - val_loss: 0.6673\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6734 - val_loss: 0.6172\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.5761\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.5764 - val_loss: 0.5401\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5390 - val_loss: 0.5083\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5127 - val_loss: 0.4801\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4783 - val_loss: 0.4547\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4530 - val_loss: 0.4324\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4319 - val_loss: 0.4121\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4094 - val_loss: 0.3939\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3947 - val_loss: 0.3764\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3803 - val_loss: 0.3605\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3628 - val_loss: 0.3466\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3545 - val_loss: 0.3353\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3441 - val_loss: 0.3255\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3346 - val_loss: 0.3167\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3244 - val_loss: 0.3096\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3195 - val_loss: 0.3032\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3124 - val_loss: 0.2976\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3024 - val_loss: 0.2927\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2995 - val_loss: 0.2876\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2948 - val_loss: 0.2830\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2838 - val_loss: 0.2783\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2843 - val_loss: 0.2751\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2817 - val_loss: 0.2710\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2743 - val_loss: 0.2676\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2717 - val_loss: 0.2644\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2680 - val_loss: 0.2617\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2647 - val_loss: 0.2588\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2602 - val_loss: 0.2563\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2550 - val_loss: 0.2538\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2530 - val_loss: 0.2511\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2524 - val_loss: 0.2495\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2496 - val_loss: 0.2461\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2440 - val_loss: 0.2445\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2450 - val_loss: 0.2423\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2386 - val_loss: 0.2399\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2355 - val_loss: 0.2375\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2342 - val_loss: 0.2366\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2323 - val_loss: 0.2350\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2314 - val_loss: 0.2332\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2278 - val_loss: 0.2314\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2286 - val_loss: 0.2291\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2236 - val_loss: 0.2278\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2202 - val_loss: 0.2263\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2211 - val_loss: 0.2247\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2188 - val_loss: 0.2225\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2164 - val_loss: 0.2215\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2147 - val_loss: 0.2203\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2111 - val_loss: 0.2184\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2092 - val_loss: 0.2166\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2078 - val_loss: 0.2150\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2077 - val_loss: 0.2143\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2057 - val_loss: 0.2120\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2034 - val_loss: 0.2116\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.2105\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1990 - val_loss: 0.2088\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.2082\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1967 - val_loss: 0.2062\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1945 - val_loss: 0.2048\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1939 - val_loss: 0.2035\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.2024\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1908 - val_loss: 0.2014\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1911 - val_loss: 0.2000\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1887 - val_loss: 0.1989\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1884 - val_loss: 0.1981\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1878 - val_loss: 0.1971\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1829 - val_loss: 0.1958\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.1949\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1808 - val_loss: 0.1935\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.1924\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.1920\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1784 - val_loss: 0.1911\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 0.1895\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1762 - val_loss: 0.1892\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1760 - val_loss: 0.1880\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.1873\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1716 - val_loss: 0.1863\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1730 - val_loss: 0.1849\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1699 - val_loss: 0.1837\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1730 - val_loss: 0.1842\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1727 - val_loss: 0.1823\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1681 - val_loss: 0.1822\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.1805\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.1808\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 0.1793\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1641 - val_loss: 0.1798\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1664 - val_loss: 0.1785\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1774\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1635 - val_loss: 0.1765\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1622 - val_loss: 0.1758\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1607 - val_loss: 0.1751\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1622 - val_loss: 0.1747\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1734\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1599 - val_loss: 0.1729\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1578 - val_loss: 0.1727\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1567 - val_loss: 0.1714\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1569 - val_loss: 0.1711\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1556 - val_loss: 0.1704\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.1699\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1558 - val_loss: 0.1697\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1550 - val_loss: 0.1684\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1542 - val_loss: 0.1679\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1680\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1515 - val_loss: 0.1669\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1503 - val_loss: 0.1673\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1521 - val_loss: 0.1666\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1512 - val_loss: 0.1657\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.1655\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1499 - val_loss: 0.1645\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1500 - val_loss: 0.1648\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 0.1646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.1639\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1488 - val_loss: 0.1630\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1632\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1482 - val_loss: 0.1624\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1623\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1610\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1617\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1604\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1441 - val_loss: 0.1608\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1600\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.1600\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1590\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1589\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1440 - val_loss: 0.1584\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1425 - val_loss: 0.1580\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1431 - val_loss: 0.1591\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1418 - val_loss: 0.1584\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1412 - val_loss: 0.1569\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1415 - val_loss: 0.1573\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.1572\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1561\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.1566\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1405 - val_loss: 0.1558\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1393 - val_loss: 0.1559\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1402 - val_loss: 0.1550\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1378 - val_loss: 0.1551\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1374 - val_loss: 0.1545\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1370 - val_loss: 0.1544\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1377 - val_loss: 0.1547\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1545\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1537\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1536\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1372 - val_loss: 0.1546\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1536\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 0.1531\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.1532\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1530\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1363 - val_loss: 0.1521\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1518\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1358 - val_loss: 0.1523\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 0.1513\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1340 - val_loss: 0.1513\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1332 - val_loss: 0.1516\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1331 - val_loss: 0.1510\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1506\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 0.1504\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.1508\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1506\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1501\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1494\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1322 - val_loss: 0.1506\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1320 - val_loss: 0.1496\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1487\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1324 - val_loss: 0.1503\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1487\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1490\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1316 - val_loss: 0.1484\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1327 - val_loss: 0.1487\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1480\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1482\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1296 - val_loss: 0.1476\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1311 - val_loss: 0.1478\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1478\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1296 - val_loss: 0.1479\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1472\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.1472\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1296 - val_loss: 0.1473\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.1466\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1466\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1293 - val_loss: 0.1465\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.1462\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1279 - val_loss: 0.1466\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1465\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1291 - val_loss: 0.1465\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1272 - val_loss: 0.1458\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1274 - val_loss: 0.1462\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.1467\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1283 - val_loss: 0.1458\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.1456\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1269 - val_loss: 0.1457\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1453\n",
      "Quantile: 0.8413447460685429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.8212 - val_loss: 2.5602\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.4811 - val_loss: 2.2237\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.1475 - val_loss: 1.9019\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.8380 - val_loss: 1.5963\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5399 - val_loss: 1.3204\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2798 - val_loss: 1.0863\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0493 - val_loss: 0.9049\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8796 - val_loss: 0.7672\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7394 - val_loss: 0.6592\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6444 - val_loss: 0.5753\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5591 - val_loss: 0.5128\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5008 - val_loss: 0.4658\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4506 - val_loss: 0.4286\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4163 - val_loss: 0.3975\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3863 - val_loss: 0.3726\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3607 - val_loss: 0.3524\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3447 - val_loss: 0.3362\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3236 - val_loss: 0.3214\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3137 - val_loss: 0.3080\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.2955\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2908 - val_loss: 0.2841\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.2736\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2705 - val_loss: 0.2639\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2626 - val_loss: 0.2551\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2555 - val_loss: 0.2472\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2462 - val_loss: 0.2401\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2391 - val_loss: 0.2335\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2318 - val_loss: 0.2281\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2279 - val_loss: 0.2232\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2221 - val_loss: 0.2181\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2189 - val_loss: 0.2138\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2141 - val_loss: 0.2096\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2097 - val_loss: 0.2059\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2070 - val_loss: 0.2025\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2019 - val_loss: 0.1994\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2008 - val_loss: 0.1967\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1977 - val_loss: 0.1939\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1956 - val_loss: 0.1916\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1912 - val_loss: 0.1892\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1880 - val_loss: 0.1874\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.1855\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1848 - val_loss: 0.1833\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1819 - val_loss: 0.1821\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1828 - val_loss: 0.1804\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.1790\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1780 - val_loss: 0.1776\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.1761\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1749\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1723 - val_loss: 0.1737\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.1719\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1686 - val_loss: 0.1706\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1668 - val_loss: 0.1695\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1649 - val_loss: 0.1680\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1646 - val_loss: 0.1666\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1621 - val_loss: 0.1653\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1617 - val_loss: 0.1649\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1632 - val_loss: 0.1630\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1592 - val_loss: 0.1619\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1609\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.1602\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1588\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1538 - val_loss: 0.1591\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1569\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1513 - val_loss: 0.1569\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1549\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1553\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1491 - val_loss: 0.1532\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1486 - val_loss: 0.1523\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1469 - val_loss: 0.1514\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1448 - val_loss: 0.1508\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1460 - val_loss: 0.1492\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1417 - val_loss: 0.1488\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1422 - val_loss: 0.1479\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1468\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1462\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1387 - val_loss: 0.1449\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1438\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1385 - val_loss: 0.1433\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1363 - val_loss: 0.1423\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1361 - val_loss: 0.1416\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1366 - val_loss: 0.1409\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1340 - val_loss: 0.1399\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1341 - val_loss: 0.1391\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.1390\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1369\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1369\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1308 - val_loss: 0.1364\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1352\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1284 - val_loss: 0.1339\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1350\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.1331\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1256 - val_loss: 0.1325\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1257 - val_loss: 0.1316\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1251 - val_loss: 0.1306\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1242 - val_loss: 0.1305\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 0.1292\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1219 - val_loss: 0.1287\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1229 - val_loss: 0.1282\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1208 - val_loss: 0.1277\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.1273\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1211 - val_loss: 0.1259\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1195 - val_loss: 0.1257\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1191 - val_loss: 0.1246\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.1244\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1237\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.1227\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1170 - val_loss: 0.1225\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1215\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1216\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1204\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1138 - val_loss: 0.1207\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.1196\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1192\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1107 - val_loss: 0.1183\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1106 - val_loss: 0.1184\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1103 - val_loss: 0.1179\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.1167\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1097 - val_loss: 0.1163\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.1162\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1073 - val_loss: 0.1153\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1073 - val_loss: 0.1155\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.1151\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1069 - val_loss: 0.1135\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1059 - val_loss: 0.1139\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1051 - val_loss: 0.1129\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1056 - val_loss: 0.1126\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1031 - val_loss: 0.1122\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.1112\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1108\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1037 - val_loss: 0.1102\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1021 - val_loss: 0.1094\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.1099\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1013 - val_loss: 0.1095\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1012 - val_loss: 0.1083\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1014 - val_loss: 0.1090\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1020 - val_loss: 0.1082\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0993 - val_loss: 0.1073\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.1072\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0998 - val_loss: 0.1070\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0984 - val_loss: 0.1062\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.1057\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0981 - val_loss: 0.1059\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0978 - val_loss: 0.1042\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0968 - val_loss: 0.1045\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.1038\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0966 - val_loss: 0.1041\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.1037\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.1038\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.1034\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.1028\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0939 - val_loss: 0.1022\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.1032\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0943 - val_loss: 0.1021\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1020\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.1011\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0921 - val_loss: 0.1010\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0924 - val_loss: 0.1008\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.1005\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0933 - val_loss: 0.1009\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0912 - val_loss: 0.1003\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0996\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0913 - val_loss: 0.0990\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0997\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0901 - val_loss: 0.0994\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0912 - val_loss: 0.0981\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0895 - val_loss: 0.0984\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0889 - val_loss: 0.0982\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0910 - val_loss: 0.0983\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0978\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0973\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0967\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0883 - val_loss: 0.0968\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0965\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0969\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0877 - val_loss: 0.0962\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0878 - val_loss: 0.0962\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0958\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0954\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0862 - val_loss: 0.0953\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0870 - val_loss: 0.0953\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0869 - val_loss: 0.0945\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0861 - val_loss: 0.0948\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0854 - val_loss: 0.0948\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0941\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0937\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0934\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0934\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0932\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0928\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0845 - val_loss: 0.0932\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0926\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0926\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0920\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0838 - val_loss: 0.0921\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0837 - val_loss: 0.0916\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0843 - val_loss: 0.0919\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0835 - val_loss: 0.0917\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0916\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0913\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0916\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.7340 - val_loss: 3.5032\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3739 - val_loss: 3.1333\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.0170 - val_loss: 2.7343\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.5932 - val_loss: 2.2967\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 2.1441 - val_loss: 1.8427\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.7077 - val_loss: 1.4368\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3231 - val_loss: 1.1000\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0173 - val_loss: 0.8391\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7612 - val_loss: 0.6363\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.5871 - val_loss: 0.4826\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4348 - val_loss: 0.3683\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3459 - val_loss: 0.2821\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2690 - val_loss: 0.2245\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2111 - val_loss: 0.1818\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.1524\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1526 - val_loss: 0.1325\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1348 - val_loss: 0.1192\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.1102\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.1035\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1027 - val_loss: 0.0979\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.0937\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0941 - val_loss: 0.0905\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.0880\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0893 - val_loss: 0.0858\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0837\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0819\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0805\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0789\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0776\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0762\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0750\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0738\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0728\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0718\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0709\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0701\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0690\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0683\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0690 - val_loss: 0.0675\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0668\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0660\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0653\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0645\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0637\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0629\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0641 - val_loss: 0.0621\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0625 - val_loss: 0.0613\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0618 - val_loss: 0.0606\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0607 - val_loss: 0.0593\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0586\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0579\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0572\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0567\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0572 - val_loss: 0.0562\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0563 - val_loss: 0.0558\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0562 - val_loss: 0.0551\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0546\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0540\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0540 - val_loss: 0.0537\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0532\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0527\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0522\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0521 - val_loss: 0.0516\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0512 - val_loss: 0.0511\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0515 - val_loss: 0.0507\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0501\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0497\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0493\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0490\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0485\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0482\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0475\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0473\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0471\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0468\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0464\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0461\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0459\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0455\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0454\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0451\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0448\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0448\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0447\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0442\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0438\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0436\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0419 - val_loss: 0.0434\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0431\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0429\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0412 - val_loss: 0.0427\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0426\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0424\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0421\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0418\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0418\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0415\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0413\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0411\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0409\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0408\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0408\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0405\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0404\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0403\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0402\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0401\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0396\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0396\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0394\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0393\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0361 - val_loss: 0.0391\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0388\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0391\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0389\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0385\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0387\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0385\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0384\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0346 - val_loss: 0.0383\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0382\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0380\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0377\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0378\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0377\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0374\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0374\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0374\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0372\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0374\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0373\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0369\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0370\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0365\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0366\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0367\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0365\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0364\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0361\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0308 - val_loss: 0.0359\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0361\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0360\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0360\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0358\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0357\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0354\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0356\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0356\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0351\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0349\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0351\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0347\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0349\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0289 - val_loss: 0.0349\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0350\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0346\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0347\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0346\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0345\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0345\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0343\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0343\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0342\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0340\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0338\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0279 - val_loss: 0.0340\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0339\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0337\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0336\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0337\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0333\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0332\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0330\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0332\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0330\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0332\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0326\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0326\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0329\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0329\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0327\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0326\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0327\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0324\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0254 - val_loss: 0.0324\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0322\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0320\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0320\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0321\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0317\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0316\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0318\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0317\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 13.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [01:32<04:37, 92.62s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.0709 - val_loss: 0.0505\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0388\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0320\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0292\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.0269\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0252\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0251\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0283 - val_loss: 0.0251\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0243\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0240 - val_loss: 0.0231\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0230 - val_loss: 0.0232\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0224\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0221\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0225\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0213\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0208\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0211\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0206\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0204\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0208\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0210\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0198\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0204\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0205\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0204\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0205\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0228\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 00037: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.5864 - val_loss: 0.3058\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2725 - val_loss: 0.1870\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1829 - val_loss: 0.1571\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1564 - val_loss: 0.1382\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1377 - val_loss: 0.1256\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1279 - val_loss: 0.1161\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1191 - val_loss: 0.1137\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1154 - val_loss: 0.1103\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1104 - val_loss: 0.1079\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1074 - val_loss: 0.1043\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1020 - val_loss: 0.0991\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0988 - val_loss: 0.0967\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0985 - val_loss: 0.0954\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0945 - val_loss: 0.0966\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.0916\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0915 - val_loss: 0.0894\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0882 - val_loss: 0.0892\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0874 - val_loss: 0.0864\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0851 - val_loss: 0.0885\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.0873\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0858 - val_loss: 0.0869\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0858\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0864\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0816 - val_loss: 0.0866\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0851\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0876\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0837\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0835\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0776 - val_loss: 0.0825\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0828\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0761 - val_loss: 0.0831\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0776 - val_loss: 0.0805\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0823\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0812\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0807\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0747 - val_loss: 0.0812\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0824\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0796\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0800\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0720 - val_loss: 0.0807\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0784\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0785\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0705 - val_loss: 0.0801\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0796\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0703 - val_loss: 0.0791\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0784\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0787\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0797\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0702 - val_loss: 0.0809\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0788\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0683 - val_loss: 0.0799\n",
      "Epoch 00051: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.2591 - val_loss: 0.5710\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4816 - val_loss: 0.3249\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3107 - val_loss: 0.2663\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2667 - val_loss: 0.2418\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2407 - val_loss: 0.2241\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2204 - val_loss: 0.2116\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2077 - val_loss: 0.2078\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2007 - val_loss: 0.1880\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1843 - val_loss: 0.1813\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1802 - val_loss: 0.1770\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.1701\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1627 - val_loss: 0.1651\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1589 - val_loss: 0.1612\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1559 - val_loss: 0.1557\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1508 - val_loss: 0.1536\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.1535\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1450 - val_loss: 0.1492\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1426 - val_loss: 0.1474\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1380 - val_loss: 0.1464\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1400 - val_loss: 0.1456\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1374 - val_loss: 0.1457\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1346 - val_loss: 0.1420\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1349 - val_loss: 0.1427\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1385\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1311 - val_loss: 0.1402\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 0.1393\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 0.1425\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1295 - val_loss: 0.1405\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1412\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.1368\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1267 - val_loss: 0.1352\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1252 - val_loss: 0.1343\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1362\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1343\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1351\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1351\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1207 - val_loss: 0.1322\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1196 - val_loss: 0.1330\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1226 - val_loss: 0.1324\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1195 - val_loss: 0.1309\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1193 - val_loss: 0.1336\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1331\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1171 - val_loss: 0.1335\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1332\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1209 - val_loss: 0.1342\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1187 - val_loss: 0.1367\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1182 - val_loss: 0.1320\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.1334\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1313\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1157 - val_loss: 0.1297\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1144 - val_loss: 0.1290\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1140 - val_loss: 0.1309\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1125 - val_loss: 0.1297\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1145 - val_loss: 0.1295\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1320\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1150 - val_loss: 0.1291\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1353\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1300\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1109 - val_loss: 0.1308\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1130 - val_loss: 0.1298\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1115 - val_loss: 0.1307\n",
      "Epoch 00061: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 16ms/step - loss: 2.8443 - val_loss: 1.0742\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.7611 - val_loss: 0.3878\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3557 - val_loss: 0.2678\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2589 - val_loss: 0.2158\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2102 - val_loss: 0.1939\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1872 - val_loss: 0.1803\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.1701\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1622 - val_loss: 0.1622\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1531 - val_loss: 0.1550\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1470 - val_loss: 0.1508\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1384 - val_loss: 0.1424\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1334 - val_loss: 0.1386\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1330\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1286\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1206 - val_loss: 0.1249\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1149 - val_loss: 0.1269\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1108 - val_loss: 0.1194\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1095 - val_loss: 0.1183\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1064 - val_loss: 0.1146\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.1127\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0983 - val_loss: 0.1089\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.1082\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0955 - val_loss: 0.1051\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0954 - val_loss: 0.1031\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0931 - val_loss: 0.1025\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.0997\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0909 - val_loss: 0.1012\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0925 - val_loss: 0.0989\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0885 - val_loss: 0.0975\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0880 - val_loss: 0.0988\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0957\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0837 - val_loss: 0.0940\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.0916\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0831 - val_loss: 0.0899\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0928\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0811 - val_loss: 0.0941\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0828 - val_loss: 0.0894\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0808 - val_loss: 0.0902\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0788 - val_loss: 0.0884\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0873\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0859\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0782 - val_loss: 0.0865\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0774 - val_loss: 0.0865\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0858\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0769 - val_loss: 0.0850\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0762 - val_loss: 0.0845\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0835\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0759 - val_loss: 0.0852\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0846\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0835\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0749 - val_loss: 0.0849\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0850\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0743 - val_loss: 0.0825\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0740 - val_loss: 0.0861\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0838\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0838\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0737 - val_loss: 0.0859\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0741 - val_loss: 0.0849\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0867\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0729 - val_loss: 0.0839\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0718 - val_loss: 0.0816\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0717 - val_loss: 0.0815\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0709 - val_loss: 0.0825\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0713 - val_loss: 0.0833\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0818\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0706 - val_loss: 0.0836\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0700 - val_loss: 0.0822\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0823\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0826\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0814\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0707 - val_loss: 0.0814\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0697 - val_loss: 0.0803\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0677 - val_loss: 0.0802\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0686 - val_loss: 0.0838\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0684 - val_loss: 0.0811\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0842\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0698 - val_loss: 0.0807\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0688 - val_loss: 0.0818\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0682 - val_loss: 0.0833\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0824\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0693 - val_loss: 0.0800\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0801\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0689 - val_loss: 0.0802\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0811\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0671 - val_loss: 0.0808\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0663 - val_loss: 0.0791\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0810\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0667 - val_loss: 0.0784\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0659 - val_loss: 0.0810\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0848\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0675 - val_loss: 0.0818\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0658 - val_loss: 0.0808\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0647 - val_loss: 0.0809\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0664 - val_loss: 0.0806\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0681 - val_loss: 0.0807\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0821\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0791\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0639 - val_loss: 0.0791\n",
      "Epoch 00098: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.6119 - val_loss: 0.3943\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2597 - val_loss: 0.0994\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0977 - val_loss: 0.0916\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.0808\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0721\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0665 - val_loss: 0.0656\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0612\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0542 - val_loss: 0.0571\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0540\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0511\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0453 - val_loss: 0.0488\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0478\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0458\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0450\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0433\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0426\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0419\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0405\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0398\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0395\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0396\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0388\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0387\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0376\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0362\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0369\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0380\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0356\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0349\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0351\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0355\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0341\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0330\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0333\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0323\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0325\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0318\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0326\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0316\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0311\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0299\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0301\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0299\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0291\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0290\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0295\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0285\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0207 - val_loss: 0.0292\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0282\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0281\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0281\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0276\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0272\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0267\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0272\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0293\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0197 - val_loss: 0.0253\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0252\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0265\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0254\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0250\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0245\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0240\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0254\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0243\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0243\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0253\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0236\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0239\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0241\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0241\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0233\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0250\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0236\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0262\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0240\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0228\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0224\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0239\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0228\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0229\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0228\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0231\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0225\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0217\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0233\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0222\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0229\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0217\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0222\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0210\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0229\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0222\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0212\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0237\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0220\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0211\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0224\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0213\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0209\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0217\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0218\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0221\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0234\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0208\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0205\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0206\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0208\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0222\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0199\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0202\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0224\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0214\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0221\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0222\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0208\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0217\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0216\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0216\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00124: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [02:15<02:35, 77.72s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 0.0716 - val_loss: 0.0430\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0329\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0262\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0225\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0216\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0291\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0214\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0245\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0229 - val_loss: 0.0199\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0198\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0207\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0202\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0194\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0194\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0190\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0187\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0205\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0185\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0213\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0202\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0188\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0197\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0185\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0174\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0228\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0189\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0187\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0183\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0242\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0188\n",
      "Epoch 00042: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.3328 - val_loss: 0.1539\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.1074\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.0971\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.0919\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0926 - val_loss: 0.1341\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.0963\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0915 - val_loss: 0.0905\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0862 - val_loss: 0.0880\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0858 - val_loss: 0.0920\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.0835 - val_loss: 0.0820\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0824 - val_loss: 0.0885\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0830 - val_loss: 0.0910\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0868 - val_loss: 0.0918\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0866 - val_loss: 0.0843\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0799 - val_loss: 0.0859\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0796 - val_loss: 0.0841\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0811 - val_loss: 0.0809\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0785 - val_loss: 0.0799\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0801 - val_loss: 0.0888\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0841 - val_loss: 0.0838\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0862\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0800 - val_loss: 0.0860\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0844\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0821 - val_loss: 0.0898\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0787 - val_loss: 0.0852\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0835 - val_loss: 0.0830\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0781 - val_loss: 0.0871\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0793 - val_loss: 0.0812\n",
      "Epoch 00029: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 9ms/step - loss: 0.8439 - val_loss: 0.2938\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.2644 - val_loss: 0.2112\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1959 - val_loss: 0.1779\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1701 - val_loss: 0.1570\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1565 - val_loss: 0.1625\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1484 - val_loss: 0.1652\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.159 - 0s 4ms/step - loss: 0.1533 - val_loss: 0.1501\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1431 - val_loss: 0.1488\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1418 - val_loss: 0.1386\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1372 - val_loss: 0.1508\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1417 - val_loss: 0.1383\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1397 - val_loss: 0.1497\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1413 - val_loss: 0.1363\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1355 - val_loss: 0.1357\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1340 - val_loss: 0.1395\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1406 - val_loss: 0.1629\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1462 - val_loss: 0.1325\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.1441\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1306 - val_loss: 0.1354\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1278 - val_loss: 0.1380\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1267 - val_loss: 0.1434\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1299\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1290 - val_loss: 0.1392\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1292 - val_loss: 0.1280\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1226 - val_loss: 0.1363\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1287 - val_loss: 0.1341\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1297 - val_loss: 0.1364\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1264 - val_loss: 0.1349\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1242 - val_loss: 0.1352\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.1365\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1228 - val_loss: 0.1351\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1348\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1225 - val_loss: 0.1515\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.1300\n",
      "Epoch 00034: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 1s 11ms/step - loss: 1.1093 - val_loss: 0.2506\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2157 - val_loss: 0.1675\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1243\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1210 - val_loss: 0.1291\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1139 - val_loss: 0.1045\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0987 - val_loss: 0.1025\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0992 - val_loss: 0.1107\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0989 - val_loss: 0.1034\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0889 - val_loss: 0.0944\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0971\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0923 - val_loss: 0.0967\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.0981\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0843\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0844 - val_loss: 0.0869\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0803 - val_loss: 0.0853\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0810 - val_loss: 0.0996\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0875 - val_loss: 0.0887\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0873\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0785 - val_loss: 0.0860\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0805 - val_loss: 0.0838\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0784 - val_loss: 0.0870\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0817\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0768 - val_loss: 0.0887\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0765 - val_loss: 0.1002\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0815\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0778 - val_loss: 0.0810\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0743 - val_loss: 0.0828\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0765 - val_loss: 0.0825\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0754 - val_loss: 0.0837\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0739 - val_loss: 0.0886\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0861\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0852 - val_loss: 0.0871\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0960\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0814 - val_loss: 0.0909\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0764 - val_loss: 0.0821\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0751 - val_loss: 0.0890\n",
      "Epoch 00037: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1.2627 - val_loss: 0.2264\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 0.0604\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0416\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0401 - val_loss: 0.0390\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0330\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0303\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0321\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0332\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0279\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0269\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0275\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0251\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0285\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0244\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0276\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0207 - val_loss: 0.0272\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0227\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0221 - val_loss: 0.0296\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0302\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0351\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0253 - val_loss: 0.0234\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0220\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0244\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0245\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0251\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0202\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0217\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0250\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0263\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0206\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0223\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0243\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0261\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0189 - val_loss: 0.0270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 15.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 15.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [02:42<01:02, 62.46s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.9572 - val_loss: 2.1989\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1257 - val_loss: 0.3626\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3293 - val_loss: 0.2357\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.1391\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1147 - val_loss: 0.0600\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0674 - val_loss: 0.0494\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0544\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0361\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0317\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0291\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0282\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0236\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0268 - val_loss: 0.0244\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0260\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0258\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0228\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0229\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0261 - val_loss: 0.0250\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0242 - val_loss: 0.0208\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0199\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0300\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0327\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0244 - val_loss: 0.0190\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0218\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0194\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0191\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0196\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0188 - val_loss: 0.0204\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0201\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0192\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0210\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0199\n",
      "Epoch 00033: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 3.6406 - val_loss: 1.7938\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2426 - val_loss: 0.4120\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.3062 - val_loss: 0.1519\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1499 - val_loss: 0.1006\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.0906\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0947 - val_loss: 0.0856\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0914 - val_loss: 0.0928\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.0891\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0884 - val_loss: 0.0815\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.0856\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0891 - val_loss: 0.0898\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0890 - val_loss: 0.0950\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0907 - val_loss: 0.0799\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.0846 - val_loss: 0.0792\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0861 - val_loss: 0.0838\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0834 - val_loss: 0.0800\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0803 - val_loss: 0.0777\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0812 - val_loss: 0.0880\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0854 - val_loss: 0.0924\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0860 - val_loss: 0.0806\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0821 - val_loss: 0.0851\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0808\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0826 - val_loss: 0.0802\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0778 - val_loss: 0.0852\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0807 - val_loss: 0.0793\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0832 - val_loss: 0.0832\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0853 - val_loss: 0.0785\n",
      "Epoch 00027: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3.4440 - val_loss: 0.6979\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4792 - val_loss: 0.1964\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1888 - val_loss: 0.1844\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1667 - val_loss: 0.1487\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.1539\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1376\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1407 - val_loss: 0.1392\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1408 - val_loss: 0.1953\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1616 - val_loss: 0.1349\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1416 - val_loss: 0.1652\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1411\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1406 - val_loss: 0.1359\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1395 - val_loss: 0.1327\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1378 - val_loss: 0.1430\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1379 - val_loss: 0.1345\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.1250\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1305 - val_loss: 0.1264\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1289 - val_loss: 0.1433\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1318 - val_loss: 0.1364\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1329 - val_loss: 0.1741\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.1327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1368 - val_loss: 0.1461\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1357 - val_loss: 0.1291\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1310 - val_loss: 0.1316\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1339 - val_loss: 0.1333\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1319 - val_loss: 0.1343\n",
      "Epoch 00026: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.2874 - val_loss: 0.4982\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4076 - val_loss: 0.2334\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.2056 - val_loss: 0.1350\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1336 - val_loss: 0.1495\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1249 - val_loss: 0.1025\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0961 - val_loss: 0.0871\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0916 - val_loss: 0.0935\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0937 - val_loss: 0.0933\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0892 - val_loss: 0.0843\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0859 - val_loss: 0.0918\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0882 - val_loss: 0.1179\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0955 - val_loss: 0.0838\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0854 - val_loss: 0.1013\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0905 - val_loss: 0.0967\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0859 - val_loss: 0.0812\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0787 - val_loss: 0.0819\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0818 - val_loss: 0.0827\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0804 - val_loss: 0.0832\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0831\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.1069\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0899 - val_loss: 0.0853\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0808 - val_loss: 0.0834\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0812 - val_loss: 0.0810\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0773 - val_loss: 0.0896\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0833 - val_loss: 0.0796\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0798 - val_loss: 0.0867\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0780 - val_loss: 0.0792\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0770 - val_loss: 0.0805\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0789 - val_loss: 0.0835\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0818 - val_loss: 0.0809\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0796 - val_loss: 0.0845\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0806 - val_loss: 0.0923\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0839 - val_loss: 0.0808\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0774 - val_loss: 0.0794\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0775 - val_loss: 0.0837\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0794\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0758 - val_loss: 0.0810\n",
      "Epoch 00037: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.3145 - val_loss: 2.2035\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4457 - val_loss: 0.7067\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.4063 - val_loss: 0.0733\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1151 - val_loss: 0.1156\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1179 - val_loss: 0.0496\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0519\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0363\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0320\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0303\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0956\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0565 - val_loss: 0.0226\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0235\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0254\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0199\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0229\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0224\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0213\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0254\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.0186 - val_loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 17.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [03:04<00:00, 46.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [03:04<00:00, 184.86s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [15:39<07:54, 237.15s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0931 - val_loss: 0.0898\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0891 - val_loss: 0.0858\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0848 - val_loss: 0.0817\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0808 - val_loss: 0.0776\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0766 - val_loss: 0.0735\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0726 - val_loss: 0.0691\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0683 - val_loss: 0.0647\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0642 - val_loss: 0.0608\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0606 - val_loss: 0.0579\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0569 - val_loss: 0.0562\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.0548\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0532\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0517 - val_loss: 0.0518\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0508 - val_loss: 0.0505\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0496 - val_loss: 0.0492\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0483 - val_loss: 0.0480\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0470 - val_loss: 0.0468\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.0457\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0452 - val_loss: 0.0447\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0427 - val_loss: 0.0427\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0417 - val_loss: 0.0421\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0414\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0405 - val_loss: 0.0406\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.0398\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0389 - val_loss: 0.0392\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0383 - val_loss: 0.0386\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.0378\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0372 - val_loss: 0.0371\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0352 - val_loss: 0.0353\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0349 - val_loss: 0.0346\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.0343\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0345 - val_loss: 0.0338\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.0332\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0333 - val_loss: 0.0329\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0333 - val_loss: 0.0326\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0329 - val_loss: 0.0323\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0327 - val_loss: 0.0321\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0316\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0320 - val_loss: 0.0312\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0319 - val_loss: 0.0311\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0306\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0314 - val_loss: 0.0304\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0310 - val_loss: 0.0301\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0309 - val_loss: 0.0299\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0305 - val_loss: 0.0297\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0302 - val_loss: 0.0296\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0300 - val_loss: 0.0295\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0300 - val_loss: 0.0294\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0296 - val_loss: 0.0295\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0294 - val_loss: 0.0287\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0292 - val_loss: 0.0287\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0289\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0286 - val_loss: 0.0282\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0288 - val_loss: 0.0279\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0275\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0273\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0274\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0279 - val_loss: 0.0272\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0271\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0270\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0274 - val_loss: 0.0271\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0268 - val_loss: 0.0269\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0270 - val_loss: 0.0266\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0265\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0265\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0262\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0265 - val_loss: 0.0263\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0262\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0258 - val_loss: 0.0260\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0258 - val_loss: 0.0259\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.0259\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0252 - val_loss: 0.0257\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0254 - val_loss: 0.0256\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0254\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0250 - val_loss: 0.0255\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0253\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0247 - val_loss: 0.0251\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0250\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0247 - val_loss: 0.0253\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0253\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0245 - val_loss: 0.0252\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0251\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0253\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0241 - val_loss: 0.0249\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0248\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0237 - val_loss: 0.0247\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0236 - val_loss: 0.0246\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0248\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0246\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0233 - val_loss: 0.0245\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0243\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0244\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0244\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0243\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0243\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0242\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0242\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0242\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0242\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0240\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0241\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0240\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0239\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0239\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0238\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0237\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0238\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0237\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0237\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0237\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0236\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0235\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0235\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0233\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0233\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0235\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0235\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0234\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0233\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0233\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0235\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0234\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0235\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0232\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0235\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0233\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0206 - val_loss: 0.0232\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0231\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0230\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0233\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0229\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0228\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0232\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0230\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0203 - val_loss: 0.0229\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0198 - val_loss: 0.0226\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0228\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0228\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0198 - val_loss: 0.0227\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0228\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0227\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0223\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0197 - val_loss: 0.0224\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0196 - val_loss: 0.0224\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0197 - val_loss: 0.0226\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0224\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0223\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0195 - val_loss: 0.0222\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0225\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0225\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0223\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0224\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0224\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0223\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0224\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0224\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0190 - val_loss: 0.0224\n",
      "Epoch 00199: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6805 - val_loss: 0.6609\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6339\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6272 - val_loss: 0.6069\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6015 - val_loss: 0.5795\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5721 - val_loss: 0.5528\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5464 - val_loss: 0.5270\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5207 - val_loss: 0.5026\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4970 - val_loss: 0.4796\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4747 - val_loss: 0.4565\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4483 - val_loss: 0.4326\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4267 - val_loss: 0.4077\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3998 - val_loss: 0.3816\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - val_loss: 0.3544\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3468 - val_loss: 0.3266\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3194 - val_loss: 0.3027\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3020 - val_loss: 0.2871\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2856 - val_loss: 0.2758\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2775 - val_loss: 0.2664\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2677 - val_loss: 0.2575\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2586 - val_loss: 0.2487\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2509 - val_loss: 0.2403\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2425 - val_loss: 0.2321\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2355 - val_loss: 0.2246\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2300 - val_loss: 0.2173\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2226 - val_loss: 0.2107\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2158 - val_loss: 0.2044\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2116 - val_loss: 0.1988\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2047 - val_loss: 0.1933\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2009 - val_loss: 0.1892\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1971 - val_loss: 0.1851\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1934 - val_loss: 0.1818\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1893 - val_loss: 0.1789\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1866 - val_loss: 0.1763\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1845 - val_loss: 0.1742\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1818 - val_loss: 0.1722\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1788 - val_loss: 0.1695\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1764 - val_loss: 0.1680\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1752 - val_loss: 0.1663\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1734 - val_loss: 0.1641\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1703 - val_loss: 0.1620\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1682 - val_loss: 0.1604\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1674 - val_loss: 0.1592\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1647 - val_loss: 0.1580\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1652 - val_loss: 0.1567\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1618 - val_loss: 0.1555\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1600 - val_loss: 0.1543\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1534\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1576 - val_loss: 0.1528\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1576 - val_loss: 0.1511\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1547 - val_loss: 0.1504\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.1482\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1518 - val_loss: 0.1476\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1508 - val_loss: 0.1464\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1514 - val_loss: 0.1455\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1490 - val_loss: 0.1445\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1486 - val_loss: 0.1436\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1470 - val_loss: 0.1432\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1452 - val_loss: 0.1424\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1425 - val_loss: 0.1420\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.1411\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1430 - val_loss: 0.1403\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1408 - val_loss: 0.1396\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1403 - val_loss: 0.1390\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1404 - val_loss: 0.1379\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1396 - val_loss: 0.1373\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1382 - val_loss: 0.1377\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1391 - val_loss: 0.1369\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1364 - val_loss: 0.1361\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1366 - val_loss: 0.1357\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1347 - val_loss: 0.1349\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1351 - val_loss: 0.1336\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1344 - val_loss: 0.1333\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1343 - val_loss: 0.1326\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1341 - val_loss: 0.1324\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1320 - val_loss: 0.1316\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1307 - val_loss: 0.1311\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1304 - val_loss: 0.1306\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1306 - val_loss: 0.1304\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1307 - val_loss: 0.1292\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1288 - val_loss: 0.1290\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1277 - val_loss: 0.1280\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1279 - val_loss: 0.1280\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1279 - val_loss: 0.1273\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1260 - val_loss: 0.1268\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1258 - val_loss: 0.1264\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1263 - val_loss: 0.1251\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1247 - val_loss: 0.1242\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1236 - val_loss: 0.1240\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1223 - val_loss: 0.1237\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1221 - val_loss: 0.1231\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1221 - val_loss: 0.1226\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1222 - val_loss: 0.1216\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1228 - val_loss: 0.1217\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1218 - val_loss: 0.1217\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1199 - val_loss: 0.1211\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1192 - val_loss: 0.1204\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1194 - val_loss: 0.1193\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1187 - val_loss: 0.1194\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1195 - val_loss: 0.1189\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1182 - val_loss: 0.1188\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1176 - val_loss: 0.1181\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1180 - val_loss: 0.1174\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1171 - val_loss: 0.1167\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1158 - val_loss: 0.1173\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1160 - val_loss: 0.1170\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1155 - val_loss: 0.1158\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1152 - val_loss: 0.1156\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1152 - val_loss: 0.1157\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1136 - val_loss: 0.1157\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1143 - val_loss: 0.1146\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1141 - val_loss: 0.1140\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1135 - val_loss: 0.1143\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1132 - val_loss: 0.1143\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1124 - val_loss: 0.1134\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1126 - val_loss: 0.1131\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1126 - val_loss: 0.1124\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1107 - val_loss: 0.1130\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1119 - val_loss: 0.1121\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1103 - val_loss: 0.1123\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1106 - val_loss: 0.1119\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1105 - val_loss: 0.1113\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1105 - val_loss: 0.1115\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1101 - val_loss: 0.1110\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1093 - val_loss: 0.1110\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1080 - val_loss: 0.1104\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1106\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1085 - val_loss: 0.1101\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1074 - val_loss: 0.1096\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1082 - val_loss: 0.1094\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1070 - val_loss: 0.1089\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1078 - val_loss: 0.1087\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1058 - val_loss: 0.1085\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1065 - val_loss: 0.1083\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1055 - val_loss: 0.1082\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1061 - val_loss: 0.1080\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1052 - val_loss: 0.1077\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1045 - val_loss: 0.1074\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1040 - val_loss: 0.1072\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1033 - val_loss: 0.1073\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1033 - val_loss: 0.1071\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1044 - val_loss: 0.1070\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1040 - val_loss: 0.1065\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1031 - val_loss: 0.1065\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1026 - val_loss: 0.1060\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1036 - val_loss: 0.1061\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1024 - val_loss: 0.1060\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1014 - val_loss: 0.1055\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1033 - val_loss: 0.1057\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1020 - val_loss: 0.1057\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1011 - val_loss: 0.1048\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1019 - val_loss: 0.1042\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1006 - val_loss: 0.1043\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1016 - val_loss: 0.1040\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1012 - val_loss: 0.1041\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0999 - val_loss: 0.1044\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1001 - val_loss: 0.1040\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.1038\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.1033\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0999 - val_loss: 0.1036\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0988 - val_loss: 0.1035\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.1031\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0976 - val_loss: 0.1033\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0990 - val_loss: 0.1027\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0991 - val_loss: 0.1023\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0976 - val_loss: 0.1023\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0974 - val_loss: 0.1027\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1022\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0973 - val_loss: 0.1016\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0971 - val_loss: 0.1019\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0959 - val_loss: 0.1018\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0968 - val_loss: 0.1012\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0960 - val_loss: 0.1012\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0960 - val_loss: 0.1012\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0954 - val_loss: 0.1014\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0965 - val_loss: 0.1012\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0951 - val_loss: 0.1011\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0955 - val_loss: 0.1007\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.1005\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0948 - val_loss: 0.1003\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0947 - val_loss: 0.1001\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0951 - val_loss: 0.0999\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0950 - val_loss: 0.0997\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0941 - val_loss: 0.0996\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0945 - val_loss: 0.0997\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0944 - val_loss: 0.0996\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.0992\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0939 - val_loss: 0.0995\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0938 - val_loss: 0.0994\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0925 - val_loss: 0.0987\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0932 - val_loss: 0.0985\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0930 - val_loss: 0.0987\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0922 - val_loss: 0.0986\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0926 - val_loss: 0.0983\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0914 - val_loss: 0.0982\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0914 - val_loss: 0.0978\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0914 - val_loss: 0.0981\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0918 - val_loss: 0.0977\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0921 - val_loss: 0.0979\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.7705 - val_loss: 1.6762\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6732 - val_loss: 1.5808\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5804 - val_loss: 1.4885\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 1.4830 - val_loss: 1.3986\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4036 - val_loss: 1.3101\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.3140 - val_loss: 1.2243\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2345 - val_loss: 1.1399\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1468 - val_loss: 1.0554\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0674 - val_loss: 0.9700\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9829 - val_loss: 0.8857\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8986 - val_loss: 0.8048\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8255 - val_loss: 0.7355\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7635 - val_loss: 0.6812\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7100 - val_loss: 0.6364\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6668 - val_loss: 0.5986\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.6247 - val_loss: 0.5674\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5937 - val_loss: 0.5391\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5694 - val_loss: 0.5140\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5422 - val_loss: 0.4918\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5156 - val_loss: 0.4719\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4905 - val_loss: 0.4552\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4760 - val_loss: 0.4405\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4562 - val_loss: 0.4276\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4398 - val_loss: 0.4156\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4257 - val_loss: 0.4039\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4166 - val_loss: 0.3929\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4023 - val_loss: 0.3835\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3944 - val_loss: 0.3745\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3853 - val_loss: 0.3664\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3769 - val_loss: 0.3597\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - val_loss: 0.3531\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3654 - val_loss: 0.3466\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3547 - val_loss: 0.3412\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3507 - val_loss: 0.3362\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3434 - val_loss: 0.3308\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3386 - val_loss: 0.3263\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3296 - val_loss: 0.3216\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3283 - val_loss: 0.3172\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3244 - val_loss: 0.3138\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3204 - val_loss: 0.3104\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3170 - val_loss: 0.3064\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3093 - val_loss: 0.3023\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3072 - val_loss: 0.2993\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3025 - val_loss: 0.2963\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3023 - val_loss: 0.2937\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2981 - val_loss: 0.2908\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2978 - val_loss: 0.2879\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2941 - val_loss: 0.2851\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2897 - val_loss: 0.2830\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2858 - val_loss: 0.2810\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2866 - val_loss: 0.2795\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2826 - val_loss: 0.2775\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2808 - val_loss: 0.2745\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2759 - val_loss: 0.2724\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2759 - val_loss: 0.2706\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2761 - val_loss: 0.2693\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2741 - val_loss: 0.2670\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2709 - val_loss: 0.2655\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2691 - val_loss: 0.2634\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2660 - val_loss: 0.2618\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2670 - val_loss: 0.2600\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2644 - val_loss: 0.2584\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2616 - val_loss: 0.2573\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2589 - val_loss: 0.2568\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2595 - val_loss: 0.2552\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2583 - val_loss: 0.2529\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2551 - val_loss: 0.2514\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2536 - val_loss: 0.2496\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2506 - val_loss: 0.2491\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2493 - val_loss: 0.2481\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2474 - val_loss: 0.2466\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2480 - val_loss: 0.2448\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2451 - val_loss: 0.2437\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2453 - val_loss: 0.2426\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2444 - val_loss: 0.2418\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2428 - val_loss: 0.2408\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2407 - val_loss: 0.2397\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2414 - val_loss: 0.2382\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2382 - val_loss: 0.2382\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2365 - val_loss: 0.2368\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2375 - val_loss: 0.2355\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.2349\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2353 - val_loss: 0.2346\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2308 - val_loss: 0.2326\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2327 - val_loss: 0.2318\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2323 - val_loss: 0.2308\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2304 - val_loss: 0.2300\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2279 - val_loss: 0.2288\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2277 - val_loss: 0.2286\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2254 - val_loss: 0.2272\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2276 - val_loss: 0.2259\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2273 - val_loss: 0.2256\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2263 - val_loss: 0.2248\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2206 - val_loss: 0.2242\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2218 - val_loss: 0.2233\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2195 - val_loss: 0.2220\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2193 - val_loss: 0.2213\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2184 - val_loss: 0.2211\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2188 - val_loss: 0.2197\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2163 - val_loss: 0.2194\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2170 - val_loss: 0.2182\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2124 - val_loss: 0.2173\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2137 - val_loss: 0.2168\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2114 - val_loss: 0.2162\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2124 - val_loss: 0.2159\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2105 - val_loss: 0.2146\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2125 - val_loss: 0.2142\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2101 - val_loss: 0.2136\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2091 - val_loss: 0.2125\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2096 - val_loss: 0.2115\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2064 - val_loss: 0.2113\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2068 - val_loss: 0.2105\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2043 - val_loss: 0.2093\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2056 - val_loss: 0.2084\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2061 - val_loss: 0.2083\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2033 - val_loss: 0.2081\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2028 - val_loss: 0.2071\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2013 - val_loss: 0.2064\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2015 - val_loss: 0.2058\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2003 - val_loss: 0.2050\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1994 - val_loss: 0.2046\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1980 - val_loss: 0.2041\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1956 - val_loss: 0.2029\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1983 - val_loss: 0.2023\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1947 - val_loss: 0.2018\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1949 - val_loss: 0.2014\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1927 - val_loss: 0.2008\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1971 - val_loss: 0.2004\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1922 - val_loss: 0.1997\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1949 - val_loss: 0.1993\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1932 - val_loss: 0.1981\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1897 - val_loss: 0.1976\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1903 - val_loss: 0.1971\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1911 - val_loss: 0.1970\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1885 - val_loss: 0.1960\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1899 - val_loss: 0.1957\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1877 - val_loss: 0.1954\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1872 - val_loss: 0.1950\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1857 - val_loss: 0.1941\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1849 - val_loss: 0.1935\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1859 - val_loss: 0.1930\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1842 - val_loss: 0.1923\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1856 - val_loss: 0.1919\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1830 - val_loss: 0.1915\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1833 - val_loss: 0.1905\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1826 - val_loss: 0.1900\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1825 - val_loss: 0.1895\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1819 - val_loss: 0.1884\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1792 - val_loss: 0.1880\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1815 - val_loss: 0.1875\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1763 - val_loss: 0.1868\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1781 - val_loss: 0.1862\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1783 - val_loss: 0.1865\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1752 - val_loss: 0.1856\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1777 - val_loss: 0.1847\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1752 - val_loss: 0.1848\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1775 - val_loss: 0.1832\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1744 - val_loss: 0.1828\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1757 - val_loss: 0.1832\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1752 - val_loss: 0.1824\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1742 - val_loss: 0.1821\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1729 - val_loss: 0.1822\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1737 - val_loss: 0.1813\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1712 - val_loss: 0.1811\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1714 - val_loss: 0.1804\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1709 - val_loss: 0.1800\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1688 - val_loss: 0.1792\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1679 - val_loss: 0.1789\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1684 - val_loss: 0.1783\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1703 - val_loss: 0.1775\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1688 - val_loss: 0.1776\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1684 - val_loss: 0.1775\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1677 - val_loss: 0.1770\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1656 - val_loss: 0.1766\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1663 - val_loss: 0.1760\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1666 - val_loss: 0.1757\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1666 - val_loss: 0.1745\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1664 - val_loss: 0.1743\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1641 - val_loss: 0.1741\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1663 - val_loss: 0.1732\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1630 - val_loss: 0.1726\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1637 - val_loss: 0.1728\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1624 - val_loss: 0.1720\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1719\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1616 - val_loss: 0.1714\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1619 - val_loss: 0.1710\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1607 - val_loss: 0.1710\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1611 - val_loss: 0.1704\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1603 - val_loss: 0.1702\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1589 - val_loss: 0.1700\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1604 - val_loss: 0.1698\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1579 - val_loss: 0.1695\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1581 - val_loss: 0.1687\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1573 - val_loss: 0.1689\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1578 - val_loss: 0.1687\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1588 - val_loss: 0.1677\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1589 - val_loss: 0.1675\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1566 - val_loss: 0.1672\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1566 - val_loss: 0.1668\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1554 - val_loss: 0.1666\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 2.8971 - val_loss: 2.7760\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7429 - val_loss: 2.6245\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.5881 - val_loss: 2.4718\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.4307 - val_loss: 2.3171\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2732 - val_loss: 2.1590\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.1181 - val_loss: 1.9982\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.9679 - val_loss: 1.8364\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8002 - val_loss: 1.6756\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6392 - val_loss: 1.5211\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4924 - val_loss: 1.3727\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.3449 - val_loss: 1.2392\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2181 - val_loss: 1.1170\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.0909 - val_loss: 1.0099\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9932 - val_loss: 0.9143\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9034 - val_loss: 0.8289\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8168 - val_loss: 0.7557\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.7413 - val_loss: 0.6933\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.6387\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.5928\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5850 - val_loss: 0.5536\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5494 - val_loss: 0.5193\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5162 - val_loss: 0.4904\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4899 - val_loss: 0.4666\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4647 - val_loss: 0.4460\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4434 - val_loss: 0.4279\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4243 - val_loss: 0.4120\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4100 - val_loss: 0.3980\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3966 - val_loss: 0.3852\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - val_loss: 0.3731\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - val_loss: 0.3628\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3608 - val_loss: 0.3531\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3516 - val_loss: 0.3444\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3441 - val_loss: 0.3362\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3375 - val_loss: 0.3284\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3274 - val_loss: 0.3215\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3211 - val_loss: 0.3145\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3112 - val_loss: 0.3077\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3086 - val_loss: 0.3015\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3006 - val_loss: 0.2958\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2940 - val_loss: 0.2904\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2888 - val_loss: 0.2853\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2843 - val_loss: 0.2805\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2787 - val_loss: 0.2755\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2754 - val_loss: 0.2707\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2665 - val_loss: 0.2663\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2622 - val_loss: 0.2623\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2583 - val_loss: 0.2584\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2562 - val_loss: 0.2548\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2510 - val_loss: 0.2515\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2503 - val_loss: 0.2478\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2428 - val_loss: 0.2447\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2401 - val_loss: 0.2417\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2389 - val_loss: 0.2389\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2335 - val_loss: 0.2360\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2332 - val_loss: 0.2331\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2302 - val_loss: 0.2305\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2281 - val_loss: 0.2281\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2223 - val_loss: 0.2257\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2228 - val_loss: 0.2232\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2181 - val_loss: 0.2209\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2167 - val_loss: 0.2188\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2123 - val_loss: 0.2170\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2125 - val_loss: 0.2154\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2100 - val_loss: 0.2135\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2077 - val_loss: 0.2118\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2061 - val_loss: 0.2101\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2054 - val_loss: 0.2084\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2013 - val_loss: 0.2066\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2005 - val_loss: 0.2050\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1985 - val_loss: 0.2038\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1974 - val_loss: 0.2023\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1954 - val_loss: 0.2009\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1943 - val_loss: 0.1996\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1928 - val_loss: 0.1979\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1924 - val_loss: 0.1966\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1877 - val_loss: 0.1954\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1879 - val_loss: 0.1940\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1867 - val_loss: 0.1926\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1890 - val_loss: 0.1915\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1843 - val_loss: 0.1902\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1828 - val_loss: 0.1890\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1830 - val_loss: 0.1881\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1811 - val_loss: 0.1870\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1803 - val_loss: 0.1862\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1790 - val_loss: 0.1853\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1771 - val_loss: 0.1843\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1750 - val_loss: 0.1835\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1770 - val_loss: 0.1824\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1740 - val_loss: 0.1815\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1727 - val_loss: 0.1807\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1714 - val_loss: 0.1802\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1716 - val_loss: 0.1795\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.1786\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1700 - val_loss: 0.1776\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1707 - val_loss: 0.1772\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1667 - val_loss: 0.1762\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1669 - val_loss: 0.1750\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1667 - val_loss: 0.1746\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1660 - val_loss: 0.1737\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1646 - val_loss: 0.1733\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1654 - val_loss: 0.1727\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1720\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1640 - val_loss: 0.1710\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1596 - val_loss: 0.1703\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1609 - val_loss: 0.1689\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1617 - val_loss: 0.1683\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1612 - val_loss: 0.1677\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1577 - val_loss: 0.1672\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1565 - val_loss: 0.1664\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1567 - val_loss: 0.1659\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1567 - val_loss: 0.1651\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1556 - val_loss: 0.1646\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1548 - val_loss: 0.1643\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1552 - val_loss: 0.1637\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.1625\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1539 - val_loss: 0.1618\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1535 - val_loss: 0.1612\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1524 - val_loss: 0.1605\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1511 - val_loss: 0.1600\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1523 - val_loss: 0.1596\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1507 - val_loss: 0.1591\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1484 - val_loss: 0.1590\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1475 - val_loss: 0.1589\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1486 - val_loss: 0.1583\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1480 - val_loss: 0.1579\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1475 - val_loss: 0.1568\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1455 - val_loss: 0.1564\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1451 - val_loss: 0.1560\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1455 - val_loss: 0.1550\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1453 - val_loss: 0.1544\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1443 - val_loss: 0.1537\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1437 - val_loss: 0.1535\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1428 - val_loss: 0.1527\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.1523\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1429 - val_loss: 0.1520\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1439 - val_loss: 0.1513\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1411 - val_loss: 0.1505\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1404 - val_loss: 0.1499\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1403 - val_loss: 0.1495\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1410 - val_loss: 0.1492\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1399 - val_loss: 0.1492\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1399 - val_loss: 0.1482\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1388 - val_loss: 0.1480\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1367 - val_loss: 0.1473\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1367 - val_loss: 0.1468\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1369 - val_loss: 0.1465\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1369 - val_loss: 0.1460\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1356 - val_loss: 0.1453\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1351 - val_loss: 0.1449\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1342 - val_loss: 0.1449\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1350 - val_loss: 0.1445\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1334 - val_loss: 0.1438\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1322 - val_loss: 0.1430\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1335 - val_loss: 0.1428\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.1425\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1309 - val_loss: 0.1424\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1302 - val_loss: 0.1419\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1317 - val_loss: 0.1414\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1307 - val_loss: 0.1408\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1303 - val_loss: 0.1398\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1289 - val_loss: 0.1397\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1290 - val_loss: 0.1396\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1290 - val_loss: 0.1391\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1291 - val_loss: 0.1387\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1284 - val_loss: 0.1383\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1261 - val_loss: 0.1377\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1281 - val_loss: 0.1374\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1283 - val_loss: 0.1373\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1278 - val_loss: 0.1375\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1272 - val_loss: 0.1370\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1267 - val_loss: 0.1363\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1242 - val_loss: 0.1359\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1241 - val_loss: 0.1356\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1247 - val_loss: 0.1354\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1248 - val_loss: 0.1353\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1239 - val_loss: 0.1346\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1216 - val_loss: 0.1345\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1231 - val_loss: 0.1338\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1243 - val_loss: 0.1338\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1225 - val_loss: 0.1335\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1230 - val_loss: 0.1327\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1223 - val_loss: 0.1327\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1207 - val_loss: 0.1323\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1206 - val_loss: 0.1320\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1212 - val_loss: 0.1316\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1200 - val_loss: 0.1316\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1194 - val_loss: 0.1310\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1196 - val_loss: 0.1308\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1203 - val_loss: 0.1306\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1195 - val_loss: 0.1307\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1183 - val_loss: 0.1302\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1169 - val_loss: 0.1298\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1178 - val_loss: 0.1292\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1168 - val_loss: 0.1288\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1170 - val_loss: 0.1288\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1176 - val_loss: 0.1285\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1168 - val_loss: 0.1275\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1155 - val_loss: 0.1273\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1152 - val_loss: 0.1275\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1156 - val_loss: 0.1272\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 3.6527 - val_loss: 3.4969\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3.4644 - val_loss: 3.3130\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3.2701 - val_loss: 3.1277\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 3.0884 - val_loss: 2.9381\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.9133 - val_loss: 2.7418\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.7003 - val_loss: 2.5363\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.5023 - val_loss: 2.3233\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2946 - val_loss: 2.1057\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2.0811 - val_loss: 1.8865\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8614 - val_loss: 1.6693\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.6572 - val_loss: 1.4564\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.4416 - val_loss: 1.2591\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 1.2493 - val_loss: 1.0793\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0774 - val_loss: 0.9185\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9066 - val_loss: 0.7768\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7721 - val_loss: 0.6544\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6450 - val_loss: 0.5521\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5569 - val_loss: 0.4675\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4739 - val_loss: 0.3979\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4017 - val_loss: 0.3391\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3451 - val_loss: 0.2919\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2976 - val_loss: 0.2541\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.2240\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2363 - val_loss: 0.1993\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2046 - val_loss: 0.1794\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1868 - val_loss: 0.1640\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1651 - val_loss: 0.1514\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1527 - val_loss: 0.1410\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1420 - val_loss: 0.1326\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1359 - val_loss: 0.1255\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1229 - val_loss: 0.1195\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1203 - val_loss: 0.1144\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1118 - val_loss: 0.1097\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1071 - val_loss: 0.1059\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1009 - val_loss: 0.1024\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0956 - val_loss: 0.0993\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0987 - val_loss: 0.0965\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0948 - val_loss: 0.0942\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0898\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0879\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0863 - val_loss: 0.0863\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0851 - val_loss: 0.0848\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0835 - val_loss: 0.0835\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0795 - val_loss: 0.0824\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0814 - val_loss: 0.0812\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0796 - val_loss: 0.0800\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0781 - val_loss: 0.0788\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0797 - val_loss: 0.0780\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0776 - val_loss: 0.0771\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0759 - val_loss: 0.0764\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0759 - val_loss: 0.0757\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0749 - val_loss: 0.0751\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0742 - val_loss: 0.0744\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0758 - val_loss: 0.0738\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0734 - val_loss: 0.0732\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0738 - val_loss: 0.0718\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0714 - val_loss: 0.0713\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0707\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0698 - val_loss: 0.0701\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0719 - val_loss: 0.0695\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0702 - val_loss: 0.0690\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0692 - val_loss: 0.0685\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0690 - val_loss: 0.0681\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.0677\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0670 - val_loss: 0.0672\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0687 - val_loss: 0.0668\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0680 - val_loss: 0.0664\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0674 - val_loss: 0.0660\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0671 - val_loss: 0.0656\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0662 - val_loss: 0.0652\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0664 - val_loss: 0.0648\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0660 - val_loss: 0.0645\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0651 - val_loss: 0.0641\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0657 - val_loss: 0.0638\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0645 - val_loss: 0.0634\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0637 - val_loss: 0.0631\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0641 - val_loss: 0.0628\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0635 - val_loss: 0.0625\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0634 - val_loss: 0.0622\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0633 - val_loss: 0.0619\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0624 - val_loss: 0.0616\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0620 - val_loss: 0.0613\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0617 - val_loss: 0.0610\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0624 - val_loss: 0.0607\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0621 - val_loss: 0.0604\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0604 - val_loss: 0.0601\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0613 - val_loss: 0.0597\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0604 - val_loss: 0.0595\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0602 - val_loss: 0.0591\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0590 - val_loss: 0.0587\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0584 - val_loss: 0.0584\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0595 - val_loss: 0.0581\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0589 - val_loss: 0.0578\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0582 - val_loss: 0.0575\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0585 - val_loss: 0.0572\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0578 - val_loss: 0.0571\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0579 - val_loss: 0.0568\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0571 - val_loss: 0.0565\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0578 - val_loss: 0.0563\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0566 - val_loss: 0.0561\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0560 - val_loss: 0.0559\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0557\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0552 - val_loss: 0.0555\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0550 - val_loss: 0.0553\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0553 - val_loss: 0.0550\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0552 - val_loss: 0.0548\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0546\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0545 - val_loss: 0.0544\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0544 - val_loss: 0.0541\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0540 - val_loss: 0.0539\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0539 - val_loss: 0.0537\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0534 - val_loss: 0.0535\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0537 - val_loss: 0.0532\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0528 - val_loss: 0.0530\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.0528\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0528 - val_loss: 0.0526\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0516 - val_loss: 0.0524\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0529 - val_loss: 0.0522\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0511 - val_loss: 0.0520\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0513 - val_loss: 0.0519\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0513 - val_loss: 0.0517\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0509 - val_loss: 0.0516\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0515 - val_loss: 0.0514\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.0511\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0505 - val_loss: 0.0510\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0504 - val_loss: 0.0509\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0503 - val_loss: 0.0507\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.0506\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0498 - val_loss: 0.0504\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0497 - val_loss: 0.0503\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0490 - val_loss: 0.0501\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0487 - val_loss: 0.0500\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0487 - val_loss: 0.0500\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0479 - val_loss: 0.0498\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0483 - val_loss: 0.0496\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0495\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0476 - val_loss: 0.0494\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.0492\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0476 - val_loss: 0.0492\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.0490\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.0488\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0467 - val_loss: 0.0486\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0463 - val_loss: 0.0484\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.0480\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0458 - val_loss: 0.0479\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0462 - val_loss: 0.0479\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.0478\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0457 - val_loss: 0.0477\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0475\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0460 - val_loss: 0.0475\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0448 - val_loss: 0.0473\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0449 - val_loss: 0.0471\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0444 - val_loss: 0.0468\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0450 - val_loss: 0.0467\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0466\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0465\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0440 - val_loss: 0.0465\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0446 - val_loss: 0.0463\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0459\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0442 - val_loss: 0.0459\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0433 - val_loss: 0.0458\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0429 - val_loss: 0.0457\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0456\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0425 - val_loss: 0.0455\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0423 - val_loss: 0.0454\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0435 - val_loss: 0.0451\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0428 - val_loss: 0.0451\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0423 - val_loss: 0.0450\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0448\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0417 - val_loss: 0.0448\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0419 - val_loss: 0.0448\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.043 - 0s 6ms/step - loss: 0.0424 - val_loss: 0.0447\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0417 - val_loss: 0.0446\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0445\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0443\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0412 - val_loss: 0.0441\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0409 - val_loss: 0.0441\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0441\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0408 - val_loss: 0.0441\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0441\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0407 - val_loss: 0.0440\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0438\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0436\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0400 - val_loss: 0.0436\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0400 - val_loss: 0.0435\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0434\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0399 - val_loss: 0.0433\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0433\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0395 - val_loss: 0.0433\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0398 - val_loss: 0.0433\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0394 - val_loss: 0.0432\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0395 - val_loss: 0.0428\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0392 - val_loss: 0.0427\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0394 - val_loss: 0.0425\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0426\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0424\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0387 - val_loss: 0.0420\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0382 - val_loss: 0.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 16.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 15.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [01:18<03:54, 78.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0817 - val_loss: 0.0551\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0532 - val_loss: 0.0431\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0436 - val_loss: 0.0383\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0370 - val_loss: 0.0339\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0336 - val_loss: 0.0321\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0316 - val_loss: 0.0298\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.0292\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0274 - val_loss: 0.0277\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0266\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0253 - val_loss: 0.0258\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0255\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0236 - val_loss: 0.0251\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0236 - val_loss: 0.0260\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0245\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0232 - val_loss: 0.0252\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0224 - val_loss: 0.0229\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0246\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0237\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0217 - val_loss: 0.0235\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0233\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0228\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0229\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0204 - val_loss: 0.0234\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0217\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0224\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0199 - val_loss: 0.0212\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0226\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0188 - val_loss: 0.0213\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0218\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0214\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0222\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0216\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0233\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0216\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0212\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0210\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0213\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0211\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0171 - val_loss: 0.0217\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0179 - val_loss: 0.0228\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 00047: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 0.6229 - val_loss: 0.3905\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3526 - val_loss: 0.2845\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2624 - val_loss: 0.2123\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2100 - val_loss: 0.1727\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1820 - val_loss: 0.1624\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1646 - val_loss: 0.1480\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1546 - val_loss: 0.1423\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1462 - val_loss: 0.1328\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1391 - val_loss: 0.1289\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1304 - val_loss: 0.1241\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1253 - val_loss: 0.1202\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1228 - val_loss: 0.1169\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1172 - val_loss: 0.1150\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1163 - val_loss: 0.1137\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1134 - val_loss: 0.1118\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1089 - val_loss: 0.1072\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1078 - val_loss: 0.1058\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1044 - val_loss: 0.1062\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1007 - val_loss: 0.1030\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1003 - val_loss: 0.1033\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1008 - val_loss: 0.1023\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.1009\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0973\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0950 - val_loss: 0.0989\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0926 - val_loss: 0.0941\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0910 - val_loss: 0.0969\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0919 - val_loss: 0.0933\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0913 - val_loss: 0.0921\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0912 - val_loss: 0.0945\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0920 - val_loss: 0.0947\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0891 - val_loss: 0.0922\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0878 - val_loss: 0.0913\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0860 - val_loss: 0.0897\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0851 - val_loss: 0.0905\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0849 - val_loss: 0.0911\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0858 - val_loss: 0.0882\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0829 - val_loss: 0.0883\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0828 - val_loss: 0.0876\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0814 - val_loss: 0.0867\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.0873\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0818 - val_loss: 0.0882\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0809 - val_loss: 0.0867\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0800 - val_loss: 0.0884\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0814 - val_loss: 0.0867\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0869\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0801 - val_loss: 0.0863\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0780 - val_loss: 0.0876\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0802 - val_loss: 0.0849\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0771 - val_loss: 0.0867\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0785 - val_loss: 0.0864\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0777 - val_loss: 0.0871\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0771 - val_loss: 0.0835\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0758 - val_loss: 0.0858\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0763 - val_loss: 0.0854\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0761 - val_loss: 0.0850\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0766 - val_loss: 0.0863\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0774 - val_loss: 0.0860\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0774 - val_loss: 0.0857\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0769 - val_loss: 0.0856\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0748 - val_loss: 0.0849\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0750 - val_loss: 0.0862\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0753 - val_loss: 0.0852\n",
      "Epoch 00062: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 1s 16ms/step - loss: 1.6756 - val_loss: 1.0046\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8688 - val_loss: 0.6009\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5749 - val_loss: 0.4620\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4490 - val_loss: 0.3797\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3694 - val_loss: 0.3207\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3305 - val_loss: 0.2899\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.2974 - val_loss: 0.2674\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2782 - val_loss: 0.2519\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2589 - val_loss: 0.2396\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2454 - val_loss: 0.2300\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2353 - val_loss: 0.2216\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2266 - val_loss: 0.2193\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2223 - val_loss: 0.2102\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2119 - val_loss: 0.2047\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2048 - val_loss: 0.1984\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1996 - val_loss: 0.1937\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1935 - val_loss: 0.1906\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1895 - val_loss: 0.1855\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1840 - val_loss: 0.1831\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1801 - val_loss: 0.1773\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1761 - val_loss: 0.1755\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1728 - val_loss: 0.1706\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1695 - val_loss: 0.1692\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1653 - val_loss: 0.1684\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1642 - val_loss: 0.1655\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1599 - val_loss: 0.1614\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1615 - val_loss: 0.1630\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1583 - val_loss: 0.1587\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1536 - val_loss: 0.1572\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1532 - val_loss: 0.1558\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1509 - val_loss: 0.1537\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1495 - val_loss: 0.1539\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1482 - val_loss: 0.1543\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1472 - val_loss: 0.1600\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1467 - val_loss: 0.1511\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1432 - val_loss: 0.1457\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1407 - val_loss: 0.1479\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1415 - val_loss: 0.1450\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1404 - val_loss: 0.1484\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1384 - val_loss: 0.1432\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1381 - val_loss: 0.1442\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1393 - val_loss: 0.1433\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1356 - val_loss: 0.1445\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1348 - val_loss: 0.1420\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1338 - val_loss: 0.1420\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1333 - val_loss: 0.1442\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1357 - val_loss: 0.1437\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1326 - val_loss: 0.1422\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1342 - val_loss: 0.1393\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1292 - val_loss: 0.1410\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1296 - val_loss: 0.1403\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1293 - val_loss: 0.1385\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1285 - val_loss: 0.1389\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1315 - val_loss: 0.1386\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1303 - val_loss: 0.1387\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1295 - val_loss: 0.1430\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1304 - val_loss: 0.1375\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1283 - val_loss: 0.1388\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1283 - val_loss: 0.1347\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1287 - val_loss: 0.1422\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1287 - val_loss: 0.1377\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1279 - val_loss: 0.1334\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1257 - val_loss: 0.1392\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1269 - val_loss: 0.1401\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1276 - val_loss: 0.1358\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1252 - val_loss: 0.1341\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1247 - val_loss: 0.1370\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1239 - val_loss: 0.1383\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1256 - val_loss: 0.1354\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1220 - val_loss: 0.1329\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1216 - val_loss: 0.1350\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1234 - val_loss: 0.1323\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1212 - val_loss: 0.1329\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1221 - val_loss: 0.1311\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1225 - val_loss: 0.1366\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1251 - val_loss: 0.1341\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1230 - val_loss: 0.1304\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1198 - val_loss: 0.1339\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1205 - val_loss: 0.1366\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1203 - val_loss: 0.1323\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1186 - val_loss: 0.1309\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1200 - val_loss: 0.1313\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1187 - val_loss: 0.1337\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1204 - val_loss: 0.1319\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1196 - val_loss: 0.1307\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1198 - val_loss: 0.1300\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1183 - val_loss: 0.1312\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1193 - val_loss: 0.1372\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1230 - val_loss: 0.1308\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1185 - val_loss: 0.1308\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1197 - val_loss: 0.1330\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1196 - val_loss: 0.1304\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1179 - val_loss: 0.1300\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1165 - val_loss: 0.1305\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1172 - val_loss: 0.1296\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1187 - val_loss: 0.1322\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1163 - val_loss: 0.1282\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1149 - val_loss: 0.1321\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1172 - val_loss: 0.1306\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1186 - val_loss: 0.1342\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1195 - val_loss: 0.1305\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1161 - val_loss: 0.1292\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1146 - val_loss: 0.1292\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1136 - val_loss: 0.1348\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1196 - val_loss: 0.1312\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1161 - val_loss: 0.1280\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1145 - val_loss: 0.1300\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1156 - val_loss: 0.1311\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1154 - val_loss: 0.1287\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1123 - val_loss: 0.1278\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1122 - val_loss: 0.1303\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1144 - val_loss: 0.1276\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1135 - val_loss: 0.1266\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1141 - val_loss: 0.1261\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1132 - val_loss: 0.1269\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1106 - val_loss: 0.1266\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.108 - 0s 10ms/step - loss: 0.1112 - val_loss: 0.1292\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1121 - val_loss: 0.1263\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1120 - val_loss: 0.1266\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1124 - val_loss: 0.1270\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1115 - val_loss: 0.1253\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1103 - val_loss: 0.1289\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1125 - val_loss: 0.1287\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1119 - val_loss: 0.1271\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1112 - val_loss: 0.1290\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1119 - val_loss: 0.1256\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1108 - val_loss: 0.1278\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.1124 - val_loss: 0.1323\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1160 - val_loss: 0.1292\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1123 - val_loss: 0.1290\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1106 - val_loss: 0.1318\n",
      "Epoch 00131: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 1s 22ms/step - loss: 3.0997 - val_loss: 1.8988\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5319 - val_loss: 0.6672\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5588 - val_loss: 0.4236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4169 - val_loss: 0.3740\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3497 - val_loss: 0.2972\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2843 - val_loss: 0.2548\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2450 - val_loss: 0.2223\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2189 - val_loss: 0.2049\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2006 - val_loss: 0.1927\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1873 - val_loss: 0.1837\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1774 - val_loss: 0.1751\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1691 - val_loss: 0.1696\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1623 - val_loss: 0.1639\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1565 - val_loss: 0.1632\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1520 - val_loss: 0.1569\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1477 - val_loss: 0.1515\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1433 - val_loss: 0.1505\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1417 - val_loss: 0.1449\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1377 - val_loss: 0.1425\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.1403\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1302 - val_loss: 0.1374\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1284 - val_loss: 0.1336\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1253 - val_loss: 0.1308\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1218 - val_loss: 0.1271\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1201 - val_loss: 0.1271\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1174 - val_loss: 0.1229\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1177 - val_loss: 0.1223\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1142 - val_loss: 0.1194\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1122 - val_loss: 0.1185\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1118 - val_loss: 0.1162\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1074 - val_loss: 0.1131\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1063 - val_loss: 0.1129\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1054 - val_loss: 0.1127\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1029 - val_loss: 0.1140\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1017 - val_loss: 0.1096\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1017 - val_loss: 0.1081\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1000 - val_loss: 0.1079\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0975 - val_loss: 0.1073\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0972 - val_loss: 0.1044\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0963 - val_loss: 0.1030\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0936 - val_loss: 0.1056\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1002 - val_loss: 0.1007\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0972 - val_loss: 0.1033\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0957 - val_loss: 0.0991\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0925 - val_loss: 0.0993\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0906 - val_loss: 0.0978\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0906 - val_loss: 0.0988\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0899 - val_loss: 0.0973\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0891 - val_loss: 0.0954\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0877 - val_loss: 0.0941\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0865 - val_loss: 0.0939\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0855 - val_loss: 0.0946\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0859 - val_loss: 0.0961\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0866 - val_loss: 0.0938\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.0919\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0832 - val_loss: 0.0920\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0851 - val_loss: 0.0934\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0835 - val_loss: 0.0896\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0839 - val_loss: 0.0891\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0817 - val_loss: 0.0913\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0822 - val_loss: 0.0902\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0817 - val_loss: 0.0900\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0809 - val_loss: 0.0886\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0807 - val_loss: 0.0890\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0792 - val_loss: 0.0890\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0801 - val_loss: 0.0864\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0799 - val_loss: 0.0884\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0800 - val_loss: 0.0880\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0798 - val_loss: 0.0860\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0780 - val_loss: 0.0850\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0782 - val_loss: 0.0858\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0794 - val_loss: 0.0890\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0775 - val_loss: 0.0870\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0780 - val_loss: 0.0855\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0795 - val_loss: 0.0886\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0770 - val_loss: 0.0855\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0786 - val_loss: 0.0862\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0768 - val_loss: 0.0843\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0757 - val_loss: 0.0852\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0747 - val_loss: 0.0853\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0768 - val_loss: 0.0859\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0766 - val_loss: 0.0856\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0752 - val_loss: 0.0844\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0759 - val_loss: 0.0862\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0744 - val_loss: 0.0847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0745 - val_loss: 0.0838\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0739 - val_loss: 0.0855\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0755 - val_loss: 0.0859\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0758 - val_loss: 0.0823\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0753 - val_loss: 0.0832\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0751 - val_loss: 0.0853\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0748 - val_loss: 0.0852\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0724 - val_loss: 0.0838\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0728 - val_loss: 0.0857\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0734 - val_loss: 0.0823\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0735 - val_loss: 0.0871\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0740 - val_loss: 0.0835\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0725 - val_loss: 0.0863\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0721 - val_loss: 0.0835\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0706 - val_loss: 0.0837\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0710 - val_loss: 0.0834\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0745 - val_loss: 0.0854\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0730 - val_loss: 0.0836\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0719 - val_loss: 0.0832\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0721 - val_loss: 0.0840\n",
      "Epoch 00105: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.4000 - val_loss: 2.1282\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.7837 - val_loss: 0.8068\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6361 - val_loss: 0.2288\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1825 - val_loss: 0.1076\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1018 - val_loss: 0.0953\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0936 - val_loss: 0.0900\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0890 - val_loss: 0.0838\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0821 - val_loss: 0.0779\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0772 - val_loss: 0.0731\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0721 - val_loss: 0.0692\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0670 - val_loss: 0.0656\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0641 - val_loss: 0.0625\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0597\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0585 - val_loss: 0.0573\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0556 - val_loss: 0.0545\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0522\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0511 - val_loss: 0.0502\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0504 - val_loss: 0.0487\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0482 - val_loss: 0.0477\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0474 - val_loss: 0.0466\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0453 - val_loss: 0.0455\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0448 - val_loss: 0.0448\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0435 - val_loss: 0.0443\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0421 - val_loss: 0.0437\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0419 - val_loss: 0.0433\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0424\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0395 - val_loss: 0.0420\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0391 - val_loss: 0.0413\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0386 - val_loss: 0.0413\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0380 - val_loss: 0.0411\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0376 - val_loss: 0.0402\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0369 - val_loss: 0.0392\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0368 - val_loss: 0.0393\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0396\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0400\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0348 - val_loss: 0.0401\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0343 - val_loss: 0.0393\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0336 - val_loss: 0.0388\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0326 - val_loss: 0.0389\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0322 - val_loss: 0.0382\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0324 - val_loss: 0.0374\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0324 - val_loss: 0.0381\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0319 - val_loss: 0.0372\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0315 - val_loss: 0.0371\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0367\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0360\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0306 - val_loss: 0.0363\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0351\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0291 - val_loss: 0.0359\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0352\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0283 - val_loss: 0.0351\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0287 - val_loss: 0.0347\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0284 - val_loss: 0.0342\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0281 - val_loss: 0.0343\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0278 - val_loss: 0.0337\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0278 - val_loss: 0.0338\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0331\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0326\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0265 - val_loss: 0.0331\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0266 - val_loss: 0.0328\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0262 - val_loss: 0.0328\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0258 - val_loss: 0.0331\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0329\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0337\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0252 - val_loss: 0.0316\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0320\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0249 - val_loss: 0.0319\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0319\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0248 - val_loss: 0.0316\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0310\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0303\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0312\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0240 - val_loss: 0.0303\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0235 - val_loss: 0.0303\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0318\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0297\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0310\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0317\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0227 - val_loss: 0.0309\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0225 - val_loss: 0.0307\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0219 - val_loss: 0.0294\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0286\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0218 - val_loss: 0.0286\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0283\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0283\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0285\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0281\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0297\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0213 - val_loss: 0.0293\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0285\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0277\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0278\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0285\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0284\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0202 - val_loss: 0.0269\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0280\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0200 - val_loss: 0.0267\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0262\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0281\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0295\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0266\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0272\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0274\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0266\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0269\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0265\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0276\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00108: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 16.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 15.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [02:04<02:17, 68.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.0723 - val_loss: 0.0796\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0598 - val_loss: 0.0415\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0375 - val_loss: 0.0272\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0296 - val_loss: 0.0268\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0246\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0235\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0241\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0228\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0257 - val_loss: 0.0220\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0224 - val_loss: 0.0215\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0228 - val_loss: 0.0221\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0248 - val_loss: 0.0212\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0212\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0198 - val_loss: 0.0216\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0201\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0209\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0225\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0202\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0220\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0219\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0212 - val_loss: 0.0202\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0210 - val_loss: 0.0191\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0193 - val_loss: 0.0217\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0233\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0231\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0201\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0190\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0189\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0180\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0186\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0183\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0192\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0202\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0194\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0193\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0188\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0187\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0199\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0188\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0213\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0237\n",
      "Epoch 00049: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.4118 - val_loss: 0.1773\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1752 - val_loss: 0.1311\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1333 - val_loss: 0.1078\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1133 - val_loss: 0.1078\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1095 - val_loss: 0.1014\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1026 - val_loss: 0.0956\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1002 - val_loss: 0.0954\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0952 - val_loss: 0.1054\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1022 - val_loss: 0.1053\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1015 - val_loss: 0.0936\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0939 - val_loss: 0.0895\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0899 - val_loss: 0.0941\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0912 - val_loss: 0.0852\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0897 - val_loss: 0.0984\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0933 - val_loss: 0.0858\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0864 - val_loss: 0.0842\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0814 - val_loss: 0.0898\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0882 - val_loss: 0.0965\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0958 - val_loss: 0.0870\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0881 - val_loss: 0.0844\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0841 - val_loss: 0.0939\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0896 - val_loss: 0.0826\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0828 - val_loss: 0.0953\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0973 - val_loss: 0.0930\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0936\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0907 - val_loss: 0.0846\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0825 - val_loss: 0.0884\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0838 - val_loss: 0.0809\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0782 - val_loss: 0.0860\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0826 - val_loss: 0.0837\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0827 - val_loss: 0.0847\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0806 - val_loss: 0.0928\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0834 - val_loss: 0.0794\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0792 - val_loss: 0.0876\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0819 - val_loss: 0.0842\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0789 - val_loss: 0.0815\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0786 - val_loss: 0.0821\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0810 - val_loss: 0.0907\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0826 - val_loss: 0.0938\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0914 - val_loss: 0.0928\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0875 - val_loss: 0.0857\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0797 - val_loss: 0.0864\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0815 - val_loss: 0.0956\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 1s 14ms/step - loss: 1.0134 - val_loss: 0.3456\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3335 - val_loss: 0.2614\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2538 - val_loss: 0.2513\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2253 - val_loss: 0.1865\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1876 - val_loss: 0.1800\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1748 - val_loss: 0.1703\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1683 - val_loss: 0.1840\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1626 - val_loss: 0.1582\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1520 - val_loss: 0.1470\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1429 - val_loss: 0.1632\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1539 - val_loss: 0.1500\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1497 - val_loss: 0.1485\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1478 - val_loss: 0.1486\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1399 - val_loss: 0.1422\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1382 - val_loss: 0.1398\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1364 - val_loss: 0.1409\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1350 - val_loss: 0.1413\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1366 - val_loss: 0.1384\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1380 - val_loss: 0.1495\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1444 - val_loss: 0.1353\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1323 - val_loss: 0.1466\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1410 - val_loss: 0.1337\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1325 - val_loss: 0.1406\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1303 - val_loss: 0.1557\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1450 - val_loss: 0.1669\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1497 - val_loss: 0.1347\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1309 - val_loss: 0.1468\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1384 - val_loss: 0.1389\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1314 - val_loss: 0.1372\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1312 - val_loss: 0.1358\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1294 - val_loss: 0.1287\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1288 - val_loss: 0.1373\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1297 - val_loss: 0.1268\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1279 - val_loss: 0.1504\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1337 - val_loss: 0.1355\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1331 - val_loss: 0.1414\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1303 - val_loss: 0.1385\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1318 - val_loss: 0.1349\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1282 - val_loss: 0.1415\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1330 - val_loss: 0.1345\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1250 - val_loss: 0.1390\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1274 - val_loss: 0.1303\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1267 - val_loss: 0.1334\n",
      "Epoch 00043: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.6442 - val_loss: 0.3982\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3909 - val_loss: 0.2791\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2314 - val_loss: 0.1807\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1673 - val_loss: 0.1440\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1366 - val_loss: 0.1352\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1266 - val_loss: 0.1222\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1161 - val_loss: 0.1220\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1122 - val_loss: 0.1076\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1056 - val_loss: 0.1036\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0982 - val_loss: 0.1014\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1011 - val_loss: 0.0984\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0927 - val_loss: 0.0994\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0934\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0904 - val_loss: 0.0948\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0930 - val_loss: 0.1072\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0948 - val_loss: 0.1006\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0915 - val_loss: 0.1019\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - val_loss: 0.0991\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0917 - val_loss: 0.1027\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0935 - val_loss: 0.1016\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0912 - val_loss: 0.0988\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0928 - val_loss: 0.1017\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0868 - val_loss: 0.0895\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.0857\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0804 - val_loss: 0.0848\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0792 - val_loss: 0.0850\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0785 - val_loss: 0.0945\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0869 - val_loss: 0.0939\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0892 - val_loss: 0.0934\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0825 - val_loss: 0.0991\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0970 - val_loss: 0.0866\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0852 - val_loss: 0.0926\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0846 - val_loss: 0.0946\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0837 - val_loss: 0.0808\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0772 - val_loss: 0.0804\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0760 - val_loss: 0.0804\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0756 - val_loss: 0.0808\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0757 - val_loss: 0.0801\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0732 - val_loss: 0.0829\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0753 - val_loss: 0.0877\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0779 - val_loss: 0.0877\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0813 - val_loss: 0.0907\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0821 - val_loss: 0.0852\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0794 - val_loss: 0.0932\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0783 - val_loss: 0.0829\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0735 - val_loss: 0.0808\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0743 - val_loss: 0.0853\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0775 - val_loss: 0.0880\n",
      "Epoch 00048: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.8355 - val_loss: 0.3349\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3342 - val_loss: 0.2203\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1690 - val_loss: 0.0675\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0729 - val_loss: 0.0642\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0556 - val_loss: 0.0461\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0449 - val_loss: 0.0402\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0397 - val_loss: 0.0404\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0385 - val_loss: 0.0365\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.0398\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0321 - val_loss: 0.0395\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0376 - val_loss: 0.0395\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0330 - val_loss: 0.0359\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0285 - val_loss: 0.0366\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0286 - val_loss: 0.0322\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0323\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0260 - val_loss: 0.0304\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0290 - val_loss: 0.0351\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0305\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0231 - val_loss: 0.0294\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0235 - val_loss: 0.0273\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0264\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0258\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0266\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0246 - val_loss: 0.0256\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0273 - val_loss: 0.0279\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0272\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0221 - val_loss: 0.0238\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0276\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0247\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0206 - val_loss: 0.0281\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0245\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0201 - val_loss: 0.0236\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0279\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0216 - val_loss: 0.0257\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0342\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0312 - val_loss: 0.0285\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0286 - val_loss: 0.0277\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0275 - val_loss: 0.0296\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0218\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0255\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0198 - val_loss: 0.0224\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0235\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0195 - val_loss: 0.0229\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0185 - val_loss: 0.0221\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0231\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0220 - val_loss: 0.0294\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0222 - val_loss: 0.0239\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0229 - val_loss: 0.0240\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0209\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0218\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0215\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0184 - val_loss: 0.0222\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0213\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0245\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0244 - val_loss: 0.0234\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0317\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0242 - val_loss: 0.0232\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0209\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0198\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0186 - val_loss: 0.0227\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0214\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0258\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0203\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0203\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0201\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0195\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0206\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0196 - val_loss: 0.0209\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0204\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0201\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00082: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 16.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 15.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [02:32<00:56, 56.50s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 5.1071 - val_loss: 1.0660\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.8658 - val_loss: 1.3547\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.4997 - val_loss: 2.1504\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2.2137 - val_loss: 2.5693\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.8951 - val_loss: 0.5586\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4134 - val_loss: 0.2852\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2621 - val_loss: 0.1386\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1306 - val_loss: 0.0754\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0770 - val_loss: 0.0699\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0652 - val_loss: 0.0528\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0508 - val_loss: 0.0774\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1187 - val_loss: 0.0804\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0704 - val_loss: 0.0642\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0547 - val_loss: 0.0392\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0402 - val_loss: 0.0349\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0363 - val_loss: 0.0354\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0340 - val_loss: 0.0359\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0350 - val_loss: 0.0310\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.0341\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0283\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0269 - val_loss: 0.0412\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0379 - val_loss: 0.0327\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0333 - val_loss: 0.0300\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0327 - val_loss: 0.0342\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0293 - val_loss: 0.0250\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0261\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0266 - val_loss: 0.0241\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0272 - val_loss: 0.0294\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0251\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0286 - val_loss: 0.0257\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.0310\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0311 - val_loss: 0.0247\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0263 - val_loss: 0.0206\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0302\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0313 - val_loss: 0.0219\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0259 - val_loss: 0.0218\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0202\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0209 - val_loss: 0.0359\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0335 - val_loss: 0.0335\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0280 - val_loss: 0.0255\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0250 - val_loss: 0.0233\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0268 - val_loss: 0.0248\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0226\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0207\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0207 - val_loss: 0.0241\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0244\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0273\n",
      "Epoch 00050: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 5.0602 - val_loss: 2.1261\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.5326 - val_loss: 0.6572\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.3390\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2935 - val_loss: 0.2426\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2153 - val_loss: 0.1588\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1466 - val_loss: 0.2014\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1735 - val_loss: 0.1184\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1273 - val_loss: 0.1002\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1022 - val_loss: 0.0944\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0989 - val_loss: 0.0880\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0943 - val_loss: 0.0911\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0944 - val_loss: 0.0977\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0939 - val_loss: 0.1077\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1042 - val_loss: 0.0884\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0899 - val_loss: 0.0889\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0934 - val_loss: 0.0898\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0898 - val_loss: 0.0960\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0924 - val_loss: 0.0951\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0940 - val_loss: 0.0878\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0900 - val_loss: 0.0822\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0859 - val_loss: 0.0816\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0845 - val_loss: 0.0823\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0831 - val_loss: 0.0822\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0854 - val_loss: 0.0884\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0881 - val_loss: 0.0797\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0859 - val_loss: 0.0915\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0871 - val_loss: 0.0960\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0951 - val_loss: 0.0844\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0876 - val_loss: 0.0876\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0896 - val_loss: 0.0913\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0871 - val_loss: 0.0912\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0870 - val_loss: 0.0848\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0872 - val_loss: 0.1121\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1022 - val_loss: 0.0923\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0919 - val_loss: 0.0798\n",
      "Epoch 00035: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 3.8211 - val_loss: 1.0161\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7850 - val_loss: 0.7251\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5745 - val_loss: 0.4869\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - val_loss: 0.2367\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2138 - val_loss: 0.1805\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1778 - val_loss: 0.1869\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1790 - val_loss: 0.1609\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1626 - val_loss: 0.1508\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1491 - val_loss: 0.1532\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1503 - val_loss: 0.1771\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1570\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1485 - val_loss: 0.1528\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1448 - val_loss: 0.1406\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1435 - val_loss: 0.1376\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1398 - val_loss: 0.1348\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1404 - val_loss: 0.1401\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1423 - val_loss: 0.1306\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1359 - val_loss: 0.1420\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1385 - val_loss: 0.1309\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1335 - val_loss: 0.1302\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1373 - val_loss: 0.1487\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1407 - val_loss: 0.1431\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1397 - val_loss: 0.1330\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1343 - val_loss: 0.1409\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1365 - val_loss: 0.1458\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1421 - val_loss: 0.1356\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1328 - val_loss: 0.1297\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1261 - val_loss: 0.1311\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1321 - val_loss: 0.1493\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1405 - val_loss: 0.1344\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1323 - val_loss: 0.1330\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1307 - val_loss: 0.1286\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1262 - val_loss: 0.1525\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1389 - val_loss: 0.1311\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1315 - val_loss: 0.1289\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1256 - val_loss: 0.1360\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1287 - val_loss: 0.1372\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1286 - val_loss: 0.1442\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1348 - val_loss: 0.1319\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1275 - val_loss: 0.1416\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1366 - val_loss: 0.1457\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1354 - val_loss: 0.1387\n",
      "Epoch 00042: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 3.1740 - val_loss: 0.9749\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8907 - val_loss: 0.3839\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2964 - val_loss: 0.1639\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1469 - val_loss: 0.1684\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1562 - val_loss: 0.1091\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1223 - val_loss: 0.0992\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.0879\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0928 - val_loss: 0.1098\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1071 - val_loss: 0.1081\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0985 - val_loss: 0.0942\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0930 - val_loss: 0.0873\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0879 - val_loss: 0.0830\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0839 - val_loss: 0.0806\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0851 - val_loss: 0.0892\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0861 - val_loss: 0.0959\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0890 - val_loss: 0.0961\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0888 - val_loss: 0.1253\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1055 - val_loss: 0.1007\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0943 - val_loss: 0.0889\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0845 - val_loss: 0.0983\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0900 - val_loss: 0.0859\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0831 - val_loss: 0.0920\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0843 - val_loss: 0.0836\n",
      "Epoch 00023: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 2.2088 - val_loss: 2.4503\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1.5838 - val_loss: 0.3405\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4524 - val_loss: 0.4137\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2656 - val_loss: 0.2858\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2734 - val_loss: 0.2353\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2210 - val_loss: 0.0892\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0724 - val_loss: 0.0687\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0751 - val_loss: 0.1040\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0972 - val_loss: 0.0803\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0789 - val_loss: 0.2478\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1881 - val_loss: 0.1295\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0809 - val_loss: 0.0392\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0441 - val_loss: 0.0570\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0985 - val_loss: 0.0780\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0631 - val_loss: 0.0357\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0364 - val_loss: 0.0294\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0286\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0273 - val_loss: 0.0252\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0247 - val_loss: 0.0220\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0205 - val_loss: 0.0304\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0326 - val_loss: 0.0236\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0243 - val_loss: 0.0202\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.0272 - val_loss: 0.0277\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0231\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0226 - val_loss: 0.0196\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0344\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0297 - val_loss: 0.0346\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0255 - val_loss: 0.0320\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0312 - val_loss: 0.0242\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0282 - val_loss: 0.0354\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0374 - val_loss: 0.0292\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0251 - val_loss: 0.0198\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0223\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0223 - val_loss: 0.0231\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0209 - val_loss: 0.0268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00035: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 17.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 16.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 4/4 [02:56<00:00, 44.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [02:56<00:00, 176.31s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [18:36<03:38, 218.90s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 23ms/step - loss: 0.0979 - val_loss: 0.0953\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0957 - val_loss: 0.0932\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0936 - val_loss: 0.0910\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0914 - val_loss: 0.0889\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0893 - val_loss: 0.0868\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0873 - val_loss: 0.0847\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0853 - val_loss: 0.0826\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0829 - val_loss: 0.0806\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0810 - val_loss: 0.0785\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0790 - val_loss: 0.0765\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0770 - val_loss: 0.0744\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0750 - val_loss: 0.0726\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0730 - val_loss: 0.0709\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0715 - val_loss: 0.0699\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0696 - val_loss: 0.0686\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0681 - val_loss: 0.0671\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0665 - val_loss: 0.0655\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0639\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0633 - val_loss: 0.0624\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0620 - val_loss: 0.0608\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0601 - val_loss: 0.0594\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0592 - val_loss: 0.0581\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0581 - val_loss: 0.0570\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0567 - val_loss: 0.0560\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0561 - val_loss: 0.0552\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.0540\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0541 - val_loss: 0.0531\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0536 - val_loss: 0.0527\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0523 - val_loss: 0.0521\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0516 - val_loss: 0.0511\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0506 - val_loss: 0.0502\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0499 - val_loss: 0.0494\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0492 - val_loss: 0.0487\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0484 - val_loss: 0.0479\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0483 - val_loss: 0.0475\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0476 - val_loss: 0.0472\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0471 - val_loss: 0.0465\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0462 - val_loss: 0.0457\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0460 - val_loss: 0.0454\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0450 - val_loss: 0.0456\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0444 - val_loss: 0.0442\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0436 - val_loss: 0.0435\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0433 - val_loss: 0.0431\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0431 - val_loss: 0.0427\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0424 - val_loss: 0.0424\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0423 - val_loss: 0.0419\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0419 - val_loss: 0.0413\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0410 - val_loss: 0.0409\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0410 - val_loss: 0.0407\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.0401\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0401 - val_loss: 0.0397\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0401 - val_loss: 0.0393\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0397 - val_loss: 0.0390\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.0387\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0392 - val_loss: 0.0383\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0388 - val_loss: 0.0380\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0378\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.0375\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0378 - val_loss: 0.0371\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.0368\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0366\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0373 - val_loss: 0.0364\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0361\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0369 - val_loss: 0.0358\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0367 - val_loss: 0.0355\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0365 - val_loss: 0.0352\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0351\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0358 - val_loss: 0.0351\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0355 - val_loss: 0.0349\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0354 - val_loss: 0.0348\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.0346\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0348 - val_loss: 0.0345\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.0343\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.0341\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.0339\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0343 - val_loss: 0.0338\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0337\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0339 - val_loss: 0.0336\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0336 - val_loss: 0.0334\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0337 - val_loss: 0.0332\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0334 - val_loss: 0.0331\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0333 - val_loss: 0.0329\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0333 - val_loss: 0.0327\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0330 - val_loss: 0.0327\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0330 - val_loss: 0.0326\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0323 - val_loss: 0.0324\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0322\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0324 - val_loss: 0.0323\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0324 - val_loss: 0.0322\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0324 - val_loss: 0.0320\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0322 - val_loss: 0.0319\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0318\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0316\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0314\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0312\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.0313\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.0314\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0315\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0310\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0307 - val_loss: 0.0307\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0309 - val_loss: 0.0307\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0306\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0306 - val_loss: 0.0306\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0302 - val_loss: 0.0310\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0305\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0300\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0300\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0303\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0304\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0301\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0298\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.0297\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0299\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0298\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0297\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0295\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0294\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0291\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0288\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0288 - val_loss: 0.0294\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0292\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0287\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.0287\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0289\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.0288\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0283 - val_loss: 0.0284\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0284\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0283 - val_loss: 0.0288\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0286\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - val_loss: 0.0286\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - val_loss: 0.0286\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0280 - val_loss: 0.0284\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0279\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0280\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0278\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0276\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0277\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0277\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0277\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0281\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0274 - val_loss: 0.0282\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0283\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0283\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - val_loss: 0.0280\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0279\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0277\n",
      "Epoch 00160: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6639 - val_loss: 0.6535\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6505 - val_loss: 0.6392\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6358 - val_loss: 0.6251\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6217 - val_loss: 0.6110\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6075 - val_loss: 0.5969\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5942 - val_loss: 0.5829\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5800 - val_loss: 0.5686\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5661 - val_loss: 0.5542\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5522 - val_loss: 0.5396\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5371 - val_loss: 0.5249\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5229 - val_loss: 0.5099\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5098 - val_loss: 0.4946\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4917 - val_loss: 0.4789\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4788 - val_loss: 0.4639\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4631 - val_loss: 0.4494\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4494 - val_loss: 0.4352\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4348 - val_loss: 0.4213\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4219 - val_loss: 0.4086\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4087 - val_loss: 0.3961\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3958 - val_loss: 0.3832\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3823 - val_loss: 0.3701\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3696 - val_loss: 0.3566\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3567 - val_loss: 0.3433\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3447 - val_loss: 0.3307\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3302 - val_loss: 0.3186\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3206 - val_loss: 0.3085\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3097 - val_loss: 0.3008\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3035 - val_loss: 0.2936\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2952 - val_loss: 0.2867\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2913 - val_loss: 0.2807\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2830 - val_loss: 0.2755\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2786 - val_loss: 0.2704\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2727 - val_loss: 0.2655\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2692 - val_loss: 0.2608\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2644 - val_loss: 0.2564\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2586 - val_loss: 0.2514\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2559 - val_loss: 0.2468\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2492 - val_loss: 0.2422\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2444 - val_loss: 0.2379\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2420 - val_loss: 0.2337\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2374 - val_loss: 0.2294\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2326 - val_loss: 0.2252\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2287 - val_loss: 0.2217\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2253 - val_loss: 0.2176\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2222 - val_loss: 0.2135\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2193 - val_loss: 0.2101\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2148 - val_loss: 0.2068\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2116 - val_loss: 0.2037\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2097 - val_loss: 0.2004\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2048 - val_loss: 0.1975\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2027 - val_loss: 0.1947\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2004 - val_loss: 0.1920\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1964 - val_loss: 0.1897\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1949 - val_loss: 0.1873\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1929 - val_loss: 0.1848\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1915 - val_loss: 0.1824\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1887 - val_loss: 0.1804\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1865 - val_loss: 0.1790\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1848 - val_loss: 0.1772\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1834 - val_loss: 0.1757\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1801 - val_loss: 0.1744\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1793 - val_loss: 0.1727\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1770 - val_loss: 0.1713\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1761 - val_loss: 0.1702\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1748 - val_loss: 0.1697\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1736 - val_loss: 0.1680\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1724 - val_loss: 0.1660\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1705 - val_loss: 0.1651\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1696 - val_loss: 0.1642\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1687 - val_loss: 0.1636\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1674 - val_loss: 0.1632\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1654 - val_loss: 0.1622\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1668 - val_loss: 0.1611\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1655 - val_loss: 0.1601\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1646 - val_loss: 0.1602\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1641 - val_loss: 0.1594\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1645 - val_loss: 0.1591\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1624 - val_loss: 0.1588\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1621 - val_loss: 0.1578\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1606 - val_loss: 0.1562\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1590 - val_loss: 0.1551\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1577 - val_loss: 0.1544\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1591 - val_loss: 0.1537\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1580 - val_loss: 0.1530\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1587 - val_loss: 0.1529\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1563 - val_loss: 0.1525\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1558 - val_loss: 0.1522\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1565 - val_loss: 0.1519\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1549 - val_loss: 0.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1547 - val_loss: 0.1510\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1532 - val_loss: 0.1504\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1522 - val_loss: 0.1496\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1520 - val_loss: 0.1488\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1523 - val_loss: 0.1486\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1510 - val_loss: 0.1487\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1503 - val_loss: 0.1488\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1497 - val_loss: 0.1485\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1487 - val_loss: 0.1475\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1466 - val_loss: 0.1467\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1472 - val_loss: 0.1459\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1474 - val_loss: 0.1456\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1467 - val_loss: 0.1454\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1467 - val_loss: 0.1453\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1459 - val_loss: 0.1451\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1453 - val_loss: 0.1445\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1448 - val_loss: 0.1442\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1436 - val_loss: 0.1440\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1441 - val_loss: 0.1435\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1424 - val_loss: 0.1428\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1421 - val_loss: 0.1421\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1413 - val_loss: 0.1413\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1422 - val_loss: 0.1409\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1404 - val_loss: 0.1408\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1403 - val_loss: 0.1405\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1397 - val_loss: 0.1401\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1405 - val_loss: 0.1400\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1397 - val_loss: 0.1398\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1385 - val_loss: 0.1393\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1391 - val_loss: 0.1390\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1372 - val_loss: 0.1386\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1389 - val_loss: 0.1380\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1385 - val_loss: 0.1373\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1370 - val_loss: 0.1369\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1370 - val_loss: 0.1362\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1353 - val_loss: 0.1362\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1368 - val_loss: 0.1363\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1347 - val_loss: 0.1363\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1346 - val_loss: 0.1361\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1339 - val_loss: 0.1356\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1347 - val_loss: 0.1351\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1338 - val_loss: 0.1343\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1339 - val_loss: 0.1339\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1330 - val_loss: 0.1337\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1317 - val_loss: 0.1337\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1317 - val_loss: 0.1336\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1327 - val_loss: 0.1334\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1316 - val_loss: 0.1329\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1301 - val_loss: 0.1318\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1308 - val_loss: 0.1310\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1314 - val_loss: 0.1308\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1303 - val_loss: 0.1305\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1299 - val_loss: 0.1301\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1295 - val_loss: 0.1302\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1289 - val_loss: 0.1305\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1293 - val_loss: 0.1303\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1282 - val_loss: 0.1298\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1275 - val_loss: 0.1293\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1275 - val_loss: 0.1287\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1275 - val_loss: 0.1280\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1269 - val_loss: 0.1277\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1271 - val_loss: 0.1273\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1268 - val_loss: 0.1273\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1253 - val_loss: 0.1277\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1259 - val_loss: 0.1270\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1255 - val_loss: 0.1266\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1264 - val_loss: 0.1262\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1248 - val_loss: 0.1262\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1247 - val_loss: 0.1258\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1236 - val_loss: 0.1258\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1243 - val_loss: 0.1257\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1234 - val_loss: 0.1258\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1242 - val_loss: 0.1257\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1227 - val_loss: 0.1258\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1226 - val_loss: 0.1258\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1233 - val_loss: 0.1251\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1223 - val_loss: 0.1246\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1217 - val_loss: 0.1240\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1226 - val_loss: 0.1235\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1211 - val_loss: 0.1231\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1225 - val_loss: 0.1228\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1208 - val_loss: 0.1225\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1215 - val_loss: 0.1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1206 - val_loss: 0.1221\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1204 - val_loss: 0.1219\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1201 - val_loss: 0.1216\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1196 - val_loss: 0.1216\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1198 - val_loss: 0.1218\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1190 - val_loss: 0.1217\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1184 - val_loss: 0.1212\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1185 - val_loss: 0.1209\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1188 - val_loss: 0.1208\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1188 - val_loss: 0.1202\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1197\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1177 - val_loss: 0.1198\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1192 - val_loss: 0.1194\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1171 - val_loss: 0.1188\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1178 - val_loss: 0.1188\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1174 - val_loss: 0.1184\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1174 - val_loss: 0.1180\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1171 - val_loss: 0.1180\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1158 - val_loss: 0.1182\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1159 - val_loss: 0.1183\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1165 - val_loss: 0.1179\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1162 - val_loss: 0.1172\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1158 - val_loss: 0.1166\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1151 - val_loss: 0.1165\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1160 - val_loss: 0.1161\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1152 - val_loss: 0.1163\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1154 - val_loss: 0.1161\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1152 - val_loss: 0.1164\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.9624 - val_loss: 1.9215\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.9175 - val_loss: 1.8754\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8725 - val_loss: 1.8288\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8297 - val_loss: 1.7816\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7781 - val_loss: 1.7336\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7324 - val_loss: 1.6844\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6848 - val_loss: 1.6351\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6325 - val_loss: 1.5851\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5851 - val_loss: 1.5348\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5344 - val_loss: 1.4848\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4876 - val_loss: 1.4368\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4320 - val_loss: 1.3906\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3873 - val_loss: 1.3450\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3420 - val_loss: 1.2999\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2959 - val_loss: 1.2545\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2518 - val_loss: 1.2092\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2019 - val_loss: 1.1645\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1613 - val_loss: 1.1193\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1233 - val_loss: 1.0740\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0774 - val_loss: 1.0290\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0330 - val_loss: 0.9823\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9894 - val_loss: 0.9349\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9389 - val_loss: 0.8870\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8934 - val_loss: 0.8387\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8494 - val_loss: 0.7915\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8075 - val_loss: 0.7479\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7704 - val_loss: 0.7063\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7274 - val_loss: 0.6716\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7023 - val_loss: 0.6416\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6742 - val_loss: 0.6162\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6483 - val_loss: 0.5939\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6295 - val_loss: 0.5753\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6108 - val_loss: 0.5599\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.5939 - val_loss: 0.5465\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5801 - val_loss: 0.5344\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5634 - val_loss: 0.5223\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5569 - val_loss: 0.5107\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5369 - val_loss: 0.4993\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5258 - val_loss: 0.4883\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5154 - val_loss: 0.4784\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5010 - val_loss: 0.4699\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4945 - val_loss: 0.4618\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4831 - val_loss: 0.4538\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4724 - val_loss: 0.4453\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4670 - val_loss: 0.4374\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4528 - val_loss: 0.4294\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4472 - val_loss: 0.4224\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4374 - val_loss: 0.4158\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4302 - val_loss: 0.4096\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4246 - val_loss: 0.4039\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4164 - val_loss: 0.3980\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4131 - val_loss: 0.3921\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4021 - val_loss: 0.3870\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3989 - val_loss: 0.3814\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3958 - val_loss: 0.3760\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3883 - val_loss: 0.3712\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3827 - val_loss: 0.3672\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3788 - val_loss: 0.3627\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3714 - val_loss: 0.3585\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3696 - val_loss: 0.3546\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3621 - val_loss: 0.3512\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3622 - val_loss: 0.3477\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3555 - val_loss: 0.3446\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3530 - val_loss: 0.3407\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3509 - val_loss: 0.3372\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3473 - val_loss: 0.3345\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3432 - val_loss: 0.3319\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3422 - val_loss: 0.3291\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3398 - val_loss: 0.3258\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3362 - val_loss: 0.3232\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3317 - val_loss: 0.3209\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3324 - val_loss: 0.3185\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3271 - val_loss: 0.3162\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3263 - val_loss: 0.3141\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3230 - val_loss: 0.3118\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3223 - val_loss: 0.3101\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3195 - val_loss: 0.3082\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3166 - val_loss: 0.3067\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3153 - val_loss: 0.3053\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3130 - val_loss: 0.3032\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3096 - val_loss: 0.3015\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3092 - val_loss: 0.3003\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3092 - val_loss: 0.2992\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3055 - val_loss: 0.2978\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3031 - val_loss: 0.2964\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3021 - val_loss: 0.2946\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2999 - val_loss: 0.2925\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2992 - val_loss: 0.2915\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2987 - val_loss: 0.2905\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2950 - val_loss: 0.2894\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2952 - val_loss: 0.2877\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2914 - val_loss: 0.2862\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2915 - val_loss: 0.2846\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2927 - val_loss: 0.2839\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2901 - val_loss: 0.2832\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2870 - val_loss: 0.2824\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2859 - val_loss: 0.2818\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2865 - val_loss: 0.2806\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2832 - val_loss: 0.2794\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2824 - val_loss: 0.2784\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2831 - val_loss: 0.2770\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2806 - val_loss: 0.2755\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2786 - val_loss: 0.2746\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2791 - val_loss: 0.2740\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2760 - val_loss: 0.2730\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2775 - val_loss: 0.2720\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2761 - val_loss: 0.2711\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2741 - val_loss: 0.2705\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2724 - val_loss: 0.2702\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2721 - val_loss: 0.2690\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2697 - val_loss: 0.2679\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2712 - val_loss: 0.2669\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2695 - val_loss: 0.2660\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2671 - val_loss: 0.2653\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2668 - val_loss: 0.2650\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2681 - val_loss: 0.2644\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2655 - val_loss: 0.2634\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2660 - val_loss: 0.2627\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2646 - val_loss: 0.2621\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2629 - val_loss: 0.2612\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2628 - val_loss: 0.2605\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2602 - val_loss: 0.2598\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2590 - val_loss: 0.2592\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2588 - val_loss: 0.2586\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2581 - val_loss: 0.2576\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2582 - val_loss: 0.2563\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2574 - val_loss: 0.2554\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2541 - val_loss: 0.2546\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2542 - val_loss: 0.2542\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2546 - val_loss: 0.2539\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2525 - val_loss: 0.2537\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2536 - val_loss: 0.2529\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2521 - val_loss: 0.2519\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2523 - val_loss: 0.2508\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2515 - val_loss: 0.2501\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2505 - val_loss: 0.2500\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2479 - val_loss: 0.2498\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2482 - val_loss: 0.2487\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2475 - val_loss: 0.2480\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2469 - val_loss: 0.2469\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2472 - val_loss: 0.2457\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2445 - val_loss: 0.2451\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2456 - val_loss: 0.2442\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2431 - val_loss: 0.2439\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2421 - val_loss: 0.2442\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2421 - val_loss: 0.2441\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2399 - val_loss: 0.2432\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2425 - val_loss: 0.2425\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2408 - val_loss: 0.2418\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2408 - val_loss: 0.2409\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2363 - val_loss: 0.2403\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2400 - val_loss: 0.2397\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2387 - val_loss: 0.2393\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2358 - val_loss: 0.2387\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2366 - val_loss: 0.2385\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2355 - val_loss: 0.2381\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2354 - val_loss: 0.2374\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2336 - val_loss: 0.2366\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2342 - val_loss: 0.2355\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2340 - val_loss: 0.2352\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2336 - val_loss: 0.2350\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2318 - val_loss: 0.2346\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2337 - val_loss: 0.2339\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2300 - val_loss: 0.2336\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2309 - val_loss: 0.2330\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2311 - val_loss: 0.2320\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2297 - val_loss: 0.2311\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2280 - val_loss: 0.2302\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2297 - val_loss: 0.2296\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2275 - val_loss: 0.2295\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2277 - val_loss: 0.2297\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2274 - val_loss: 0.2297\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2294 - val_loss: 0.2292\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2276 - val_loss: 0.2281\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2250 - val_loss: 0.2275\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2253 - val_loss: 0.2272\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2246 - val_loss: 0.2275\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2233 - val_loss: 0.2271\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2237 - val_loss: 0.2274\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2237 - val_loss: 0.2273\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2229 - val_loss: 0.2264\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2200 - val_loss: 0.2256\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2209 - val_loss: 0.2247\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2197 - val_loss: 0.2244\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2206 - val_loss: 0.2233\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2188 - val_loss: 0.2228\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2215 - val_loss: 0.2227\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2193 - val_loss: 0.2228\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2185 - val_loss: 0.2228\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2174 - val_loss: 0.2228\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2174 - val_loss: 0.2217\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2163 - val_loss: 0.2203\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2154 - val_loss: 0.2196\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2147 - val_loss: 0.2195\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2135 - val_loss: 0.2193\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2155 - val_loss: 0.2186\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2124 - val_loss: 0.2182\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2144 - val_loss: 0.2177\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2125 - val_loss: 0.2172\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2123 - val_loss: 0.2174\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.1589 - val_loss: 3.1129\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.0948 - val_loss: 3.0419\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.0189 - val_loss: 2.9707\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.9511 - val_loss: 2.8987\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.8800 - val_loss: 2.8257\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.8106 - val_loss: 2.7515\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.7383 - val_loss: 2.6763\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.6597 - val_loss: 2.5991\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5833 - val_loss: 2.5206\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5071 - val_loss: 2.4407\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4377 - val_loss: 2.3595\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3467 - val_loss: 2.2769\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2681 - val_loss: 2.1932\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1887 - val_loss: 2.1097\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0972 - val_loss: 2.0268\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0253 - val_loss: 1.9449\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9402 - val_loss: 1.8637\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8640 - val_loss: 1.7836\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7819 - val_loss: 1.7031\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6988 - val_loss: 1.6227\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6309 - val_loss: 1.5439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5528 - val_loss: 1.4660\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4729 - val_loss: 1.3893\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3913 - val_loss: 1.3148\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3209 - val_loss: 1.2424\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2510 - val_loss: 1.1741\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1868 - val_loss: 1.1102\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1170 - val_loss: 1.0499\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0547 - val_loss: 0.9923\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0008 - val_loss: 0.9381\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9457 - val_loss: 0.8884\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8893 - val_loss: 0.8428\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8512 - val_loss: 0.8004\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8011 - val_loss: 0.7602\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7669 - val_loss: 0.7231\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7328 - val_loss: 0.6899\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7000 - val_loss: 0.6598\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6615 - val_loss: 0.6321\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6302 - val_loss: 0.6065\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6073 - val_loss: 0.5822\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5795 - val_loss: 0.5589\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5618 - val_loss: 0.5377\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5388 - val_loss: 0.5192\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5117 - val_loss: 0.5024\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5032 - val_loss: 0.4868\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4864 - val_loss: 0.4730\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4717 - val_loss: 0.4600\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4595 - val_loss: 0.4482\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4459 - val_loss: 0.4373\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4404 - val_loss: 0.4272\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4248 - val_loss: 0.4180\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4198 - val_loss: 0.4093\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4096 - val_loss: 0.4012\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4018 - val_loss: 0.3941\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3885 - val_loss: 0.3876\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3882 - val_loss: 0.3816\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3830 - val_loss: 0.3759\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3738 - val_loss: 0.3705\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3741 - val_loss: 0.3656\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3646 - val_loss: 0.3609\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3599 - val_loss: 0.3561\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3580 - val_loss: 0.3515\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3543 - val_loss: 0.3470\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3507 - val_loss: 0.3427\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3444 - val_loss: 0.3384\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3411 - val_loss: 0.3345\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3379 - val_loss: 0.3306\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3329 - val_loss: 0.3268\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3303 - val_loss: 0.3231\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3253 - val_loss: 0.3195\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3223 - val_loss: 0.3161\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3199 - val_loss: 0.3126\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3150 - val_loss: 0.3094\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3113 - val_loss: 0.3063\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3066 - val_loss: 0.3031\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3060 - val_loss: 0.2999\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3004 - val_loss: 0.2969\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3018 - val_loss: 0.2939\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2982 - val_loss: 0.2910\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2948 - val_loss: 0.2881\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2923 - val_loss: 0.2853\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2904 - val_loss: 0.2826\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2858 - val_loss: 0.2798\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2835 - val_loss: 0.2769\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2823 - val_loss: 0.2741\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2787 - val_loss: 0.2715\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2769 - val_loss: 0.2693\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2728 - val_loss: 0.2670\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2734 - val_loss: 0.2649\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2679 - val_loss: 0.2628\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2671 - val_loss: 0.2609\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2654 - val_loss: 0.2591\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2634 - val_loss: 0.2573\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2605 - val_loss: 0.2553\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2585 - val_loss: 0.2532\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2546 - val_loss: 0.2512\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2545 - val_loss: 0.2493\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2520 - val_loss: 0.2474\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2490 - val_loss: 0.2454\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2480 - val_loss: 0.2435\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2467 - val_loss: 0.2416\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2437 - val_loss: 0.2399\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2414 - val_loss: 0.2382\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2397 - val_loss: 0.2365\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2391 - val_loss: 0.2350\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2393 - val_loss: 0.2338\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2350 - val_loss: 0.2326\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2343 - val_loss: 0.2312\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2305 - val_loss: 0.2298\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2316 - val_loss: 0.2283\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2285 - val_loss: 0.2268\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2265 - val_loss: 0.2256\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2259 - val_loss: 0.2245\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2247 - val_loss: 0.2234\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2241 - val_loss: 0.2223\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2207 - val_loss: 0.2213\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2209 - val_loss: 0.2201\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2184 - val_loss: 0.2189\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2158 - val_loss: 0.2177\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2176 - val_loss: 0.2167\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2144 - val_loss: 0.2158\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2149 - val_loss: 0.2149\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2114 - val_loss: 0.2141\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2121 - val_loss: 0.2132\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2098 - val_loss: 0.2122\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2076 - val_loss: 0.2111\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2097 - val_loss: 0.2102\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2087 - val_loss: 0.2093\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2058 - val_loss: 0.2085\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2049 - val_loss: 0.2078\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2034 - val_loss: 0.2069\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2053 - val_loss: 0.2058\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2019 - val_loss: 0.2050\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2008 - val_loss: 0.2044\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1989 - val_loss: 0.2037\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2008 - val_loss: 0.2030\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1976 - val_loss: 0.2022\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1975 - val_loss: 0.2013\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1981 - val_loss: 0.2004\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1958 - val_loss: 0.1997\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1942 - val_loss: 0.1990\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1935 - val_loss: 0.1983\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1932 - val_loss: 0.1977\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1933 - val_loss: 0.1970\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1924 - val_loss: 0.1964\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1936 - val_loss: 0.1958\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1904 - val_loss: 0.1953\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1878 - val_loss: 0.1947\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1894 - val_loss: 0.1940\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1880 - val_loss: 0.1932\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1869 - val_loss: 0.1923\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1867 - val_loss: 0.1917\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1853 - val_loss: 0.1912\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1838 - val_loss: 0.1907\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1832 - val_loss: 0.1902\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1851 - val_loss: 0.1898\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1830 - val_loss: 0.1893\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1822 - val_loss: 0.1888\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1821 - val_loss: 0.1882\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1826 - val_loss: 0.1875\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1792 - val_loss: 0.1871\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1804 - val_loss: 0.1868\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1805 - val_loss: 0.1864\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1791 - val_loss: 0.1858\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1779 - val_loss: 0.1852\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1771 - val_loss: 0.1847\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1770 - val_loss: 0.1843\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1767 - val_loss: 0.1836\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1771 - val_loss: 0.1830\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1755 - val_loss: 0.1826\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1751 - val_loss: 0.1822\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1748 - val_loss: 0.1818\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1748 - val_loss: 0.1810\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1752 - val_loss: 0.1803\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1737 - val_loss: 0.1798\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1721 - val_loss: 0.1794\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1722 - val_loss: 0.1790\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1720 - val_loss: 0.1786\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1708 - val_loss: 0.1782\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1712 - val_loss: 0.1778\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1703 - val_loss: 0.1773\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1699 - val_loss: 0.1769\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1700 - val_loss: 0.1763\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1693 - val_loss: 0.1760\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1677 - val_loss: 0.1756\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1686 - val_loss: 0.1753\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1686 - val_loss: 0.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1657 - val_loss: 0.1747\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1666 - val_loss: 0.1743\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1660 - val_loss: 0.1738\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1656 - val_loss: 0.1734\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1652 - val_loss: 0.1731\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1659 - val_loss: 0.1727\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1649 - val_loss: 0.1724\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1636 - val_loss: 0.1722\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1635 - val_loss: 0.1719\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1631 - val_loss: 0.1713\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1644 - val_loss: 0.1710\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1623 - val_loss: 0.1710\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1627 - val_loss: 0.1709\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 3.9028 - val_loss: 3.8213\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8098 - val_loss: 3.7269\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.7027 - val_loss: 3.6331\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.6179 - val_loss: 3.5395\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.5213 - val_loss: 3.4454\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.4313 - val_loss: 3.3507\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.3344 - val_loss: 3.2552\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.2394 - val_loss: 3.1582\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1430 - val_loss: 3.0600\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0444 - val_loss: 2.9602\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.9453 - val_loss: 2.8592\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8415 - val_loss: 2.7564\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.7452 - val_loss: 2.6523\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.6357 - val_loss: 2.5460\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5372 - val_loss: 2.4383\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4245 - val_loss: 2.3292\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3211 - val_loss: 2.2204\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2241 - val_loss: 2.1116\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1157 - val_loss: 2.0026\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9962 - val_loss: 1.8926\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8973 - val_loss: 1.7830\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7916 - val_loss: 1.6740\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6761 - val_loss: 1.5669\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5721 - val_loss: 1.4630\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4721 - val_loss: 1.3631\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3654 - val_loss: 1.2683\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2789 - val_loss: 1.1806\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2031 - val_loss: 1.0993\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1073 - val_loss: 1.0236\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0362 - val_loss: 0.9525\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9628 - val_loss: 0.8875\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8992 - val_loss: 0.8265\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8351 - val_loss: 0.7693\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7735 - val_loss: 0.7153\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7285 - val_loss: 0.6648\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6731 - val_loss: 0.6184\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6231 - val_loss: 0.5762\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5789 - val_loss: 0.5372\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5390 - val_loss: 0.5015\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5016 - val_loss: 0.4686\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4672 - val_loss: 0.4388\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4384 - val_loss: 0.4107\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4082 - val_loss: 0.3843\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3811 - val_loss: 0.3601\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3556 - val_loss: 0.3380\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3315 - val_loss: 0.3183\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3151 - val_loss: 0.3002\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2938 - val_loss: 0.2839\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2726 - val_loss: 0.2687\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2653 - val_loss: 0.2543\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2506 - val_loss: 0.2414\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2383 - val_loss: 0.2296\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2252 - val_loss: 0.2189\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2149 - val_loss: 0.2090\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2064 - val_loss: 0.1997\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1954 - val_loss: 0.1915\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1909 - val_loss: 0.1840\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1807 - val_loss: 0.1771\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1751 - val_loss: 0.1710\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1695 - val_loss: 0.1654\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1633 - val_loss: 0.1604\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1585 - val_loss: 0.1558\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1521 - val_loss: 0.1515\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1535 - val_loss: 0.1473\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1428 - val_loss: 0.1434\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1400 - val_loss: 0.1400\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1388 - val_loss: 0.1367\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1350 - val_loss: 0.1337\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1312 - val_loss: 0.1307\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1291 - val_loss: 0.1280\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1267 - val_loss: 0.1253\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1229 - val_loss: 0.1227\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1205 - val_loss: 0.1202\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1192 - val_loss: 0.1179\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1168 - val_loss: 0.1158\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1147 - val_loss: 0.1140\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1125 - val_loss: 0.1122\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1103 - val_loss: 0.1107\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1078 - val_loss: 0.1093\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1050 - val_loss: 0.1079\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1055 - val_loss: 0.1064\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1066 - val_loss: 0.1050\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1038 - val_loss: 0.1037\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1002 - val_loss: 0.1025\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.1013\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0996 - val_loss: 0.1003\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0993\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0978 - val_loss: 0.0983\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0967 - val_loss: 0.0974\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0943 - val_loss: 0.0965\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0943 - val_loss: 0.0955\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0926 - val_loss: 0.0947\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0935 - val_loss: 0.0939\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0918 - val_loss: 0.0932\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0920 - val_loss: 0.0924\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0907 - val_loss: 0.0917\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0908 - val_loss: 0.0910\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0892 - val_loss: 0.0904\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0889 - val_loss: 0.0899\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0898 - val_loss: 0.0893\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0869 - val_loss: 0.0887\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0886 - val_loss: 0.0881\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0866 - val_loss: 0.0875\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0871 - val_loss: 0.0870\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - val_loss: 0.0865\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0851 - val_loss: 0.0860\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0854 - val_loss: 0.0855\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - val_loss: 0.0850\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - val_loss: 0.0844\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0846 - val_loss: 0.0839\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - val_loss: 0.0833\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0829\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.0824\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0808 - val_loss: 0.0820\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0811 - val_loss: 0.0816\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0822 - val_loss: 0.0812\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0815 - val_loss: 0.0808\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0803 - val_loss: 0.0804\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0802 - val_loss: 0.0800\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0810 - val_loss: 0.0796\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0796 - val_loss: 0.0792\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0795 - val_loss: 0.0788\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0788 - val_loss: 0.0785\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.0781\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0785 - val_loss: 0.0778\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0785 - val_loss: 0.0774\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0784 - val_loss: 0.0771\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0773 - val_loss: 0.0767\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0771 - val_loss: 0.0764\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0770 - val_loss: 0.0760\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0751 - val_loss: 0.0757\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0762 - val_loss: 0.0754\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0757 - val_loss: 0.0751\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0760 - val_loss: 0.0747\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0765 - val_loss: 0.0744\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0749 - val_loss: 0.0741\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0738\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0732 - val_loss: 0.0736\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0736 - val_loss: 0.0733\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0733 - val_loss: 0.0731\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0733 - val_loss: 0.0729\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0735 - val_loss: 0.0727\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0722 - val_loss: 0.0725\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0724 - val_loss: 0.0723\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0720 - val_loss: 0.0721\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0721 - val_loss: 0.0719\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0725 - val_loss: 0.0716\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0713 - val_loss: 0.0714\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0713 - val_loss: 0.0711\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0703 - val_loss: 0.0709\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0712 - val_loss: 0.0707\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0700 - val_loss: 0.0705\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0701 - val_loss: 0.0703\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0696 - val_loss: 0.0701\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0699 - val_loss: 0.0698\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0699 - val_loss: 0.0696\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0691 - val_loss: 0.0694\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0687 - val_loss: 0.0692\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0686 - val_loss: 0.0691\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0688 - val_loss: 0.0689\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0687 - val_loss: 0.0686\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0684 - val_loss: 0.0684\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0675 - val_loss: 0.0682\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0673 - val_loss: 0.0680\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0666 - val_loss: 0.0677\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0675 - val_loss: 0.0675\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0669 - val_loss: 0.0673\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0671 - val_loss: 0.0671\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0663 - val_loss: 0.0669\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0657 - val_loss: 0.0667\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0660 - val_loss: 0.0666\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0659 - val_loss: 0.0664\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0658 - val_loss: 0.0663\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0661\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0649 - val_loss: 0.0660\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0646 - val_loss: 0.0658\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.0656\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0642 - val_loss: 0.0655\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0643 - val_loss: 0.0653\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0639 - val_loss: 0.0651\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0633 - val_loss: 0.0649\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0631 - val_loss: 0.0647\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0631 - val_loss: 0.0645\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0643\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0641\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0614 - val_loss: 0.0640\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0639\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0637\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0626 - val_loss: 0.0635\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.0633\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0601 - val_loss: 0.0631\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0607 - val_loss: 0.0630\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0608 - val_loss: 0.0627\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0601 - val_loss: 0.0625\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0603 - val_loss: 0.0622\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0604 - val_loss: 0.0620\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0613 - val_loss: 0.0617\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0603 - val_loss: 0.0615\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0596 - val_loss: 0.0613\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0594 - val_loss: 0.0611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 18.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [00:54<02:44, 54.87s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0775 - val_loss: 0.0615\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0615 - val_loss: 0.0500\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0507 - val_loss: 0.0453\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0446 - val_loss: 0.0416\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0429 - val_loss: 0.0380\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0403 - val_loss: 0.0375\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0376 - val_loss: 0.0376\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0331\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0342 - val_loss: 0.0327\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0326 - val_loss: 0.0308\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.0306\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0306 - val_loss: 0.0294\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0296 - val_loss: 0.0301\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0295\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0303 - val_loss: 0.0292\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0268\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0270\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0275\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0286\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0280\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0269\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0253\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0254\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0257\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0257\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0256\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0260\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0254\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.0256\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0256\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0245\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0233\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0231\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0243\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0233\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0221 - val_loss: 0.0245\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0221\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0216 - val_loss: 0.0223\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0231\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0223\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0220\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0216\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0212\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0211\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0228\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0210\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0205\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0203\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0220\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0244\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0210\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0210\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0203\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0227\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0211\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0203\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0201 - val_loss: 0.0220\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0218\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0208\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0201\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0201\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0208\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0196\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0199\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0201\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0203\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0203\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0213\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0233\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0222\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0219\n",
      "Epoch 00087: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.5656 - val_loss: 0.4647\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4368 - val_loss: 0.3451\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3249 - val_loss: 0.2929\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2838 - val_loss: 0.2515\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2458 - val_loss: 0.2189\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2145 - val_loss: 0.1952\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1938 - val_loss: 0.1779\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1801 - val_loss: 0.1727\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1755 - val_loss: 0.1588\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1667 - val_loss: 0.1514\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1583 - val_loss: 0.1508\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1546 - val_loss: 0.1431\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1492 - val_loss: 0.1411\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1457 - val_loss: 0.1380\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1407 - val_loss: 0.1345\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1374 - val_loss: 0.1362\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1371 - val_loss: 0.1295\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1311 - val_loss: 0.1278\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1300 - val_loss: 0.1277\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1276 - val_loss: 0.1232\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1252 - val_loss: 0.1213\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1236 - val_loss: 0.1198\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1209 - val_loss: 0.1194\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1167\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1179 - val_loss: 0.1181\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1171 - val_loss: 0.1176\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1154 - val_loss: 0.1130\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1127 - val_loss: 0.1114\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1122 - val_loss: 0.1089\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1102 - val_loss: 0.1086\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1078 - val_loss: 0.1090\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1082 - val_loss: 0.1085\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1056 - val_loss: 0.1070\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1069 - val_loss: 0.1078\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1057 - val_loss: 0.1090\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1060 - val_loss: 0.1069\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1037 - val_loss: 0.1073\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1027 - val_loss: 0.1012\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1011 - val_loss: 0.1009\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0995 - val_loss: 0.1013\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0996 - val_loss: 0.1021\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1000 - val_loss: 0.1022\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1006 - val_loss: 0.0970\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.0997\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.0965\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0948 - val_loss: 0.1010\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0966 - val_loss: 0.0984\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0956 - val_loss: 0.0968\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0946 - val_loss: 0.0975\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0941 - val_loss: 0.0964\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0926 - val_loss: 0.0953\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0926 - val_loss: 0.0960\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0924 - val_loss: 0.0969\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0911 - val_loss: 0.0945\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0911 - val_loss: 0.0936\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0890 - val_loss: 0.0946\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0905 - val_loss: 0.0932\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0897 - val_loss: 0.0934\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0895 - val_loss: 0.0935\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0879 - val_loss: 0.0928\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0874 - val_loss: 0.0921\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0863 - val_loss: 0.0923\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0862 - val_loss: 0.0921\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0861 - val_loss: 0.0900\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0860 - val_loss: 0.0929\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0861 - val_loss: 0.0926\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0866 - val_loss: 0.0902\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - val_loss: 0.0895\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0844 - val_loss: 0.0899\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - val_loss: 0.0877\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - val_loss: 0.0913\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0846 - val_loss: 0.0900\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0848 - val_loss: 0.0882\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0850 - val_loss: 0.0907\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0840 - val_loss: 0.0874\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0819 - val_loss: 0.0893\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.0881\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - val_loss: 0.0891\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0832 - val_loss: 0.0868\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - val_loss: 0.0861\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0805 - val_loss: 0.0884\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - val_loss: 0.0890\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - val_loss: 0.0864\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0800 - val_loss: 0.0886\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0816 - val_loss: 0.0861\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0817 - val_loss: 0.0876\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0816 - val_loss: 0.0855\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0798 - val_loss: 0.0862\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0800 - val_loss: 0.0863\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0793 - val_loss: 0.0871\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0795 - val_loss: 0.0871\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0799 - val_loss: 0.0854\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0795 - val_loss: 0.0847\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0799 - val_loss: 0.0905\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0796 - val_loss: 0.0845\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0777 - val_loss: 0.0848\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0783 - val_loss: 0.0866\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0787 - val_loss: 0.0857\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0790 - val_loss: 0.0848\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0775 - val_loss: 0.0843\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0799 - val_loss: 0.0856\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0781 - val_loss: 0.0870\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0781 - val_loss: 0.0845\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0771 - val_loss: 0.0825\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0770 - val_loss: 0.0830\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0763 - val_loss: 0.0870\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0779 - val_loss: 0.0838\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.0758 - val_loss: 0.0843\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0761 - val_loss: 0.0848\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0757 - val_loss: 0.0852\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0770 - val_loss: 0.0836\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0767 - val_loss: 0.0880\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0788 - val_loss: 0.0846\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0779 - val_loss: 0.0885\n",
      "Epoch 00114: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.6662 - val_loss: 1.2890\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1953 - val_loss: 0.8934\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8226 - val_loss: 0.6609\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6471 - val_loss: 0.5873\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5731 - val_loss: 0.4843\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4721 - val_loss: 0.4088\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3998 - val_loss: 0.3696\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3627 - val_loss: 0.3352\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3317 - val_loss: 0.3082\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3119 - val_loss: 0.2955\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2974 - val_loss: 0.2822\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2843 - val_loss: 0.2699\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2726 - val_loss: 0.2679\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2638 - val_loss: 0.2580\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2572 - val_loss: 0.2493\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2523 - val_loss: 0.2481\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2450 - val_loss: 0.2417\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2410 - val_loss: 0.2369\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2347 - val_loss: 0.2297\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2284 - val_loss: 0.2236\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2247 - val_loss: 0.2254\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2215 - val_loss: 0.2197\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2158 - val_loss: 0.2153\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2142 - val_loss: 0.2140\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2088 - val_loss: 0.2092\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2070 - val_loss: 0.2056\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.2037 - val_loss: 0.2051\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1991 - val_loss: 0.2009\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1969 - val_loss: 0.1989\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1951 - val_loss: 0.1995\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1924 - val_loss: 0.1942\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1904 - val_loss: 0.1922\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1876 - val_loss: 0.1935\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1862 - val_loss: 0.1866\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1831 - val_loss: 0.1883\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1828 - val_loss: 0.1883\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1796 - val_loss: 0.1825\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1780 - val_loss: 0.1839\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1774 - val_loss: 0.1808\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1743 - val_loss: 0.1788\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1730 - val_loss: 0.1772\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1687 - val_loss: 0.1763\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1669 - val_loss: 0.1745\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1667 - val_loss: 0.1744\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1654 - val_loss: 0.1766\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1653 - val_loss: 0.1699\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1619 - val_loss: 0.1686\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1597 - val_loss: 0.1661\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1595 - val_loss: 0.1656\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1581 - val_loss: 0.1669\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1572 - val_loss: 0.1670\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1574 - val_loss: 0.1634\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1567 - val_loss: 0.1607\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1521 - val_loss: 0.1617\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1546 - val_loss: 0.1604\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1536 - val_loss: 0.1620\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1526 - val_loss: 0.1619\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1536 - val_loss: 0.1603\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1514 - val_loss: 0.1565\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1517 - val_loss: 0.1573\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1485 - val_loss: 0.1559\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1475 - val_loss: 0.1571\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1464 - val_loss: 0.1531\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1458 - val_loss: 0.1549\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1460 - val_loss: 0.1525\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1454 - val_loss: 0.1513\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1438 - val_loss: 0.1515\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1414 - val_loss: 0.1516\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1406 - val_loss: 0.1519\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1442 - val_loss: 0.1535\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1425 - val_loss: 0.1479\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1398 - val_loss: 0.1499\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1417 - val_loss: 0.1521\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1416 - val_loss: 0.1504\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1419 - val_loss: 0.1501\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1395 - val_loss: 0.1468\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1387 - val_loss: 0.1458\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1393 - val_loss: 0.1482\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1387 - val_loss: 0.1502\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1402 - val_loss: 0.1466\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1395 - val_loss: 0.1478\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1385 - val_loss: 0.1469\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1368 - val_loss: 0.1486\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1401 - val_loss: 0.1473\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1357 - val_loss: 0.1442\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1362 - val_loss: 0.1436\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1342 - val_loss: 0.1441\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1348 - val_loss: 0.1449\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1359 - val_loss: 0.1469\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1377 - val_loss: 0.1452\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1350 - val_loss: 0.1444\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1327 - val_loss: 0.1431\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1322 - val_loss: 0.1444\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1323 - val_loss: 0.1436\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1338 - val_loss: 0.1413\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1329 - val_loss: 0.1420\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1331 - val_loss: 0.1432\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1310 - val_loss: 0.1461\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1332 - val_loss: 0.1425\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1313 - val_loss: 0.1411\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1311 - val_loss: 0.1429\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1304 - val_loss: 0.1417\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1321 - val_loss: 0.1396\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1300 - val_loss: 0.1408\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1314 - val_loss: 0.1413\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1288 - val_loss: 0.1405\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1303 - val_loss: 0.1426\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1319 - val_loss: 0.1468\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1332 - val_loss: 0.1428\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1317 - val_loss: 0.1407\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1298 - val_loss: 0.1394\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1296 - val_loss: 0.1448\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1306 - val_loss: 0.1385\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1280 - val_loss: 0.1374\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1277 - val_loss: 0.1405\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1258 - val_loss: 0.1392\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1264 - val_loss: 0.1393\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1259 - val_loss: 0.1385\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1270 - val_loss: 0.1381\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1272 - val_loss: 0.1386\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1258 - val_loss: 0.1386\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1261 - val_loss: 0.1386\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1259 - val_loss: 0.1392\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1260 - val_loss: 0.1353\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1261 - val_loss: 0.1391\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1255 - val_loss: 0.1416\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1279 - val_loss: 0.1401\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1286 - val_loss: 0.1380\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1284 - val_loss: 0.1379\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1263 - val_loss: 0.1377\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1264 - val_loss: 0.1376\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1242 - val_loss: 0.1366\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1241 - val_loss: 0.1372\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1250 - val_loss: 0.1366\n",
      "Epoch 00134: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.0690 - val_loss: 2.3764\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1700 - val_loss: 1.4786\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3049 - val_loss: 0.7442\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.6478 - val_loss: 0.4234\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4062 - val_loss: 0.3742\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3690 - val_loss: 0.3714\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3630 - val_loss: 0.3418\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3267 - val_loss: 0.2962\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2824 - val_loss: 0.2624\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2543 - val_loss: 0.2450\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2407 - val_loss: 0.2330\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2296 - val_loss: 0.2237\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2177 - val_loss: 0.2166\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2111 - val_loss: 0.2092\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2051 - val_loss: 0.2044\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1983 - val_loss: 0.1984\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1912 - val_loss: 0.1935\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1848 - val_loss: 0.1884\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1811 - val_loss: 0.1852\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1788 - val_loss: 0.1812\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1746 - val_loss: 0.1785\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1714 - val_loss: 0.1763\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1691 - val_loss: 0.1714\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1655 - val_loss: 0.1697\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1633 - val_loss: 0.1696\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1620 - val_loss: 0.1669\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1563 - val_loss: 0.1634\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1551 - val_loss: 0.1624\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1519 - val_loss: 0.1607\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1507 - val_loss: 0.1587\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1488 - val_loss: 0.1547\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1469 - val_loss: 0.1527\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1451 - val_loss: 0.1512\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1419 - val_loss: 0.1503\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1409 - val_loss: 0.1478\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1391 - val_loss: 0.1464\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1383 - val_loss: 0.1503\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1365 - val_loss: 0.1447\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1352 - val_loss: 0.1445\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1345 - val_loss: 0.1431\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1315 - val_loss: 0.1414\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1297 - val_loss: 0.1380\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1286 - val_loss: 0.1402\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1272 - val_loss: 0.1374\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1263 - val_loss: 0.1384\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1255 - val_loss: 0.1365\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1238 - val_loss: 0.1345\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1226 - val_loss: 0.1330\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1210 - val_loss: 0.1317\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1195 - val_loss: 0.1311\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1308\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1298\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1156 - val_loss: 0.1283\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1157 - val_loss: 0.1293\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1154 - val_loss: 0.1279\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1147 - val_loss: 0.1261\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1140 - val_loss: 0.1242\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1101 - val_loss: 0.1244\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1124 - val_loss: 0.1234\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1099 - val_loss: 0.1220\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1091 - val_loss: 0.1206\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1079 - val_loss: 0.1199\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1070 - val_loss: 0.1209\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1078 - val_loss: 0.1209\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1068 - val_loss: 0.1190\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1046 - val_loss: 0.1169\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1037 - val_loss: 0.1155\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1057 - val_loss: 0.1187\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1034 - val_loss: 0.1167\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1020 - val_loss: 0.1135\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1010 - val_loss: 0.1148\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1008 - val_loss: 0.1109\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0992 - val_loss: 0.1133\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0985 - val_loss: 0.1130\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0987 - val_loss: 0.1107\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0965 - val_loss: 0.1108\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0966 - val_loss: 0.1078\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.1089\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0959 - val_loss: 0.1088\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0953 - val_loss: 0.1098\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0959 - val_loss: 0.1055\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0936 - val_loss: 0.1069\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0938 - val_loss: 0.1055\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0920 - val_loss: 0.1054\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0920 - val_loss: 0.1067\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0932 - val_loss: 0.1043\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0928 - val_loss: 0.1053\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0918 - val_loss: 0.1045\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0915 - val_loss: 0.1064\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0941 - val_loss: 0.1076\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0908 - val_loss: 0.1022\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0902 - val_loss: 0.1027\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0893 - val_loss: 0.1019\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0892 - val_loss: 0.1021\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0898 - val_loss: 0.1006\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0878 - val_loss: 0.1056\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0886 - val_loss: 0.0999\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0868 - val_loss: 0.0994\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0876 - val_loss: 0.1020\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0875 - val_loss: 0.0980\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - val_loss: 0.0988\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0864 - val_loss: 0.0985\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0852 - val_loss: 0.0982\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - val_loss: 0.0961\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - val_loss: 0.0978\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - val_loss: 0.0966\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0842 - val_loss: 0.0968\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0841 - val_loss: 0.0994\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0844 - val_loss: 0.0948\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.0961\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0817 - val_loss: 0.0945\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0823 - val_loss: 0.0956\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0837 - val_loss: 0.0998\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0843 - val_loss: 0.0961\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0815 - val_loss: 0.0990\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - val_loss: 0.0943\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0811 - val_loss: 0.0935\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0815 - val_loss: 0.0947\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0840 - val_loss: 0.1004\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0848 - val_loss: 0.0946\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0814 - val_loss: 0.0935\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0818 - val_loss: 0.0943\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0817 - val_loss: 0.0930\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0806 - val_loss: 0.1006\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0834 - val_loss: 0.0934\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0796 - val_loss: 0.0928\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0796 - val_loss: 0.0924\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0785 - val_loss: 0.0929\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0787 - val_loss: 0.0927\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0929\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0790 - val_loss: 0.0924\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0783 - val_loss: 0.0919\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0777 - val_loss: 0.0908\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0780 - val_loss: 0.0921\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0781 - val_loss: 0.0906\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0772 - val_loss: 0.0900\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0789 - val_loss: 0.0919\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0777 - val_loss: 0.0917\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0769 - val_loss: 0.0885\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0773 - val_loss: 0.0890\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0775 - val_loss: 0.0894\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0773 - val_loss: 0.0900\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0777 - val_loss: 0.0957\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0786 - val_loss: 0.0908\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0782 - val_loss: 0.0900\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0780 - val_loss: 0.0890\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0776 - val_loss: 0.0910\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0766 - val_loss: 0.0906\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0778 - val_loss: 0.0884\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0758 - val_loss: 0.0886\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0765 - val_loss: 0.0907\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0753 - val_loss: 0.0897\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0764 - val_loss: 0.0886\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0758 - val_loss: 0.0889\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0752 - val_loss: 0.0877\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0747 - val_loss: 0.0893\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0746 - val_loss: 0.0875\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0744 - val_loss: 0.0863\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0865\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0862\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0737 - val_loss: 0.0879\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0743 - val_loss: 0.0872\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0737 - val_loss: 0.0866\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0738 - val_loss: 0.0867\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0738 - val_loss: 0.0877\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0739 - val_loss: 0.0871\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0726 - val_loss: 0.0873\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0737 - val_loss: 0.0884\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0741 - val_loss: 0.0875\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0859\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0866\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0733 - val_loss: 0.0862\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0738 - val_loss: 0.0877\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0780 - val_loss: 0.0897\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0756 - val_loss: 0.0862\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0738 - val_loss: 0.0881\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0745 - val_loss: 0.0887\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0748 - val_loss: 0.0856\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0732 - val_loss: 0.0849\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0724 - val_loss: 0.0868\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0735 - val_loss: 0.0869\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0724 - val_loss: 0.0852\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0713 - val_loss: 0.0846\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0728 - val_loss: 0.0859\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0732 - val_loss: 0.0901\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0739 - val_loss: 0.0849\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0724 - val_loss: 0.0861\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0711 - val_loss: 0.0849\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0725 - val_loss: 0.0850\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0736 - val_loss: 0.0860\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0724 - val_loss: 0.0917\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0736 - val_loss: 0.0854\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0711 - val_loss: 0.0853\n",
      "Epoch 00193: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 3.9816 - val_loss: 3.1720\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.9672 - val_loss: 2.1953\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0122 - val_loss: 1.3487\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2240 - val_loss: 0.7461\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6717 - val_loss: 0.3716\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3388 - val_loss: 0.1898\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1908 - val_loss: 0.1256\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1234 - val_loss: 0.1090\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1096 - val_loss: 0.1032\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1029 - val_loss: 0.1006\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0983 - val_loss: 0.0979\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0960 - val_loss: 0.0947\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0942 - val_loss: 0.0917\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0924 - val_loss: 0.0890\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0890 - val_loss: 0.0864\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0853 - val_loss: 0.0838\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0840 - val_loss: 0.0816\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0807 - val_loss: 0.0795\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0781 - val_loss: 0.0774\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0763 - val_loss: 0.0752\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0744 - val_loss: 0.0730\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0720 - val_loss: 0.0709\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0703 - val_loss: 0.0689\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0679 - val_loss: 0.0672\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0661 - val_loss: 0.0652\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0647 - val_loss: 0.0636\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0629 - val_loss: 0.0626\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0616 - val_loss: 0.0614\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0598 - val_loss: 0.0600\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0589 - val_loss: 0.0588\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0570 - val_loss: 0.0578\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0559 - val_loss: 0.0570\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0547 - val_loss: 0.0559\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0539 - val_loss: 0.0549\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0529 - val_loss: 0.0539\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0512 - val_loss: 0.0528\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0506 - val_loss: 0.0523\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0496 - val_loss: 0.0518\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0494 - val_loss: 0.0518\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0479 - val_loss: 0.0511\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0476 - val_loss: 0.0500\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0465 - val_loss: 0.0486\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0461 - val_loss: 0.0483\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0462 - val_loss: 0.0478\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0445 - val_loss: 0.0474\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0450 - val_loss: 0.0473\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0440 - val_loss: 0.0467\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0435 - val_loss: 0.0461\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0434 - val_loss: 0.0456\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0421 - val_loss: 0.0454\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0422 - val_loss: 0.0455\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0416 - val_loss: 0.0455\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0408 - val_loss: 0.0445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0409 - val_loss: 0.0433\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0402 - val_loss: 0.0421\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0402 - val_loss: 0.0420\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0392 - val_loss: 0.0422\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0394 - val_loss: 0.0427\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0385 - val_loss: 0.0421\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0384 - val_loss: 0.0419\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0380 - val_loss: 0.0418\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0374 - val_loss: 0.0417\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0375 - val_loss: 0.0412\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0371 - val_loss: 0.0408\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0363 - val_loss: 0.0401\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0397\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0392\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0360 - val_loss: 0.0393\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0356 - val_loss: 0.0392\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0352 - val_loss: 0.0395\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.0390\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0385\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0343 - val_loss: 0.0383\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0341 - val_loss: 0.0380\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0338 - val_loss: 0.0372\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0335 - val_loss: 0.0375\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0332 - val_loss: 0.0377\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0379\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0324 - val_loss: 0.0369\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0372\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0332 - val_loss: 0.0368\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0321 - val_loss: 0.0368\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0317 - val_loss: 0.0363\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0319 - val_loss: 0.0362\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0362\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0362\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0307 - val_loss: 0.0360\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0357\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0359\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0357\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0304 - val_loss: 0.0360\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0359\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0352\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0345\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0296 - val_loss: 0.0344\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0350\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0298 - val_loss: 0.0348\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0340\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0287 - val_loss: 0.0334\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0334\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.0339\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0338\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0345\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0291 - val_loss: 0.0335\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0330\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0288 - val_loss: 0.0340\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0289 - val_loss: 0.0324\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.0324\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0276 - val_loss: 0.0334\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - val_loss: 0.0335\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0335\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0324\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0320\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0272 - val_loss: 0.0323\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - val_loss: 0.0333\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0337\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0336\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0339\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0267 - val_loss: 0.0333\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0264 - val_loss: 0.0312\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0265 - val_loss: 0.0316\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.0316\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0260 - val_loss: 0.0319\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0319\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0310\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0254 - val_loss: 0.0314\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0306\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0297\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0258 - val_loss: 0.0291\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.0302\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0307\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0254 - val_loss: 0.0300\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0302\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0303\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0311\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0244 - val_loss: 0.0307\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0305\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.0303\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00139: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 17.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 17.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████     | 2/4 [01:36<01:41, 50.89s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0873 - val_loss: 0.0704\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0661 - val_loss: 0.0518\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0486 - val_loss: 0.0426\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0411 - val_loss: 0.0458\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0437 - val_loss: 0.0448\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0431 - val_loss: 0.0345\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0348 - val_loss: 0.0354\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0331 - val_loss: 0.0305\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0303 - val_loss: 0.0282\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0334\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.0284\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0270 - val_loss: 0.0296\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0244\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.0255\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0283\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0328\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0299 - val_loss: 0.0309\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0283\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0249 - val_loss: 0.0247\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0261 - val_loss: 0.0296\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0261\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0278\n",
      "Epoch 00023: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4583 - val_loss: 0.2903\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2669 - val_loss: 0.1890\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1930 - val_loss: 0.1647\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1651 - val_loss: 0.1456\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1455 - val_loss: 0.1322\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1408 - val_loss: 0.1329\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1314 - val_loss: 0.1083\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1223 - val_loss: 0.1101\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1134 - val_loss: 0.1089\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1116 - val_loss: 0.1082\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1090 - val_loss: 0.1101\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1088 - val_loss: 0.0963\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1031 - val_loss: 0.1040\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1044 - val_loss: 0.0919\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0974 - val_loss: 0.0984\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0989 - val_loss: 0.0919\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0912\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0958 - val_loss: 0.0948\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0904 - val_loss: 0.0922\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0931 - val_loss: 0.0891\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0886 - val_loss: 0.1010\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0968 - val_loss: 0.0941\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0963 - val_loss: 0.0983\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0934 - val_loss: 0.0972\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0948 - val_loss: 0.0999\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0960 - val_loss: 0.0906\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0918 - val_loss: 0.0937\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0884 - val_loss: 0.0871\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0892 - val_loss: 0.0902\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0921 - val_loss: 0.0977\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0967 - val_loss: 0.0931\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0922 - val_loss: 0.0879\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0888 - val_loss: 0.1017\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0960 - val_loss: 0.0867\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0855 - val_loss: 0.0926\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0911 - val_loss: 0.0942\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0906 - val_loss: 0.0929\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0871 - val_loss: 0.0831\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0860 - val_loss: 0.0839\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0852 - val_loss: 0.0840\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0841 - val_loss: 0.0900\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0854 - val_loss: 0.0858\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0882 - val_loss: 0.0875\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0853 - val_loss: 0.0836\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0856 - val_loss: 0.0887\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0844 - val_loss: 0.0849\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0824 - val_loss: 0.0842\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0821 - val_loss: 0.0843\n",
      "Epoch 00048: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2345 - val_loss: 0.4723\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4933 - val_loss: 0.3874\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3737 - val_loss: 0.3215\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3030 - val_loss: 0.2548\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2604 - val_loss: 0.2262\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2308 - val_loss: 0.2160\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2187 - val_loss: 0.1991\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2027 - val_loss: 0.1949\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1921 - val_loss: 0.1833\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1802 - val_loss: 0.1843\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1776 - val_loss: 0.1646\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1687 - val_loss: 0.1665\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1620 - val_loss: 0.1585\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1576 - val_loss: 0.1636\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1567 - val_loss: 0.1570\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1548 - val_loss: 0.1556\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1541 - val_loss: 0.1496\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1469 - val_loss: 0.1474\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1448 - val_loss: 0.1545\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1528 - val_loss: 0.1885\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1783 - val_loss: 0.1746\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1655 - val_loss: 0.1763\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1640 - val_loss: 0.1515\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1545 - val_loss: 0.1470\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1465 - val_loss: 0.1576\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1523 - val_loss: 0.1504\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1499 - val_loss: 0.1436\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1434 - val_loss: 0.1448\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1439 - val_loss: 0.1553\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1538 - val_loss: 0.1378\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1402 - val_loss: 0.1427\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1390 - val_loss: 0.1434\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1456 - val_loss: 0.1496\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1442 - val_loss: 0.1428\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1408 - val_loss: 0.1377\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1391 - val_loss: 0.1405\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1372 - val_loss: 0.1405\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1394 - val_loss: 0.1328\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1359 - val_loss: 0.1382\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1358 - val_loss: 0.1326\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1309 - val_loss: 0.1379\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1367 - val_loss: 0.1378\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1330 - val_loss: 0.1394\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1343 - val_loss: 0.1327\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1367 - val_loss: 0.1338\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1324 - val_loss: 0.1392\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1377 - val_loss: 0.1343\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1331 - val_loss: 0.1526\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1430 - val_loss: 0.1484\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1410 - val_loss: 0.1448\n",
      "Epoch 00050: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.0527 - val_loss: 0.7881\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7113 - val_loss: 0.3413\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3557 - val_loss: 0.2580\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2695 - val_loss: 0.2424\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2339 - val_loss: 0.1965\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1970 - val_loss: 0.1660\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1645 - val_loss: 0.1565\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1523 - val_loss: 0.1469\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1413 - val_loss: 0.1330\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1322 - val_loss: 0.1276\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1234 - val_loss: 0.1269\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1214 - val_loss: 0.1208\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1185 - val_loss: 0.1186\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1186 - val_loss: 0.1210\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1080\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1080 - val_loss: 0.1109\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1156 - val_loss: 0.1209\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1162 - val_loss: 0.1226\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1119 - val_loss: 0.1119\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1070 - val_loss: 0.1033\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0987 - val_loss: 0.0961\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0978 - val_loss: 0.1026\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1022 - val_loss: 0.1105\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1065 - val_loss: 0.1045\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0975 - val_loss: 0.1036\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0943 - val_loss: 0.0996\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0939 - val_loss: 0.0937\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0881 - val_loss: 0.0906\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0897 - val_loss: 0.0916\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0871 - val_loss: 0.0936\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0883 - val_loss: 0.0963\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0871 - val_loss: 0.0887\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0872 - val_loss: 0.1029\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0974 - val_loss: 0.1024\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0953 - val_loss: 0.1019\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0937 - val_loss: 0.1085\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0984 - val_loss: 0.1002\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0973 - val_loss: 0.0920\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0922 - val_loss: 0.0892\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0862 - val_loss: 0.0832\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - val_loss: 0.0842\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.0849\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0804 - val_loss: 0.0856\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0812 - val_loss: 0.0915\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0880 - val_loss: 0.0935\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0938 - val_loss: 0.0907\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0878 - val_loss: 0.0882\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0846 - val_loss: 0.0868\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0867 - val_loss: 0.0902\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0835 - val_loss: 0.0894\n",
      "Epoch 00050: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 2.0523 - val_loss: 0.2002\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2424 - val_loss: 0.3365\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3255 - val_loss: 0.2696\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2364 - val_loss: 0.1541\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1307 - val_loss: 0.0802\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - val_loss: 0.0641\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0630 - val_loss: 0.0586\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0587 - val_loss: 0.0467\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0471 - val_loss: 0.0409\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0405 - val_loss: 0.0413\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0401 - val_loss: 0.0435\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0369 - val_loss: 0.0545\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0395 - val_loss: 0.0372\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0340 - val_loss: 0.0357\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0319 - val_loss: 0.0360\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0323\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0346 - val_loss: 0.0352\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0372 - val_loss: 0.0565\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0409 - val_loss: 0.0310\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0316 - val_loss: 0.0286\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0288\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0290 - val_loss: 0.0280\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0292\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0310\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0289 - val_loss: 0.0328\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0277 - val_loss: 0.0275\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0279 - val_loss: 0.0350\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0267 - val_loss: 0.0279\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0255\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0259\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0265\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0270\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0322\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0289\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0340\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0264\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0327\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0254 - val_loss: 0.0270\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0240\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0261\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.0259\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0243\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0261\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.0241\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0237 - val_loss: 0.0261\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0240\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0277\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0234\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0273\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0228 - val_loss: 0.0289\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0344\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0307\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0308 - val_loss: 0.0333\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0310 - val_loss: 0.0271\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0250 - val_loss: 0.0255\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0242\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0230\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0225\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0236\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0229\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0234\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0218\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0239\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0242\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0217\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0234\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0250\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0229\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0273\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0224\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0231\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0244\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0242\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00079: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 18.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 17.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████▌  | 3/4 [01:57<00:42, 42.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training !\n",
      "Quantile: 0.022750131948179195\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 5.9210 - val_loss: 0.6789\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6565 - val_loss: 1.0271\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9807 - val_loss: 0.9621\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7433 - val_loss: 2.3502\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1131 - val_loss: 0.7697\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9372 - val_loss: 0.7465\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6296 - val_loss: 0.2419\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2992 - val_loss: 0.3251\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2929 - val_loss: 0.2502\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2233 - val_loss: 0.1755\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1699 - val_loss: 0.2561\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2860 - val_loss: 0.4070\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3746 - val_loss: 0.2310\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2055 - val_loss: 0.1441\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1372 - val_loss: 0.1132\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1159 - val_loss: 0.1081\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1083 - val_loss: 0.0700\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0765 - val_loss: 0.0726\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0833 - val_loss: 0.0735\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0687 - val_loss: 0.0625\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0588 - val_loss: 0.0562\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0554 - val_loss: 0.0517\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0475 - val_loss: 0.0435\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0473 - val_loss: 0.0413\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0418 - val_loss: 0.0402\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0398 - val_loss: 0.0376\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0372 - val_loss: 0.0642\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0720 - val_loss: 0.0775\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0661 - val_loss: 0.0444\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0465 - val_loss: 0.0420\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0431 - val_loss: 0.0498\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0459 - val_loss: 0.0457\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0389 - val_loss: 0.0330\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0313 - val_loss: 0.0294\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0281 - val_loss: 0.0269\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0268 - val_loss: 0.0273\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0261\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.0246\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - val_loss: 0.0253\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0238\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0235\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.0223\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0239\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0260\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0256 - val_loss: 0.0235\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0250\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0220\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0247 - val_loss: 0.0272\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0262\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0240\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0234\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0225\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.0243\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0216\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0261\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0264\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0248 - val_loss: 0.0255\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0260\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0261 - val_loss: 0.0285\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0259 - val_loss: 0.0233\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.0243\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0238 - val_loss: 0.0219\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0223 - val_loss: 0.0241\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 00065: early stopping\n",
      "Quantile: 0.15865525393145707\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 4.7065 - val_loss: 4.1042\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1325 - val_loss: 0.9343\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4307 - val_loss: 1.1688\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0066 - val_loss: 0.4302\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7942 - val_loss: 0.8931\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6903 - val_loss: 0.4289\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4201 - val_loss: 0.2780\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2858 - val_loss: 0.2235\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2238 - val_loss: 0.1795\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1889 - val_loss: 0.1602\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1673 - val_loss: 0.1445\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1483 - val_loss: 0.1265\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1348 - val_loss: 0.2002\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2005 - val_loss: 0.1622\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.1521 - val_loss: 0.1139\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1196 - val_loss: 0.1536\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1400 - val_loss: 0.1091\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1119 - val_loss: 0.1260\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1167 - val_loss: 0.0973\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1024 - val_loss: 0.0928\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0962 - val_loss: 0.0948\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0971 - val_loss: 0.0852\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0913 - val_loss: 0.0903\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0944 - val_loss: 0.0886\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0972 - val_loss: 0.0852\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0943 - val_loss: 0.0864\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0885 - val_loss: 0.0860\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0882 - val_loss: 0.0855\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0858 - val_loss: 0.0906\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0932 - val_loss: 0.0860\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0900 - val_loss: 0.0837\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0881 - val_loss: 0.0904\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0911 - val_loss: 0.0818\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0868 - val_loss: 0.0867\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0892 - val_loss: 0.0823\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0875 - val_loss: 0.0866\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0854 - val_loss: 0.0879\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0890 - val_loss: 0.0799\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0839 - val_loss: 0.0852\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0838 - val_loss: 0.0804\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.0839\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0898 - val_loss: 0.1008\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0962 - val_loss: 0.0831\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0846 - val_loss: 0.1054\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0993 - val_loss: 0.0881\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0933 - val_loss: 0.0886\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0914 - val_loss: 0.0834\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0854 - val_loss: 0.0799\n",
      "Epoch 00048: early stopping\n",
      "Quantile: 0.5\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.9064 - val_loss: 1.3279\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2814 - val_loss: 1.4153\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3924 - val_loss: 0.7604\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7236 - val_loss: 0.4515\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4172 - val_loss: 0.4015\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3190 - val_loss: 0.2902\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2574 - val_loss: 0.2151\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2134 - val_loss: 0.1781\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1819 - val_loss: 0.1705\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1758 - val_loss: 0.1580\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1611 - val_loss: 0.1601\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1626 - val_loss: 0.1502\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1573 - val_loss: 0.1664\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1637 - val_loss: 0.1395\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1473 - val_loss: 0.1587\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1522 - val_loss: 0.1394\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1430 - val_loss: 0.1483\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1488 - val_loss: 0.1504\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1476 - val_loss: 0.1452\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1432 - val_loss: 0.1357\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1397 - val_loss: 0.1448\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1481 - val_loss: 0.1373\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1411 - val_loss: 0.1361\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1401 - val_loss: 0.1401\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1453 - val_loss: 0.1363\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1418 - val_loss: 0.1359\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1439 - val_loss: 0.1361\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1407 - val_loss: 0.1384\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1393 - val_loss: 0.1636\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1566 - val_loss: 0.1529\n",
      "Epoch 00030: early stopping\n",
      "Quantile: 0.8413447460685429\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 2.2181 - val_loss: 0.9481\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3110 - val_loss: 0.6995\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6789 - val_loss: 0.3685\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.4465 - val_loss: 1.3838\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.1132 - val_loss: 0.5961\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5043 - val_loss: 0.3226\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3358 - val_loss: 0.5737\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.4141 - val_loss: 0.2702\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2275 - val_loss: 0.1761\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1688 - val_loss: 0.1458\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1324 - val_loss: 0.1227\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1135 - val_loss: 0.1109\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1103 - val_loss: 0.1137\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1117 - val_loss: 0.1130\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1099 - val_loss: 0.0943\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0998 - val_loss: 0.1345\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1193 - val_loss: 0.1033\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1029 - val_loss: 0.1006\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0933 - val_loss: 0.1054\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1003 - val_loss: 0.1137\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1047 - val_loss: 0.0939\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0977 - val_loss: 0.0876\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0943 - val_loss: 0.0841\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0852 - val_loss: 0.0886\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0881 - val_loss: 0.0860\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0852 - val_loss: 0.0817\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0849 - val_loss: 0.0802\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0818 - val_loss: 0.0835\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0826 - val_loss: 0.0817\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0838 - val_loss: 0.0971\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0911 - val_loss: 0.0948\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0888 - val_loss: 0.1048\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0983 - val_loss: 0.0997\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0972 - val_loss: 0.0882\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0899 - val_loss: 0.0803\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0871 - val_loss: 0.0849\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0858 - val_loss: 0.0801\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0839 - val_loss: 0.0792\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0833 - val_loss: 0.0857\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0841 - val_loss: 0.0898\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0880 - val_loss: 0.0871\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0844 - val_loss: 0.0810\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0816 - val_loss: 0.0873\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0817 - val_loss: 0.0835\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0801 - val_loss: 0.0852\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.0821 - val_loss: 0.0851\n",
      "Epoch 00049: early stopping\n",
      "Quantile: 0.9772498680518208\n",
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 70ms/step - loss: 2.1284 - val_loss: 1.1169\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.5524 - val_loss: 1.5198\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.0358 - val_loss: 1.0260\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9981 - val_loss: 0.6308\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4916 - val_loss: 0.5602\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5150 - val_loss: 0.2969\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2357 - val_loss: 0.2704\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.2841 - val_loss: 0.2220\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1825 - val_loss: 0.1395\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.1206 - val_loss: 0.1064\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0973 - val_loss: 0.0547\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.0591 - val_loss: 0.0659\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0608 - val_loss: 0.0523\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0588 - val_loss: 0.0616\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0631 - val_loss: 0.0534\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0549 - val_loss: 0.0559\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.0649 - val_loss: 0.0746\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0560 - val_loss: 0.0541\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0456 - val_loss: 0.0424\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0348\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0322 - val_loss: 0.0353\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0318 - val_loss: 0.0377\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0334 - val_loss: 0.0340\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0350 - val_loss: 0.0368\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0348 - val_loss: 0.0355\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0340 - val_loss: 0.0554\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0392 - val_loss: 0.0345\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0325 - val_loss: 0.0272\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0273 - val_loss: 0.0288\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0271 - val_loss: 0.0317\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0302 - val_loss: 0.0267\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0309 - val_loss: 0.0293\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0328 - val_loss: 0.0320\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.0302\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0266 - val_loss: 0.0251\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0249 - val_loss: 0.0236\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0231\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0329\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0277 - val_loss: 0.0239\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0253 - val_loss: 0.0301\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0268 - val_loss: 0.0330\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0299 - val_loss: 0.0313\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0237 - val_loss: 0.0226\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.0243\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0260 - val_loss: 0.0263\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0289\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0813\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0937 - val_loss: 0.1871\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1666 - val_loss: 0.1382\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1282 - val_loss: 0.5706\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4729 - val_loss: 2.4564\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 13.2018 - val_loss: 196.6631\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 109.3611 - val_loss: 81.9019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00055: early stopping\n",
      "Done\n",
      "predicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [00:00<00:00, 15.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 14.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "<ipython-input-57-a59834279e78>:10: RuntimeWarning: overflow encountered in exp\n",
      "  results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n",
      " 75%|███████▌  | 3/4 [02:25<00:48, 48.63s/it]\n",
      "  0%|          | 0/1 [02:25<?, ?it/s]\n",
      " 83%|████████▎ | 5/6 [21:02<04:12, 252.42s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (97,) (98,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a59834279e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mqreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8a7828349cf7>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(predictions, target)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Calculate the CRPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"crps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Bonus useful Feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8a7828349cf7>\u001b[0m in \u001b[0;36mCRPS\u001b[0;34m(predictions, actuals)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdifs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcdf_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifs_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8a7828349cf7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mCRPS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mdifs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcdf_dif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifs_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8a7828349cf7>\u001b[0m in \u001b[0;36mcdf_dif\u001b[0;34m(prediction, actual)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdif\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdif\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mheavyside\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# If the actual is outside the range of the prediction,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# we need to account for that areas outside the range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__mul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rmul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   4996\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4997\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4998\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5000\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (97,) (98,) "
     ]
    }
   ],
   "source": [
    "alls=[]\n",
    "\n",
    "for batch_size in tqdm([32,64,200,500,1000,2000]):\n",
    "    for epochs in tqdm([200]):\n",
    "        for lr in tqdm([0.0001,0.001,0.01,0.1]):\n",
    "\n",
    "            qreg = MLPQuantile(batch_size=batch_size,epochs=epochs,lr=lr)\n",
    "            qreg.fit(X_train_std,y_train)\n",
    "            preds = qreg.predict(X_test_std)\n",
    "            results=evaluate((np.exp(preds)-1),(np.exp(y_test)-1).values)\n",
    "\n",
    "            del results[\"all\"]\n",
    "            del results[\"target\"]\n",
    "            results[\"batch_size\"]=batch_size\n",
    "            results[\"epochs\"]=epochs\n",
    "            results[\"lr\"]=lr\n",
    "            alls.append(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crps</th>\n",
       "      <th>count</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>bias</th>\n",
       "      <th>corr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.422962e+01</td>\n",
       "      <td>501</td>\n",
       "      <td>2.731237e+01</td>\n",
       "      <td>1.983951e+01</td>\n",
       "      <td>-3.657562e+00</td>\n",
       "      <td>0.734871</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.377067e+01</td>\n",
       "      <td>520</td>\n",
       "      <td>2.731568e+01</td>\n",
       "      <td>1.916355e+01</td>\n",
       "      <td>2.974284e+00</td>\n",
       "      <td>0.732003</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.349487e+01</td>\n",
       "      <td>509</td>\n",
       "      <td>2.783379e+01</td>\n",
       "      <td>1.915386e+01</td>\n",
       "      <td>4.290892e+00</td>\n",
       "      <td>0.723289</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.413734e+01</td>\n",
       "      <td>508</td>\n",
       "      <td>2.785583e+01</td>\n",
       "      <td>1.978315e+01</td>\n",
       "      <td>-3.097706e-02</td>\n",
       "      <td>0.716947</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.385494e+01</td>\n",
       "      <td>516</td>\n",
       "      <td>2.826727e+01</td>\n",
       "      <td>1.937147e+01</td>\n",
       "      <td>-7.111256e-01</td>\n",
       "      <td>0.711382</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.401178e+01</td>\n",
       "      <td>514</td>\n",
       "      <td>2.841920e+01</td>\n",
       "      <td>1.964609e+01</td>\n",
       "      <td>1.177599e+00</td>\n",
       "      <td>0.700589</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.463244e+01</td>\n",
       "      <td>524</td>\n",
       "      <td>2.845343e+01</td>\n",
       "      <td>2.011684e+01</td>\n",
       "      <td>6.537401e-02</td>\n",
       "      <td>0.699538</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.473368e+01</td>\n",
       "      <td>512</td>\n",
       "      <td>2.851783e+01</td>\n",
       "      <td>2.037366e+01</td>\n",
       "      <td>-4.468434e+00</td>\n",
       "      <td>0.719861</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.417941e+01</td>\n",
       "      <td>515</td>\n",
       "      <td>2.882323e+01</td>\n",
       "      <td>2.029484e+01</td>\n",
       "      <td>1.163991e+00</td>\n",
       "      <td>0.691672</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.455770e+01</td>\n",
       "      <td>524</td>\n",
       "      <td>2.969299e+01</td>\n",
       "      <td>2.015031e+01</td>\n",
       "      <td>2.965062e+00</td>\n",
       "      <td>0.674825</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.503291e+01</td>\n",
       "      <td>504</td>\n",
       "      <td>3.013125e+01</td>\n",
       "      <td>2.106543e+01</td>\n",
       "      <td>-3.617969e-01</td>\n",
       "      <td>0.658013</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.455094e+01</td>\n",
       "      <td>520</td>\n",
       "      <td>3.018036e+01</td>\n",
       "      <td>2.047202e+01</td>\n",
       "      <td>3.769241e+00</td>\n",
       "      <td>0.658355</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.482003e+01</td>\n",
       "      <td>513</td>\n",
       "      <td>3.018612e+01</td>\n",
       "      <td>2.064030e+01</td>\n",
       "      <td>3.435591e+00</td>\n",
       "      <td>0.663994</td>\n",
       "      <td>2000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.474531e+01</td>\n",
       "      <td>504</td>\n",
       "      <td>3.021823e+01</td>\n",
       "      <td>2.043523e+01</td>\n",
       "      <td>-4.427095e+00</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.504706e+01</td>\n",
       "      <td>518</td>\n",
       "      <td>3.032488e+01</td>\n",
       "      <td>2.092264e+01</td>\n",
       "      <td>4.137187e-01</td>\n",
       "      <td>0.666399</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.548254e+01</td>\n",
       "      <td>520</td>\n",
       "      <td>3.053365e+01</td>\n",
       "      <td>2.118295e+01</td>\n",
       "      <td>-4.193743e+00</td>\n",
       "      <td>0.669999</td>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.539920e+01</td>\n",
       "      <td>515</td>\n",
       "      <td>3.065882e+01</td>\n",
       "      <td>2.101116e+01</td>\n",
       "      <td>-4.707771e+00</td>\n",
       "      <td>0.689445</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.735813e+30</td>\n",
       "      <td>527</td>\n",
       "      <td>3.102701e+01</td>\n",
       "      <td>2.234847e+01</td>\n",
       "      <td>2.235736e+00</td>\n",
       "      <td>0.631242</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.517524e+01</td>\n",
       "      <td>516</td>\n",
       "      <td>3.119388e+01</td>\n",
       "      <td>2.126628e+01</td>\n",
       "      <td>6.981089e+00</td>\n",
       "      <td>0.645571</td>\n",
       "      <td>2000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.781360e+01</td>\n",
       "      <td>519</td>\n",
       "      <td>3.427044e+01</td>\n",
       "      <td>2.421322e+01</td>\n",
       "      <td>5.814700e-01</td>\n",
       "      <td>0.576196</td>\n",
       "      <td>1000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.444211e+01</td>\n",
       "      <td>519</td>\n",
       "      <td>4.464984e+01</td>\n",
       "      <td>3.150719e+01</td>\n",
       "      <td>-2.354115e+00</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>2000</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.875006e+02</td>\n",
       "      <td>527</td>\n",
       "      <td>1.586709e+02</td>\n",
       "      <td>6.677157e+01</td>\n",
       "      <td>-4.713319e+01</td>\n",
       "      <td>0.443552</td>\n",
       "      <td>64</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.179630e+81</td>\n",
       "      <td>526</td>\n",
       "      <td>1.863612e+31</td>\n",
       "      <td>1.036538e+30</td>\n",
       "      <td>-1.036538e+30</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>32</td>\n",
       "      <td>200</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            crps  count          rmse           mae          bias      corr  \\\n",
       "5   1.422962e+01    501  2.731237e+01  1.983951e+01 -3.657562e+00  0.734871   \n",
       "14  1.377067e+01    520  2.731568e+01  1.916355e+01  2.974284e+00  0.732003   \n",
       "9   1.349487e+01    509  2.783379e+01  1.915386e+01  4.290892e+00  0.723289   \n",
       "4   1.413734e+01    508  2.785583e+01  1.978315e+01 -3.097706e-02  0.716947   \n",
       "13  1.385494e+01    516  2.826727e+01  1.937147e+01 -7.111256e-01  0.711382   \n",
       "0   1.401178e+01    514  2.841920e+01  1.964609e+01  1.177599e+00  0.700589   \n",
       "2   1.463244e+01    524  2.845343e+01  2.011684e+01  6.537401e-02  0.699538   \n",
       "17  1.473368e+01    512  2.851783e+01  2.037366e+01 -4.468434e+00  0.719861   \n",
       "8   1.417941e+01    515  2.882323e+01  2.029484e+01  1.163991e+00  0.691672   \n",
       "18  1.455770e+01    524  2.969299e+01  2.015031e+01  2.965062e+00  0.674825   \n",
       "6   1.503291e+01    504  3.013125e+01  2.106543e+01 -3.617969e-01  0.658013   \n",
       "10  1.455094e+01    520  3.018036e+01  2.047202e+01  3.769241e+00  0.658355   \n",
       "21  1.482003e+01    513  3.018612e+01  2.064030e+01  3.435591e+00  0.663994   \n",
       "1   1.474531e+01    504  3.021823e+01  2.043523e+01 -4.427095e+00  0.691703   \n",
       "12  1.504706e+01    518  3.032488e+01  2.092264e+01  4.137187e-01  0.666399   \n",
       "15  1.548254e+01    520  3.053365e+01  2.118295e+01 -4.193743e+00  0.669999   \n",
       "19  1.539920e+01    515  3.065882e+01  2.101116e+01 -4.707771e+00  0.689445   \n",
       "11  7.735813e+30    527  3.102701e+01  2.234847e+01  2.235736e+00  0.631242   \n",
       "22  1.517524e+01    516  3.119388e+01  2.126628e+01  6.981089e+00  0.645571   \n",
       "16  1.781360e+01    519  3.427044e+01  2.421322e+01  5.814700e-01  0.576196   \n",
       "20  2.444211e+01    519  4.464984e+01  3.150719e+01 -2.354115e+00  0.464100   \n",
       "7   1.875006e+02    527  1.586709e+02  6.677157e+01 -4.713319e+01  0.443552   \n",
       "3   4.179630e+81    526  1.863612e+31  1.036538e+30 -1.036538e+30  0.009494   \n",
       "\n",
       "    batch_size  epochs      lr  \n",
       "5           64     200  0.0010  \n",
       "14         500     200  0.0100  \n",
       "9          200     200  0.0010  \n",
       "4           64     200  0.0001  \n",
       "13         500     200  0.0010  \n",
       "0           32     200  0.0001  \n",
       "2           32     200  0.0100  \n",
       "17        1000     200  0.0010  \n",
       "8          200     200  0.0001  \n",
       "18        1000     200  0.0100  \n",
       "6           64     200  0.0100  \n",
       "10         200     200  0.0100  \n",
       "21        2000     200  0.0010  \n",
       "1           32     200  0.0010  \n",
       "12         500     200  0.0001  \n",
       "15         500     200  0.1000  \n",
       "19        1000     200  0.1000  \n",
       "11         200     200  0.1000  \n",
       "22        2000     200  0.0100  \n",
       "16        1000     200  0.0001  \n",
       "20        2000     200  0.0001  \n",
       "7           64     200  0.1000  \n",
       "3           32     200  0.1000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(alls).sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
